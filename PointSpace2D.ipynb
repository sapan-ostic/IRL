{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "! rm -r runs\n",
    "\n",
    "import gym\n",
    "import gym_point\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from util import PGN, RewardNet, GRL, float32_preprocessor\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8bf80c2b40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAMMA = 0.95\n",
    "LEARNING_RATE = 0.0001\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagrawal/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: The dimensions are bigger than 2, only the first 2 dimensions are visualized\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('PointContinuousEnv-v0')\n",
    "env.set_curve('S') # Curve: 'S', 'C'\n",
    "env.set_reset_condition('origin') # reset state: 'origin', 'random'\n",
    "\n",
    "agent_net = PGN(env.observation_space.shape[0], env.action_space.n)\n",
    "reward_net = RewardNet(env.observation_space.shape[0] + 1)\n",
    "\n",
    "optimizer_agent = optim.Adam(agent_net.parameters(), lr=LEARNING_RATE)\n",
    "optimizer_reward = optim.Adam(reward_net.parameters(), lr=1e-4, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RewardNet(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "    (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_net.to(device)\n",
    "reward_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of demonstrations:  100\n",
      "Total number of step demonstrations:  10000\n",
      "Testing demonstrations\n",
      "Test case:  0  Reward:  65 info:  reached end\n",
      "Test case:  20  Reward:  78 info:  reached end\n",
      "Test case:  40  Reward:  56 info:  reached end\n",
      "Test case:  60  Reward:  65 info:  reached end\n",
      "Test case:  80  Reward:  72 info:  reached end\n",
      "Average over  5  samples =  67.2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABSWElEQVR4nO3dd3xb533o/88XBxskuLf2spa3LG/H8Y6T2E6cOHaSZty06Upvd2/XbXvT3f7a3nub9LZp0zY7dtzEcRw7jveShyTLlq29RVIU9wCJDTy/Pw5IgSQAghJJkNT3/XrpJQDnnOc8hwTP9zxbjDEopZRS+ThKnQGllFLzmwYKpZRSBWmgUEopVZAGCqWUUgVpoFBKKVWQBgqllFIFaaBQapEQketF5ECp86EWHw0UasERkeMiEhGRkIgMiMg2EfkFEVkQ32cRuVFE2mYgHSMia0bfG2NeMsZccK7pKjXRgvjDUiqHDxpjyoHlwF8B/wP4ammzNHNExFnqPCg1SgOFWtCMMYPGmEeBjwGfFpHNIuIRkf9PRE6KSKeI/LOI+ODM07yI/I6IdIlIh4jcIyJ3ishBEekTkd8fTT+T1v8WkVOZf/9bRDwT0vrNrLQ+m3XsnSKyN1PyaReR3xKRAPAE0Cwiw5l/zSLyJyLysIh8U0SGgM+IyFYReTVTauoQkS+JiDuT9ouZ07ydSeNjE0sqIrJBRJ7PHL9HRO7K2vafIvJlEflxJn+vi8jqzDYRkX/IXNOQiLwjIptn63eo5j8NFGpRMMa8AbQB12OXMNYBlwBrgBbgj7J2bwS8WZ//K/BJ4PLM8f9TRFZm9v0D4KpMWhcDW4E/nJBWRSatzwFfFpGqzLavAj+fKflsBp41xowA7wNOGWPKMv9OZfa/G3gYqAS+BaSAXwdqgauBm4FfylzvDZljLs6k8WD2z0NEXMCPgJ8C9cCvAN8SkeyqqfuB/wVUAYeBP898fhtwQ+ZnWAHcB/SizlsaKNRicgqoBj4P/Loxps8YEwL+AvumOCoB/LkxJgF8F/tG/H+MMSFjzB5gL3ZQAPgE8EVjTJcxphv7xvozE9L6ojEmYYx5HBgGLsjatlFEgsaYfmPMm1Pk/1VjzCPGmLQxJmKM2WmMec0YkzTGHAf+BXhPkT+Lq4Ay4K+MMXFjzLPAY8ADWfv8wBjzhjEmiR2YLsnKdzmwHhBjzD5jTEeR51WLkAYKtZi0AE7AD+zMVLkMAD8B6rL26zXGpDKvI5n/O7O2R7BvsgDNwImsbScyn2Wnlcx6H8469l7gTuCEiLwgIldPkf/W7Dcisk5EHhOR05nqqL/ADmrFaAZajTHpCXlvyXp/Ole+M0HlS8CXgS4R+YqIBIs8r1qENFCoRUFErsC+CT6CfaPfZIypzPyrMMaUFUwgv1PYDeajlmU+m5IxZrsx5m7sqp9HgIdGN+U7ZML7/wfsB9YaY4LA7wNSXLY5BSyd0BNsGdBezMHGmP9rjLkc2IhdBfXbRZ5XLUIaKNSCJiJBEfkAdhXSN40xb2O3OfyDiNRn9mkRkdvP8hTfAf5QROpEpBa7TeObReTLLSKfEJGKTBXXEDD6dN8J1IhIxRTJlGeOGxaR9cAvTtjeCazKc+zr2KWE3xERl4jcCHwQ++c0Vd6vEJErM+0cI0A0K+/qPKSBQi1UPxKREHZ1zR8Afw+M9jj6H9iNs69lqmye5ky7wXT9GbAD2A28A7yZ+awYPwMcz+ThF7DbOzDG7McOQEcz1WPNeY7/LeDjQAg7+D04YfufAF/LpHFf9gZjTBw7MLwP6AH+CfhU5txTCWbO149dXdUL/G0Rx6lFSnThIqWUUoVoiUIppVRBGiiUUkoVpIFCKaVUQRoolFJKFbToJh6rra01K1asKHU2lFJqQdm5c2ePMaYu17ZFFyhWrFjBjh07Sp0NpZRaUETkRL5tWvWklFKqIA0USimlCtJAoZRSqiANFEoppQrSQKGUUqogDRRKKaUK0kChlFKqIA0UCoCecJL+SGrqHZVS5x0NFApjDNvbI+zqiEy9s1LqvFPSQCEid4jIARE5LCK/m2ef+0Rkr4jsEZFvz3UezwdDsTTRpGEwliaa1IXMlFLjlSxQiIiFvXj7+7DX5X1ARDZO2Gct8HvAtcaYTcCvzXU+zwedI8mx111Zr0cNxVI8e3SY4fj0q6Z6w0l+uH+IU0OJc8qjUqp0Slmi2AocNsYczSzb+F3g7gn7/BzwZWNMP4AxpmuO83he6BpO4ncJLgd0DU8OBod64wzG0uzviU877Xe7oqQNHO6b/rFKqfmhlIGiBXu941Ftmc+yrQPWicgrIvKaiNyRKyER+byI7BCRHd3d3bOU3cUpmTb0hFNEk4ZEGk4PJ8heHjeaTNM2lMDpgLbBBCPx4qumEilDX8Tevz+aQpfdVWphmu+N2U5gLXAj8ADwryJSOXEnY8xXjDFbjDFb6upyzpKrMt7tinK0/8zTffdIEgOkM/fwRNr+bNSx/gRpA3V+e6LhA71RWgfjGGPoCCV4ZN8Qh3ujY/ufHIxzLJP+4b4YAJJJv3tEe1UptRCVMlC0A0uz3i/JfJatDXjUGJMwxhwDDmIHDnUWYsk0h3vjHM2qBuocSSIT9tt1OkraGFJpw7H+OEGPg47hJJU+BycGkuw4FWVvd4w32iMY4J2uOCcH46SN4Z3OGHu7Y6TTaY722+0SLUE7yJwc1OonpRaiUgaK7cBaEVkpIm7gfuDRCfs8gl2aQERqsauijs5hHhe0VNrQOZwcq/I5PWyXHkLxNPGU/VnXsF16EGB9rQeAcMLw9ukobUMJYilDwG1/TQYiZ6qdDvbGx0ohADtPRdl9Oko8ZYinDMcGEsRTBp9TqAvYgeJUKEkqrdVPSi00JQsUxpgk8AXgSWAf8JAxZo+IfFFE7srs9iTQKyJ7geeA3zbG9JYmxwtPeyjBttYwJwbtJ/tToTOlh20nR+iPpBhJGAxQ5XVwQa0bt2VvPz6QYFdHFLclDETsYOK2BOfE4kdGhcfBsYEzPZsO9tqlh5ZyJx2ZHk8pYwcrpdTCUtIV7owxjwOPT/jsj7JeG+A3Mv/UNI02PL/bGaXWZ9E1kmR5pYvjAwn6o2kO9MTG9jUi7OmKsbHOy1unoziANIyVPACcYojlKRA4JzxyRJP2jpYDTmfaJiyx20hq/RaeiQcopeYt/WtdxEYSBqcDkmnY2RHNNEpbZGqSxo2Z6I+kONofpyFg2Y3PgN8lvGeF/0x6BQoDvZHcvaEO9tqlCYeA0yGEE4bj/XGGoil+dGCIdh1fodS8p4FiERuJp6n0WqyrddMXSeF2wIHeOInMPX20sOB02E/7aQNtoSRBj/21iCQMJ/vPrQF6tACSNmdKJ8cGE+zpjpFMw/6eGMYYTocS2n6h1DylgWKR6RpJ8sShECPxNOFEGr/LwbKgC7Bv1kOxNBNvx8n0maBxtN/uvQT2Tf7Y4My1KYyeN5KwG9nBzs+BnhivtkXGVYUBY11wkxpAlCopDRSLzPH+ONGkYX93lGjSEHA5OBWyb8rJIu63kYQhFJ/9G3P2GfZlRnwf6YuTyGoTOTGY4LW2yLjuvEqpuaeBYhFJpAynh5NYAieH7OAQTqQ4MRDHn6+70jySNIwNBowk0rxz2h7I1zakgUKpUtJAsYicHk6SMnB5s2/sF3tiMMlwwoy1O8xnToc9J1QilWZXpvEdYDBmGJ7G1CFKqZk1/+8eqmhtQwl8TqG53EmN3xq3zWXN/xJFKm03eL9wbJjOkSRW1rdTe0cpVToaKBaJeMpuIG4JuhAR/K7xgSHX9OHzjcEeIR7KxITR3lkONFAoVUoaKBaJU6EEBliS6eEUyqqq8VhCbIHMx5fdyD0a6tLAYCxNaKFchFKLTElHZqtz91pbmGqvRVc4ScAlVHrt2D8cOxMokqlz78WUiITpT51iWEaIGC9hqwUDuNu3EWioJRCFoNRTVrvknM81amKu20NJ1nusnPsqpWaPBooFLJk2dISS9I4kiafhgho30aThQE+U7Lbfs3kO7zz4EkdNNwcbrqU11kVX2kVC3EB5Zo/MGlJla2DEfukgRn33CZaG32V9NMxa51LqVl91Dld4hs9pVz+NTlyolJo7GigWsKFMqWE0KNQHnBzoiY2bnG86eo68ylvhA2yvXs7J4HKghUAsxEpnkI0Dr9OUclDlKMPbcjUekoizjEjvMcKtbxJatonT/qV0hg9ywN3Edk8lAC2nt3GVO8wlI1XULr38rK81koRIMk37YJyWCvdZp6OUmj5ZbKuObdmyxezYsaPU2ZgVg9EUe7pi1PgtGsqc9I0keLvr3McYHOt8lacinez2bCQlTpYnj3NJ7zFWDcKqaz+N05re80Q6laIrfpz9gwfZmXJz2FqJmDQbk4e4te461roDOBxn3zx2/XI/tX59xlFqJonITmPMlpzbNFAsHPu6o+PWrRYm1+NPx+HQmzwx0s9eVuI3w1wz9A6XDXpYufUj55zXbKc6trPL0c0L6SZCUsEqp4vbTr/O5vX3YDmnf8MXYEuzjyUVrhnNp1LnMw0Ui8CujgiD0RTxlOGGFQE6QgneOh2b+sAcurre5YfmFG+aNVSYAd7b8w5XBa+gYvnGGc71eJHYEK93budp31p6U0k2JvZzt7+JZTWXnlV6W5p9tASdvH06yupqN0Ft6FbqrBUKFFp+XwCMMZwYSOAQqAs48Tod4+ZEKlYsPsxPjv2Qp4NbsGQJH+zfxo31N+G/8LJZyPVkPk+QG5fdzHXpNC/0HORx5xL+Ou7jhuPf433eywk2rppWem+eimCMl+MDCTxOYWOdBgqlZoMGigUgmrRXoUsZGImn6B5OjquCKsbRoaN8K9TOqYqruSq9j7urL6Oy8ZOzk+EpOB0Obq5fz8WH3+Ipx1u84LuUd9NdPHD6JBsbbyw6nTSwp9suVXUOJ9lYB6eHE9T4nAtiJLpSC4UOuFsAwokzfV1DccPLrWGKLVDEwkM8Furj78Jpwg4fP3/yRT7d/H4qPU2zlNvi1a65hAdWfZT/7ujA4RD+kWX8V+/LJNLFd+gdXUlvMJpmKJbi1dYIR/rjxJJpnjgUonVQR3Qrda60RLEARIqZHzyHtle/z8Or1nDAlHFl7F0+7NlMcOtnZjZzWc62cX19w/X8XnKYH/a+zdOJZg73tfKzFTXUuMqnPjjDAO902rPNdoQSWGIHkWP9cZZqo7dS50QDxQIQPouZUw/u+j7/uWIZwybAJ7wOrmu8Z+YzNsFokDibgOF1lvGxhmtZ23OUbyRG+MueIT5XFmdDec62tZy6MmtzD0TTxJJ2lVRvJDW2gJNS6uzoX88CMJKYXqB4bfc3+cfGTbhI89s1S7iucsWM5KMpUPjrsqbaHgg3GiTOppngstpV/MLuZ6hMD/CPwxW81P/s9BPBHqC3ITOKu00nFFTqnGigmGfiKcPELsvFrsUQj0T48b5v8LX6a1iVOs7v1Kxnqevcp7woy9TcdIzkz4cDCMVSVHodODIB4mynmLrg9v/OFxKVXBjfx7djK3i4/VGS8ci001lT7aLKZ9E6EOf5Y8OcHtaAodTZ0EAxjyTThqePDPPyyfDYutUAQ9GpG3cjA11899RjPFZ1LVtjb/PLDTcQcAfPOU9eCy5s9AHglDNfGMeE0sKqajedIyk21Hqo8lr4nYJ3Qm/V6RQwKldcxH+rvoFbUu/yjLWZfzv9NNF4aFp57wglWVLuZChu6I+mOTU0/6daV2o+KmmgEJE7ROSAiBwWkd8tsN+9ImJEpPgK6wWodTBBLGXoCafY1RHNjJ+IM1WBItx1jG8MbOPVwOXcEdnBp5fchdvlK/q8ngl1RBfWe1heYTdfbaz30Fjm4v3ryvnABeU0Be3PAy4H7kwg8LuENdVuBOgKpxiKpagvc3Jhw/g8uKY5zMFTXsm9LXfxgOc4b7s38S9drxAOdRV9/I6OKCartWSgiICrlJqsZIFCRCzgy8D7gI3AAyIyaWiwiJQDvwq8Prc5nFvGGI72x6nwOFhf6+bkYIK93THezqwbnc9I13H+I7KHXd6L+FBkJ3evvA+HVdwducrroLHMIpZVRyTAiio3lzT5uGapn2WZCfjcliAiVGRGP6+qcrGpzq7WWlvjxudy0FTu5GhfnEQaav1OWoLOcQsoxc/yPn1D1U18Jr6XA9Zq/mloNyPJ4quh2oeSYwFtKJYmlV5cMxEoNRdKWaLYChw2xhw1xsSB7wJ359jvT4G/BgrfMRe4vkiKoVialVVu1td6WBJ0crA3XrCePzbYzb/G9rPHvZ77o7u4beVHp3XO9XUeQpkZaAV7zer6gBOnQ3CI0FDmRGR8aaPaZ991K7wWyyrdXN7kZUWlHUxWVbnHnt/r/BYiwqWN3mnlKZ8rl32Az4bf5bhjGf/Yu5twkWMtBqJpEpldDTAYS3FyIE50mh0ElDqflTJQtACtWe/bMp+NEZHLgKXGmB/PZcZK4Wh/HJcDEmlD10iKwBTdOWMjfXxlcDsHnWv4RHwP71lx77TPufNUlJGEwQG4HJBMQ1N54R7TtX6LG1cEqPZZOERYVunGkQkmtX6LcreDcrcDbyb/9WUuPrQhyJ1rywhklS7OZtz0Fas/xC8mT9CeruRLPUeIpKZuczCM76rbPphkZ0eUHaem3ziu1Plq3jZmi4gD+HvgN4vY9/MiskNEdnR3d89+5mZYNJmmfShJc9DFnq4Y21rDHOiN48xzN02Eh/na8Jvsda/n44k9XLs8V0FsamljsAQ2N3jG2kEaywoHChGhymdNKmmMbrtqqZ8rl0xuH/E4HWyos0sXyytd1E/R1TafTUtv5edcnZxMC/800EUsNb2CZlvInvpkKKYlCqWKVcpA0Q4szXq/JPPZqHJgM/C8iBwHrgIezdWgbYz5ijFmizFmS11d3SxmeWYZY0ilDccH7PWu/RMiQ65qp1Q6zdei/ewyq/i44zDXLTu7IAF2CWJDnYcVlW7clr2Mqu8cB6aVuR2U55nFtSXo5NJGLxfWe6n15x4tLYB7iixcVHsDnx3czZFEhH8eOE08Fi46f9FMISSWMuN6liml8itloNgOrBWRlSLiBu4HHh3daIwZNMbUGmNWGGNWAK8BdxljFs0c4icGEzx+KMSx/jj1AYvTw2eqUtzW5NHNJp3mv049xc54gg+VVXJ9/W3ndH6/S1hV5cZyCNcs9XN5c/E9pc6GQ4QVVW5cllCR6Ttb6XGQHZtcDqbs5QVw+QX38snISfYn0nxzpOOsbvraC0qp4pQsUBhjksAXgCeBfcBDxpg9IvJFEbmrVPmaSx2hJMm0PSdRU5mT/uiZO2SuHkLPDDzHc8613BzawW1l1dM614rKM1VKo71hN9V7sTIDIqp81pyu51Djt2gud3J5i2+sMdwSxko0xRRsrln5Xu7xB9geF74/2DbtPHSEdFyFUsUo6VxPxpjHgccnfPZHefa9cS7yNFeMMXSP2DcqS2BvV+FFiN4YPsZ/xVdyReRtPrjkzmmdyyWwud5HpTfBod4YAbewoc5L1cQRcXPI6RCuXOIHoKHMcKgvzroaD+vrPBzoibK3u7hp1G/xVTOAxTPhIYL7vsltG4qfOr1nRAOFUsXQSQFLZDCaHmuDSBkoVAlyKB7h68MJNtDKR32X4vGVTetclV4HLktYWeVmeaULgZyN0aVS6bWoD1g0Zwbzravx0BtJ0zk89Y3ccrn4iKOKoaHdPFJ5FdUnHmXL8uIKpIOxNMaYefWzUGo+mre9nha7zpHi5h3qikf4l/526unlc8GLKG9cUfQ5RquYKnxnngccIvPuxuiyhGuXBcaqvkSEixuKH39hWRafDF7M8vRJvulew7Ge7UUdlzJwfCBGNKFtFUoVooGiRIqZ0XS4v4v/N9gD6Sg/j4+Av3CPrnL3+ABQlRkcVzZVN6J5KOB2UOM7UzU2OgbDl6fPsC9Ywy+4luI3I/xbAnr7Dxd1nrdOx9nermMqlCpk4d1BFriukSQvnxhhKFa4l040NMh/mCTdqTg/232AhsZLpkx7c717rBHYKVDnt0sSCzFQACzPNMBXeh2srbEbvCNJQ40v9/VU1K/lFxNxhgnw1fAJIqG+os7TG0lPmrFXKXXGwryDLDDRZJqOkF2CONAdpTs8dVXHk5F29saj3DfyDusvKm7U9btdibG5mIIeB81BJ3V+i8oSNlqfi6pMlVlL0MWyCjfN5U62NHu5fnmA960pmzTuBGDp8mv5mZ7dHLNW8l/9zxV1HgOcGkrw1JFhTg5Oby1ypc4HGijmwJG+OK+1RUikDL2RqQcJ7Ozaxk/SXq4xPVyztHAPp9FbZYXHQdoYeiJ2EKoP2N1dr1sewHU2KwjNA0GPxVVLfKzOjPW4comfpRVuRASvy8EFtbnX2thy4f3cOvQqr7gv5YXWR4o6177uKMPxNCcGdM0KpSbSQDEHQpkRZMf641MuEXri4NN80zSw3HJwX9V6nG533n3dloylt6baxSVNXio89q+0NrA41oluKneNjfWYqMqXv6R0a+X1bEjs57+c6znw4lenPE+mwEdPEaU9pc43GijmwOgKdfu6C4+VCEf6+HqwBicWn/O78XjzLzzkdwnxlBn7Bb7dGeOVkxGGYmkay5xjs7wuZuWe/F/f8vplvG/PMYJmkK+vuYiud58vOt2zWaNcqcVMA8UsM8YwkrnxTHX7eTiepIMK/pvLRV2gOe9+boddmnBbQhq7+qmp3MXWFh/vX1fO1Uv9eZ/CFxOHyLj1LjbVucbNSrv2jl/mgbdfZEiCPFweIhYuboW8YwPaTqFUNg0UsyycMBSzVs4rnW/xamSY9yU62FDdknc/twP8bgcep4PGMierq1y8Z4WfLc0+WoKuBdsecbaypx1ZXunhng3BcV/qTe/7be7peJF3PJt44dgjRaXZXkTXZaXOJzoye5YNF1GNcbJ7Jw+lfaxLHuQ9rgsK7nvnuvJ5N2CulKq89mSKPqfgcdohotrvoCd85ud+zdr7OdL7LI9WX8maztdZ1XBlwTRHEoZYMj2WnlLnO/1LmGVDscLTUETjQ3w9PoKHGB94ew/BxpV593U75tfUG/PBaDtFZVabzOgkg6N85eV8omoLVaaPf087GElOPS35O51RIroKnlKABopZ1zpYuBrjBx0/pd1awsf2Pc/aDxReo+myWZ4GfCGq8Npf4ewJDptzrNIXqGjh40f3MEAFD/bvnHKAXetQkoO9hTsfKHW+0EAxiwajKQYLjMDedepJXvRcxk2Dr3L5Tb+ec5/R8oMldoO1Gq/MbXF5k5eVVWdKEZYj99d6w3Wf4/0929ieauG1cP+UaZ8KaVuFUqCBYtaEYkleOjGSd3tf7yG+Iw0sTbVyq+finPtYAqPV5PnmOFKwLLNCX7Z8g9Hfu/xuLkgd4cFQH52x/L8fsFfDSxXTE0GpRU4DxSzZ3h4hXxV3OpXiW5FDRPFy965tVK7YnHO/LU2esTQqFug0HKVSmWcciTdYxScGvDhJ8h/DAySmCBanQ9pVVikNFLOkUJXTi6e3sde5ng/172DTB35v3LayrNqlQ/3JsRlUa/zaQW06lgXtH6QlZ6ZbH1W36Xo+Hm/lRCLGT3reKpjOwV6tflJKA8UsGI7lnwaiK5ngB45aNiYPcMPaj00+NnNfCrqFSCJNb2buplq/liimozZgB9bV1W6acjRuX7bsVq70uHjSauRwx8t50xmIac8npTRQzKCReJq3OiI8czR3dUYqleRrA204SfCRSADLlb9x+qqlAW5dXcbFDV6WV7oKTlehJvM4HbxnRYD1tZ68nQA+4qug3GHxbSPEkvmroN7uGCEUtQP2sf44QwUeBJRajPTuM4OO9sc5NpDIO1XH0+F+jiYN9yaO0bT2hnHbBNhQa9/QHGIv3GM5hFXVbi5r8uHQ8RPTVu2zsBxCrd+yl3+dsL3MG+RTFfV0OJr4cf9LedM5OpDildYwoViKt05HOdKn7Rbq/KKBYgYNRfPXZx999yf8aCTEZal2rqi7bdL25ZUuLqi1Z3+9oCb/jLFq+rxOBzevCnDt0snjUDZ4/LzHGuCp1DoOdLyYN41I0rA3M6njkFZHqfOMBooZ1BPO3YCdTMZ4sLYRn8PBfVY9Lt/kG9a6Gg8iwk2rylhfV/x60ao45R6LujIXo4v9ZX/x767YQF26i2/jJp7OP2q7I2SPsg/FUhhjiKcMaV0ZT50HNFDMoHzPmc90/ZSTBLnf66WicfJcTi6HXdWkZl9LpjdU9u/K5/ZxfzJMl9TzWG/+KigDuC1IpCGcSPP0kWEO9mg1lFr89O40Q5Kp3GHidOQIj8k6LvN4uTzYmHOfpRU64nqutARzdzPeuOwmro/v4unkao4Mvpn3+HimHftUKEksZeiPasO2WvxKGihE5A4ROSAih0Xkd3Ns/w0R2Ssiu0XkGRFZXop8FnK0L85jB4Z48fjwpG3JeJRvDLbjlQQfCzZM2u7O9HgdfcpVs6/G76TGZ7G6yk2VZ3zz9j0NN1FDH9+IxAl1HC6YzsnMmhWjqxem0mbK+aOUWqhKFihExAK+DLwP2Ag8ICIbJ+y2C9hijLkIeBj4m7nN5dQ6R5Ik0zCYowbiuf43OcoS7itvImhNHgdxebOPJcHzYzW6+cIhwg0rAlzU6KVxQrdZv6eKB8LddFLP0/6ygukMxe2gEI6nSaXTPHN0mAO9Wg2lFqdSlii2AoeNMUeNMXHgu8Dd2TsYY54zxoy2Lr4GLJnjPE6pL5zMuQ52Z99JfmSauNDt5nJv5djno8+wbgsay1xc0eLXrq8lMjoQL3vk9sbV7+dad5SnI2FODHVPmYYBeiNpRhKGrpHCU8ortVCVMlC0AK1Z79syn+XzOeCJXBtE5PMiskNEdnR3T/3HPVOiyTS51iVKxuN814BFigcCDhxZpYmg274rVXu1eajUKrxOVlS6WD6hjehDFesolwTfDu0hHo9Omc5ogBiIpLT6SS1KC+JuJSKfBLYAf5truzHmK8aYLcaYLXV1dXOWr8Fo7gbsV3teZX8iyT2ufqo849e+vrDBA0C1X9sl5oNLm3y0TAgUAcvJ/b5BTlrLePbgg1Om0TtsVzmlzJk2C6UWk1IGinZgadb7JZnPxhGRW4A/AO4yxsyrlWQGcvR46Rs+ySOOZta4XFxTfuGk7aNjtYI6Jce8UZ6ja/Ilwa1cmtjL4zVXcvrk9oLH92d9K/sj2gtKLT6lvFttB9aKyEoRcQP3A49m7yAilwL/gh0kukqQx4L6IpPrpH84vI84Fh+3HLjckwfObW+3qzJ02vD5w23JpBlmAe5J1+MkyUP0kIznb6jOrmzqDms7hVp8ShYojDFJ4AvAk8A+4CFjzB4R+aKI3JXZ7W+BMuB7IvKWiDyaJ7mSmPj0uKfvFd5gLbcHKmmqnNzcUu4WNtV5WF/r0YWI5hERodw9+fdRv3wrd/W+yT73Bew48FBRaXUNa6BQi09JFzkwxjwOPD7hsz/Ken3LnGeqCPGUoXUwTvYkopHTJ3gQFw2OFLcFKnMeV+t3sq7WMzeZVNMS9DoZTiRITmhiuHbdfWzvepnv125mzaHXqF17VcF0YimIJdN4nFq1qBYP/TafhdfbRtjdOb655CfR7XRTy8crWnDnWbO5LqDVTfNVudsxKUgAuNxe7m/tI4yfx63WyTvksL9nXjWlKXXONFCchd7w+DtK654nedpzMde6Blnn8Y/b5rHOjJ2o01Xq5q2yAp0Lll59HzcPvsGr/svZ+9K/T5lW62BC19pWi4oGirOQfQtIxKM8WOEgIGHurpg84V8yDUuCLq5f7set1RHz1mjPp4o8AeOO6vdQm+7m4dXriA71FUwrkbaDhVKLhd65ztH2E49xxLmaj3gHKXf6J21PGajxW9RqaWJeC7gdeCxhaYVr0gJHAL76pXyk5xgdjmaeO/mjKdM70q/TeajFQwPFNGWPvB3o2Mv3y9ayNn2UK4LXjdvvghonLZkpIqp0Lqd5zyHC7WvKWFPtptLroNZvcd2y8YH/4ovu59LoO/ykZis9ne8UTG9YB96pRUQDxTT1jpypUvhRdB9RfHzMU4tMaMBeX+fD53LgEB1ct1BYDkFEqPI56Y+kyNWD+cOmAcHwvWQ76VT+wXVpY/eOU2ox0DvYNCTThpda7QFzhw4+wTbfpdw8tJ2Wmksm7esQoT+SotJr6aR/C0y1zyJl4JXWyavd1a68ivf37WC3tY53B7cVTOfUkFY/qcVBA8U0jGQGTkRC/TwYCFCT7uG22htz7ts5nGQgmqJKR2AvOKPTvqcM+F2Tg/yNK+9hCR08FPMSSeWfNPBAT1wnCVSLggaKaeiL2qNut7U9Qbu1hA+dfIdATe4Jb99oD5MyUOnTH/FC43fZjdpbmn00lU3uhODyB3mgvIxeqeEnPbvzphNOGp48PMwBHVehFji9i01DXzhF645HeazyIjbH93HJ5Z/KuV9zmcVoN3otUSw8IsKWZh8tQRdL8iyduipwMVeNvMkzporTyfxVTJGkYX+3Bgq1sGmgmIa+cIqfrt5CUjzcm67DcuWeKryhzMVlTT4aAk7KcsxMqhaOSl/+bs13RVvwmBjfHeop3LANWgWlFjS9ixUplkyzbfuD7IhFud1K0bhia959q/0WSytcXLPMj2hD9oLmEOG9K/0EXDJpfEXVpqt5/9C7HIhH2TV8tGA6Tx4O8W5XlGiueUKUmuc0UBTpaz96kkcaV1NjObm1Zk3OfSo84BS0FLHIVHqdbKz3YmDSdOTXLrmTpRY8HIVIMpQ3jXgKDvXG2XUqMruZVWoW6B2tSDs97XRINfeV1+Bx5K6OuHqJn9vWlGl32EWopdyJ27J7QmXzBILc5/czYCyeGng17/Gjx3WGdblUtfBooCjCX/757/CkdxMXygAXeQM59xHA53bq9NKLlIjQEMj9gLAm0MjV3gA/TaygbVfhJVOM0VXw1MKjd7UcJj7xvXLpRlJYfCS4PO8xvhz97dXiUp8VKCo843/f95TX4pEE36/3FFwND6B1SCcMVAuLBooJDvbEePbYCACJlOGv/vp/ssu7mZsT71Lvq8l7XI3O57TojU5F7hBYXeUety1oWdzlS7PPWsvudOFA0amr4KkFRgPFBIOxFEOxNImU4d2uKJvu+W1+Y/gYt1TdkHN/R+bBsjmYu6usWjz8LvvPpcpr0RR0T9p+XXAzS5xOHh7qIprKX2oYSRhdr0ItKBooJogk7D/gkXia9iF7acxVa28nUF6fc//Rv/f6PPXXavHwWILXKTSUOXFbwqZ6D41lZ/6ELBE+5hmgPw1PhvP3gAJ4+kiIdzu1B5RaGDRQTBCK2w2Ng7EUiSm6vHssuHaZnyuX+HA6tI1isRMRbllVxtoauzSxrsbD1pbxU5GvKb+IrfE9PD0yQFe8N29a4SQc7tO2CrUwaKDICMVSPH9smESmQ0rr4NQzf9YHnNQHnDSXa7XT+cJlybjuz1aO9dFv6UpiYfheaKBgWgaIxLW9Qs2Mv/jjX+HPfu9XZiVtDRQZoWiK/mh6bJnTieti51Kjq9YpJq83snTLh/iAJ8K7CeGttx4seOyBCaWKSMJuH1NqOh775kM8e/XVPHbTzTz2zYdmPH0NFBnx9PjAUMxECxVe/fEp2FQ3uUT5nrI1NFouvt94AeH+zrzHtg6cCRTRZJpnjo2wuzP/1OVK5bJt+ADvejZyac9RPvDJ+2Y8/SnvdCLyKyJSNeNnttO+Q0QOiMhhEfndHNs9IvJgZvvrIrJiNvIBcDbDIIIe7RKroLHcM2keKJfLy33lVXQT5PlTP817bNLAcGadk92noyRShlBMB+Sp4v2v3/t5frT2SprSp1i698SsnKOYR+IGYLuIPJS5sc9Iq62IWMCXgfcBG4EHRGTjhN0+B/QbY9YA/wD89UycO5fYNIv7V2kDtsrywQvKmTjR7AZvGZe4LJ6suZK+VP62iNfbwpwaStAeSuJywHBCq57UZMm0YTCamtS1uvXSjXQ76vngvjf4/T/9P7Ny7ikDhTHmD4G1wFeBzwCHROQvRGT1OZ57K3DYGHPUGBMHvgvcPWGfu4GvZV4/DNw8U4Fqomr/9Bqkm7QBW2WxHMKSisljKz5S2YzByff7j+Q9dihu2N4eocLjYG2Nh0TK6HrbapL+SIpnj43QEz5T4vzzP/tNflp7FZdGd/PFL/zJrJ27qEp2Y89pcTrzLwlUAQ+LyN+cw7lbgNas922Zz3LuY4xJAoNA/uHR5yCm0z+rc1SdY3R+jeXi9kCQnUkXh4Z35T02DVzW5KM8M/PwSFy/j2q83rBdKnXImYeIVy6/CIDrdr49q+cupo3iV0VkJ/A3wCvAhcaYXwQuB+6d1dwVSUQ+LyI7RGRHd3f3WaUxMtWgiSzTLHyo80SuQAHw3jTUprt4cDhCMpW/27XXJQRGA8U0vo9q8TLGMBSzZxzuHEmOfgjAH33pT3jTezG39r7GH/zh381qPoopUVQDHzbG3G6M+Z4xJgFgjEkDHziHc7cDS7PeL8l8lnMfEXECFcCkUUzGmK8YY7YYY7bU1dWdVWbaBqYeNzHq+mW5Z5BV5zev04Erx1+Uv6KWu80A7TTywsn8s8se7o0xWrGqJQoFcGIwwTNHR3izI8pAxP5OdI6k+Iv/+av8aMNW6tJdLHtz76zno5g2ij82xuRsSjfG7DuHc28H1orIShFxA/cDE/+KHgU+nXn9EeBZM0uT+ecYN5WX3629nVRuVXlKFRdVv4eN8X382LuewZG+nPsc6kvw0okwAgxroFDAqZDdffrkYGKsy/5wLEXrxuV0OJr5wKHX+eO//JdZz0fJBgJk2hy+ADwJ7AMeMsbsEZEvishdmd2+CtSIyGHgN4BJXWhnihT5d6n9nFQh2WtWZIcMt8/HrUdOEcfND/t25j0+njIYtOpJ2QZyrF3ywrf/kicarmJzbC/Xll0wJ/ko6dBiY8zjwOMTPvujrNdR4KNzkZeBWHH7+bUwoQqoDTiBGG4HlLuF3uiZAvD69/4cNx/8Nj8NXsW1w72sLsvfL2NYx1Io7CV0J3rtknUkcXHTrrf4wO+dS3+i4unQ4ox11cXtVx3QSKHyC3rsdormoIvaQI4R264NVJo+vjf4LtGh/rzpxFLoVOTnudHSZbbDA0d51XMxNw28we/PUZAADRRjeossUVRPHFWlVBaHCDeuDLC53ktdjqnnq1deyr2hVk5YS3nt4MMF09Lqp/PbaHfYUfFYhIeSbqrMEGt27JnTvGigyHBZhVsfnJnN+RorlRpV5rZwWZL3u3Lpyg+wNnmIx1q20tPxTt50tOfT+SmcSLPtZJj2CUvmbhs8TGsyzgePvcIf/cU/zWmeNFBkeJ2FA8BoRyd/rv6PSuXgdAirq92sqR5fBWW5XNyX8BPBz08j+bs2as+n89P+7iidI0naQ2dKFF17X+QxE2CdlWBFTe7VNmeT3vUyggVmBXQ7IJIES8A9RclDqWwXNXjZXO9l4tdmycrruSG0nZd9l3Ok+/Wcx2rV0/np5KAdILKbqJ7y9BAx8FGXh6YLLpzzPGmgyIgWmFtnS4uPm1cFuHaZn1maakotYiJCdY7ucrd7NlFOiP+KD5NMTG4kO96f4GC3PeV4bzjJkPaEWvSGY6lJDdjH9v6YVwIXc6M/yJLKFUyeUWz2aaDI6B6ZPLunBXidQn3ASbnH0oWK1Fmry3x3sh8zKpdfzF2db3PMWsm2Uz+edIwB9vTEiSbTvNoaZo+uU7GoJVKGQxN61cRjYb4X9FIuSd4fqATAlOBZVQNFRl1g8o9iS4uP960t11KEOme1mRLFxKfFrRvvZ3XyCI+5VzISHcx57IvHhkmkoTfH4Cu1OJweTvDYwRDHB8c/sL5+5Pscc67kQ/4K/Jb9sFGK2m8NFBkOa0KDo9h94ZWaCVU+C0sgMKEtzOX28uGeIYYp48eDb+U8drSwq00Wi9e+7slVj8PRbh6tupA1yeNcWdYw9nkp+jhooMhoLnNS4T7zR9wS1GomNXMcIly5xM9FDd5J21Zdci/XJXbzfLqF1njh6iWdDn9xCsUm/15/PPAGYfzc524sea2GBooMn9viptXlVGbWwV6aYxEapc5FQ5kzbzvXByuvooxhvjPYRrrAvJddw4m829TCZIxhYl+ak+G9vGAu4D3hXSytH7/wZ6AEtyYNFBPU+Jy4HFCjA+vULHBZgtNhN2pn//GVB1u4K93KsZSD19qfzHv8/p7ip8NXC0P3yPi2p1QixneHeggyxB3eyV1h60qwII4GignW13l4z4oAlq6HrWaJz+Wg2mdR5x//53dN452s4yQ/sJoYHGrLeexwwvBWR4SQdpVd8IwxdIQS7O+OjPt8W9/zHGMJd6VOEWzZMOk4b4ExX7NFA8UEbkso92hpQs0ev1NIGYNzwsOIw7L4qL+OMH5+NPBG3uOPDSTYdjIM2BMHztISLWqWvdMV5bW2yLgZhgf7TvBD08T69FG21t+W87iByOSu/LNNA4VSc8zrchBJmJwjr5cEN3GL6yjbXBdxaM/jOY62hZOGkViSF0/Yq5+phadtcPIN/0fxvUSNlw8nfDjduRsjvM65v21roFBqjvmcDmIpQyieuyRwR8XVVDLI9yr9JNP5q5je6YoxEE0zENVqqIWiP5LiJ4dCDMfTxCa0YB868SyvcAE3m/0sXX5t3jRK0QFKA4VSc8yXqWNOmdyDp3yuIB8LxGi1lvF8b/5JA09nGkGHY2mtflogesJJIknDgQntErGRQR70eKmllzvqbsp7fJVH2Fw/uYv1bNNAodQc82VVHZS7c/8JXhi4kgvNYR5LuRlI5a6THo0NaSCW1ECxEPRl1pg4OTS+FPhC99O008i9ZgCfqyzv8f0xQ1d47kuQGiiUmmO+rF4rtVnjKrILFw7L4qNV60kD3xvqnTLNUGzuGzjV9HXnuMl3HnmVH3s2cpkc4ZKmW6dMo6wESx1ooFBqjo2WKPwuobn8TA8774TOdnXeZdyZOsCbsRF29xwsmGbbYILt7eGcU0Go+cEYM2kaltjICP/l6kUw3ONaUlQ62etUzBUNFErNMZcluBwQ9FhUZi2tm2vOv1ua7qDJkeTBtJPwQEfeNFuHUrQNJTner4Fivso1qeO7Jx/nHfdG7vZ0UFc9eczERAJjs0fMJQ0USpXA5gYva2vcWA7BU2A6UKfDzcfLfPSl4Ynel/PuN3oLiqYgmdb2ivloX9f4bszDpw7zcOUqlqVbuaGy8Kp1o01ZIpRknJcGCqVKYEWle6x94uZVAcrcDvJNBrDGv5TrfOU8G7iUYz07pky7P6zzQc0nXcNJfnxwiJ7I+HqnH0XeZJAgH3f5sRy5p+UY/UpYluB2jF/1bi5poFCqxDxOBxc1eMduArmeF+8pqyIgwoPUF5w0EKBtKMmJgTinQhow5oO3OyPEJ9Q6HT3xPC/5L+O94V0sr7si77Gjpc1owtBQ5sTvEsIlmG++JIFCRKpF5CkROZT5vyrHPpeIyKsiskdEdovIx0qRV6XmQkOZk8Yyu4TRUG5PTJktYDn5aLCWE8kkzx5/pmBaxweTvNkRZeepSMH91OxLpg3DEwZWJlIxvuNxUUk/d9bfWPD4aMrgEHvBqyVBF7etLhvXU26ulKpE8bvAM8aYtcAzmfcThYFPGWM2AXcA/1tEKucui0rNrQsbvDjEvrk0lE2+GWzxlLM5vo8feZvpOZ1/IN6oZBrSaV2/ohSGokleOTHMtpMjk7Y9NXSSNpp4wBUhUF5fMJ2rl3hZFnRiCdQFnCVbl6JUgeJu4GuZ118D7pm4gzHmoDHmUOb1KaALqJurDCo118rcDi5s8NI1kso5gE4cDj7mXoYDw3cSx0klpq5aGoimdNR2CeztitEVTtM7oV2iI9bJ4zGLK6SdC2sLN2CDPc6mcyRFfcBZ0hmtSxUoGowxo339TgMNhXYWka2AGziSZ/vnRWSHiOzo7u6e2ZwqNYdWVbm5oMadc2AWQG3jhdzVs4O9rvXsOP7olOkd6Inz0okRdrbbs82GE2kiuqbqrOvM8ftLJeN8q38/XnFwb6C4rrAnBu0pP3KVMOfSrAUKEXlaRN7N8e/u7P2M/biT95FHRJqAbwCfNcbk/IYbY75ijNlijNlSV6eFDrWwbajzsLzC7gUT9Ex+irzugo+xOnmE75WtYWCos2Bap0dS9EbSnBxKMhxL8crJMDu07WJWGGMIxVKkUqmcvZNeCb3MEZbyEaehoqy2qDR3d0ap9lksCc79YkXZZi1MGWNuybdNRDpFpMkY05EJBF159gsCPwb+wBjz2ixlVal5RUS4pMnLYGz0hjP+ruNye7m/L8Vf13l5aGgvP1deX1Td9XPHR0imIZHSRblmUiptsBxCeyjJ9vYIuVZR7urZw/eTjWxK7OOK2tuLStchsKXFR1NZ6domxvJSovM+Cnw68/rTwA8n7iAibuAHwNeNMQ/PYd6UKjmHCC3lLoZiaXKNr1py0R28f2A7u5zLeTM6ucE0l1SmPB5LGRITF2lWZ6UjlODRAyH2dEXpy4xfGZywWm08FuE7yU7EGD7S68RyFvd8vrLSRXO5q+RBAkoXKP4KuFVEDgG3ZN4jIltE5N8y+9wH3AB8RkTeyvy7pCS5VaoERuulA3lmmL1p+T2sSB3nu0NdDMaHp0wvOzQM6VKqM6JrxJ536WBvnGMDuedgeqXtJ+xnBfeG99N4ydSliVq//WRQV+J2iWwlCRTGmF5jzM3GmLXGmFuMMX2Zz3cYY3428/qbxhiXMeaSrH9vlSK/SpVC0OPA55S8o3Hd/jI+1j1MxBgeChXXiWP02fRAT4xwIl2SwVuLSX80TY3fYmuLL+fvqXu4jx/6L2CTHOfK5junTM8h9uJGZW4HNb7zPFAopaYmIjSUOQnF7Jt5rgqIFZfcxZ3pPt5MGF4/+diUaY7ey7pGUrx0fJg32rVh+2yljWEwmqLKa+UMuKl0mm+NtCMYHihfjcvnKyJNKPc4uGG5H1eBOcDmmgYKpeaxhjInKQNOR/4qqJsr1rHc5eF77hUMRvLPMJvNAOEkDERSpHQSwWkxxm7jGYqlSRv75v5u1+RZe1+IhDhgAnzU20WNf3lRafudwnXLAnhKsC52IfMrN0qpcer8TgSoDzgJ5FmwxhOo4DMVdcRx852hPaSSxa9XYIChmFY/TUd7KMnjh0K0DdqN18f645P3Ob6LR0J9XJg6wtUV75kyzRWVdvfX9XWeeVWSGKWBQql5zGUJtX6LoViavmgKvzP3TaTR6ebDfsPbZhUv7/tuUWmPptQf1Ybt6egcTpI2cKTPDhATy2PJVJRv+AO4Jc0DFRcgjsK3WZfjTMeFYAmmEC+GBgql5rmGMifD8TSJlKGlwMCr6wNruCBxkEdqL6XzyCtTpuvPLMk6kGvFJJVXTziJJfZa5bk81f8SJ9JO7k8OU1W2bMr0Vla6aCpzcsNyP1U+DRRKqbMw+rTpEFhTfSZQVHrG72dZFg90CQ7SfMMTIREpPL4inLCfhfsiut52sWLJNOGEId8wlGP9O3ksuZIrvGVsabm4YFo1Pgu3AzbUexERakowK2yxNFAoNc+Vux2UuR00BJx4XRYO7K6zlzX7J+3bcPntfKzrLY44V/GTEz8omO7ovS4UN7oq3hRSaUP3SDLncqajIskh/iOapEoS3F9eM2Wa/dEUSyvdOObBgLqpaKBQap4TEa5f7ueyZrt7ZaXPbrN4tTWCxxLKJtRGbb34Z7gy/CZPVFzJwd2Fg8WoQW2nKOj1tjAvnwzTPnHYdZaH+16jh2o+G2zEbxWuQrLE7i1VH5ifVU0TaaBQagHwOh24M71hrl7q59ImLxVei0TagDiYWGvxgeRyak0vX69tZrjtwJTp7+uOcqDH7uKZNkanJseuZmodTGCMoXPEDqRtodwBdcepJ9mWXsP7QrtY7Zu0DtsklsPuTFCKRYjOhgYKpRYYtyWsqHRz9VI/W5p9DMfTtJSPfzKtXXcF9x18k36p5jvJvSSnWLuiO5zmcF8cYwxvnoryapsOxDvaF2fHqQh7OqMF92vb9jDflhbWmBPc2nJHUWmnDdT4LZwlXGNiOjRQKLWANZc7qfA4aA9N7oOz+cZf4q7+V3nTezEvHp66y2w8ZRiKpWgPJegeSZ73pYq2ITu4HurPH2R7j+7iG8trcUiaTzka8AaCRaWdTNtjYxYKDRRKLWAiwvo6D+GkmbTONsB7lt/D5vheflC5lSPdr0+ZXttQcmy0cd953m12ODF1oHwquZ+T1jI+G4hQ17Cx4L71PhmrPgQNFEqpOdRUZpcqcnVc8gaC/Ix7PeUM8/VEmqHOowXTOtZ3prF29xRVLotZuojS1PY3v8YLwSu5LfkOm8qvLLivU+CKJQGqffYt120Jld6Fc/tdODlVSuUkImyo85AyuScODDau4TOeBnqklm/H95CI5w8A2Q/RA9H0eTcdeSKVonM4QV+48NiStuOv8O2my1mVPs0Hmz8wZbq3ry3H7XRQ5s5MIe635sU6E8XSQKHUItBY5qTGZ9FQlru75brqJdwTO8Dbrk08dfihotN98zxYNjWeMpwettshXjkZZVtrhL3d+YPpSLSPf3cbXKT4XO1lOB2Fu7jW+a2xKqfR+brq59FaE8XQQKHUIjA61uLKFl/OFfEAblpyB1sSu3ms6hr2HXmiqHT7o+kpn64XuiN9cV5tjdARShCK2yWo3kjuqqdELMY3e16hUxr4b/46qt3eKdNvCZ4JCrUBi0qvg0YNFEqpUhARHA4HDWUuBCbVgVtOJw80vJfm9Cm+6m+h89jUjdsA29vDs5Db+aMnEwh3d0ZJTjGR7k/bfsBbzk182J9kfUVzUelXZy1AFPRYvHdlGd55No34VBZWbpVSU2oIODFAWY5uUH53BZ8etKuTvuKOM9xzYsr0wknoHknw/LFhXmudHDQSKUNsqjvsPJU2Zqx3V3iKXk47X/oSP/Zv4QrnIO8tv6Co9B1iT7ey0C38K1BKjVOXmRaiLZQkVy3U0o2389mu/XQ6Gvha+B3i4anX2375ZIT+aJqOYXt8RddwgpMDdg+pNzsiPHdsBGPsgDESXzhBY3TxIYA860IB0NrzJt9YewvLXBafrLkYxxRTh9f77TaJoMexoBqt89FAodQi43E6qPZZlLkdNJfnbrDYdPF9fCTdybvujTza9ui00h+KpXmtLcKbHVHS6TQdoSSRpKFrJMnOUxG25Sh1zDfhRJpj/XG6R84MpssX39r3P8c/p8rwOnz8QmUzbpn6thlLCQLULaCxEoUsjqtQSo1z9VI/AhwfiNOaZ36iG1uup3Ooh2e4isae57iu9r1FpX24NzY2zXbrUGJsFtoDPXF6IykEe7nQ+fYkbYwhbcByCMf6YhzsS1A1xViG4f7TfKt2DaFkkt+s8FDp9BTcH+wxE0OxNAaonqfrS0yXliiUWoTcluCyJO8626PuDVSw2e3l28nlvD30TlFpnwqd6QV1tO/ME/noFNwGiCbn3/QfR/rjPHF4mETK0DliX8NANH81WTKd5uvA8WScT7a9xHJvY1HnWVLh5IoWHxUex4KZ9G8qGiiUWsRyNWhnc1ouPhsIsNyCr4YDHDzy1JRpZseAwQnrbY+WIcKJ+dVOkTaGQ71xEilDTzjJUMy+iHzhLJVM8t3OnbwTC3Nf98ts3fKpKc/hyyxT21TuoiXo4qZVZeOm7FjIShIoRKRaRJ4SkUOZ//POyysiQRFpE5EvzWUelVoM/FOUKAD8ngo+7/dTZTn5SmAZJ3c+UnT6E2+0o70+p+pBNJt6w0l2nIoQTabpCCXYdnKEU0OJsVJO+1A8b4AY9eND3+EVqeGOwW3ceOGnpzxnmRMuafTitoQq7+KobspWqhLF7wLPGGPWAs9k3ufzp8CLc5IrpRYZp0PwFPFUWxVo5AsVFTgdHv6peTkdb/zorM43WpAIJ9J0jSQ52pd/oZ/ZcrgvTutggueOjfD26SidIyn2dccY/TG0DRWeluSn7Tt4oupargnv5P0rPjrl+TyWcN3yAI3lLt6/rhzPAhsjUYxSXdHdwNcyr78G3JNrJxG5HGgAfjo32VJq8anwOqjwOKachK7OXcGvVjWREj9fWtpET3jorM4nQCSR5lBvjN2d0TkdY5E2du+rWr8Dh0AkU4oYzlrnulBp4vmRQX5gVXN55G3ub7oTp6dw47XfJdy+pgyfe/GVIrKVKlA0GGM6Mq9PYweDcUTEAfwd8FtzmTGlFputLX6uXx5gdbV7yn2bXB5+pWoZUUcl/2dkgM7W4hq4sxlgOJZiIGr3/OkIJQkn0vRFip8K5ORAnNfb7G62JwfjbDs5ucvtqVCC11rDGGM4ORDnheMj9EVSJNMwFDNcs9Q3rXy/dOIVHgz1cnH8AJ+svAaXLzDlMdcv82MtkMWHzsWsBQoReVpE3s3x7+7s/Yy9OkquIP9LwOPGmLYizvV5EdkhIju6u7tn6AqUWhxcmR5QLeUu3JbknGE22zKPj1+pWsJIKsyXrDCnBvZO+5yD8TTxzCN861CCd7uibDsZLnoxpCP9cU6FkozE07QNJukcSRKZ0EB+oCdGx3CS7pEkb3dG6Yuk2H3aHnUeTxnaCqxvPdGzu/6db3ua2OR08CnfJrxVk55dc/Iv8pLEqFnru2WMuSXfNhHpFJEmY0yHiDQBXTl2uxq4XkR+CSgD3CIybIyZ1J5hjPkK8BWALVu2zL9+eUrNA5ZDuHqpn7Yhe1R1oY5JK9xefvn42/y/5ev5x0iYX+x8hmUX3Fz0ueJZzQA94RQBl5BI291RA24HsWSa8jyzF8aS6bFuq6dDcXozJZH+SIqBaJLj/QmWVrgYzOxzsDc+NkfTYOzMn/+RvuJKME8e+x6PNN3IxS4Xn/KU4S8rvOa1A0gDfufiL0mMKlXV06PAaFeCTwM/nLiDMeYTxphlxpgV2NVPX88VJJRSxav2WVzU4GVNEdVQq6/6GL927DBpHHwpWMPBl//zrM87kukF1RNO8kZbmBdPhMem/BiMjm9c7g6feX9qODkWBE6FEmxvj3J6JMX2U9Gxaojs/bNN1fEqlUjwaM+TPOK7nCti+/m56iVTBgmwgwRA5SLs3ZRPqQLFXwG3isgh4JbMe0Rki4j8W4nypNR5Y3Q+qKksueZefjWVwmNifHn1Vt5uffacznuoN0Z3OEU8ZRiIptneHubZYyO0DsY50htl28lhTofOVBn1hc8Ue04NJccapM9VuPcU3+x9hieSa7k+vJNPNd+CNc2R5MEFtELduZLFtoD6li1bzI4dO0qdDaXmtUTK8NjBEAGXcEmTj1dyNBZn6x06xlfDrRw3zXzEa3FT1cpzzsO6GjcHeye3I1jCjAWEXAZDrfzb4H4OO1dzT3QXt7TcheVyFXWsxwKDEE8ZLm/2sqxi6pLZQiEiO40xW3JtO39ColJqjMsSfE6hymdRH3DSUu4seDOoCa7k1+q3cKnjKN+LGb4x2E00cnbdZ0edGMjd2DxVkDiXloFjB3/C34XaOWEt5fO+09y+4t6igwTY1U0NmUWHAlOMel9Mzp8rVUqNU+O3aB9K0j6U4IoWHxc2FB4z4Hb4+YTvUu50HGZbJMTfD7Vx+u2nz/r8Z7sc99kUNtLJJC+983X+oXwFSXHya94RLq24pqhjHcBoTGgJulhe4aLM7SCYbynBRUgDhVLnqUsafVT5LLa3R2gPJan0Td0J0h+s44P1t/HL5R568fM3javZ3t9KKjl/l0sNhdr4RtujfLvuOtYkjvLrIwlWVV1e9PFBr4OtLT4CLqG53EVdwMmtq8twLZJ5nIqhbRRKnccSKcOrbWF6wymcDqZcCjRbT6yTfx84zTFTzmUeH/fFQlQ0rpu9zJ6Ft9p/ykOOKgao5H2Dr3HHintxef3TSmNFpYtLm6Y3eG8h0jYKpVROLku4ZqmfhoCToMei3FX8U3Ktp4Ffr7qAu0f2sTsW4c9J8MbAi6TTZ1mnNIMGOg7wjWMP8y/WGrwmxm/27eeD639mWkHCmxknUbNI1pQ4F4tjsnSl1FlzOoRrltk30P3dUfb1FD+i2eX2csfq97N5uI9vheP8R3QJL4Rf4r7KWpb7N89WlvOK9nTwYt+L/KR8E3HvRdwSf5MP1N+Gpzk4rXScAvUBJycHE3kHBp5PNFAopcYsrXBNK1CMWlJWzW/5K9k5tI0fRMr5qyE/l4ae5rZAAyvKLpyFnI4X6jrJzraneKZxMz3BK7hYjnJPYDmNZR85q/SWlFssqXARiqUJerTiRQOFUmqM/xy6fFoOB1srr2N99Cgvj+zgucB6dg0HWD/wU67tPs2FGz+Mx1M2g7mFoy/9B/svvJ3nTYxQ83tZlTrGJwIW68vzziBUlCWVHuoCTm5cqbdI0EChlMoiIgQ9DkbiacrdDgZi058iPNi4ijtZxY2xfl7ueoHnnUv4atMaAv0nuNxXy8VOF6ssD17v1LOz5tI70sl+8bG9/w0OrrkeE42y0eXjtr53WbvyFhzOc7utVXodi2at65mivZ6UUuOMxNOkjaEnnOKt01HArrM/22WwE9EI+zv38EZwCW/HRkgguEycVaafpYFVNLm81MbaKEcI+Bvxu6uIjfQxeHQHjo3vpav/AN0D++iovoJDKUNXJnbVpzvZMnSEK5wX0Ljmihm59quW+GgqL34A3mJSqNeTBgqlVE7RZJonDg0D4HMJkRlY3nR44BSt5gR7+1o54K2nw2oiSXE35gAxVnqqWO/2si41RLO/GescSw/ZBLhrfTmOac75tFgUChRa9aSUysnrdFDjtxiKpohlihPTHWsxUVllMxtoZkPV1QAk41H6evbR0b2PYRKkli1lOF2J07sKj0njSQ5SeXw7LS1bKK/bkJVS5dlnIo+gx3HeBompaKBQSuW1tdlH50iSNzvsKqhlQSdHB2ZuFLbT7aW++VLqmy/Ns0c1XHLuExAWoyWot8N8tN+XUiovr8vB0goXLoc9q2vr0PydqmM6KjJdXn3OMzfB+sD52TZRDA0USqmCHCI0ltk30WTaDhhwZqK8iVZVzv8n82QqjSVQX+ZiaYV9bb5pjEo/32igUEpNqancScrYM7durPNgCSTSdldSALd15mYyeBZdaueSxxJGkvZ05rV+iw11Hi5u9OJ16u0wH/3JKKWm1FDmxJF54G4OuqjwWgiMLal6eZMPd2ZupL5IaQPFknKLGt/4W1vQLWP5bwhYNATsUk+t34nP5WBV1eJZgGg2zP8yolKq5JwOoaXcxUgijd/lYH2th0gyTV3mhjuSMJS7HUSTqbNaL2Imra/z8lpbBDizWt76Wg/7e+MMxdK0BF1U+Sx6wqlzGol+PtFAoZQqymXNXkaHXY2u8maMwemwB+nV+i26w/bMsQ6BdIkixvb2CMPxNF6nsLTCxdG+OI3lTlLAvu4YdQEnlkNoCWqQKJYGCqVUURwik9YhFRECLgdd4STerPtupdfBYDRNysCtq/w8dyxc1Mhu4exWsBtV67fozQSrOr/F5novm+u9ACyrcC+qNa7nkoZUpdQ5CXosQrE0Q/Ezt/imMhcrq1zU+izKPE5WVrnwWuCeYlW4sw0So6k2lDm5KLOka1O5PgfPFP1JKqXOyUWNXtbVuCn3OHj0QIi0gWq/Ra3/zBrcm+q9bKr38mZHlJODCQCCbhjKzGjuyoz4NoDPKUTyFD+uXerjUG+M7nB6LKgIUBew6BpJsacrxmjnpQqv3t5mipYolFLnxG0JQa9lzzzrtp/tKyYs9iMiiMhY2wZAbdYAtyqfRVVmxtZLGr1jn1dm1WdVeBzUl7m4dnkZS7JGUQc9DrY0+7hyiY/LmrxU+SyqfRYBHRcxYzTkKqVmTIXPSZoUrjxVTPWBM7ecxoCTo/126aKp3IUALoeMdcVNG1he4WIoGiMNLK88E1hWVbvHRonXB5x4nA6ay+2gsrxS2yFmWklKFCJSLSJPicihzP9VefZbJiI/FZF9IrJXRFbMcVaVUtNwUYOX65blX5fabQnVPnsMRm3AiScTUKq9Fiur3FyzzD+2JgbYwWF0bYglwawSiNcaa+/ILqWo2VGqqqffBZ4xxqwFnsm8z+XrwN8aYzYAW4GuOcqfUuosOB2CZ4oRzutq3Kyv9WA5hKpM0CifsNzotcv83LwygOVwcHmLj6uX+salKyIsr3DhdKCLDM2BUoXiu4EbM6+/BjwP/I/sHURkI+A0xjwFYIwZnsP8KaVmSVO5i6Zy+/XaGjf1mXEN2dyWA3fm/u93OXIOjNtQ52F1tXvSsWrmlapE0WCM6ci8Pg005NhnHTAgIt8XkV0i8rcikvPRQUQ+LyI7RGRHd3f3bOVZKTXDav1OVlefXZuC5RB8OrJ6TsxaiUJEngYac2z6g+w3xhgjIrn6wjmB64FLgZPAg8BngK9O3NEY8xXgK2CvcHdOGVdKKTXOrAUKY8wt+baJSKeINBljOkSkidxtD23AW8aYo5ljHgGuIkegUEopNXtKVW57FPh05vWngR/m2Gc7UCkidZn3NwF75yBvSimlspQqUPwVcKuIHAJuybxHRLaIyL8BGGNSwG8Bz4jIO9gDMP+1RPlVSqnzVkl6PRljeoGbc3y+A/jZrPdPARfNYdaUUkpNoF0GlFJKFaSBQimlVEEaKJRSShUkxiyuYQci0g2cOIckaoGeGcrOQqDXu7idb9cL5981z9T1LjfG1OXasOgCxbkSkR3GmC2lzsdc0etd3M6364Xz75rn4nq16kkppVRBGiiUUkoVpIFisq+UOgNzTK93cTvfrhfOv2ue9evVNgqllFIFaYlCKaVUQRoolFJKFXReBgoRuUNEDojIYRGZtAyriHhE5MHM9tcXw1rdRVzzb2TWJd8tIs+IyPJS5HOmTHW9WfvdKyJGRBZ0d8pirldE7sv8jveIyLfnOo8zqYjv8zIReS6z6NluEbmzFPmcKSLy7yLSJSLv5tkuIvJ/Mz+P3SJy2YxmwBhzXv0DLOAIsApwA28DGyfs80vAP2de3w88WOp8z8E1vxfwZ17/4kK+5mKuN7NfOfAi8BqwpdT5nuXf71pgF1CVeV9f6nzP8vV+BfjFzOuNwPFS5/scr/kG4DLg3Tzb7wSewJ5l+yrg9Zk8//lYotgKHDbGHDXGxIHvYq/hne1u7LW8AR4GbhaRhbww75TXbIx5zhgTzrx9DVgyx3mcScX8jgH+FPhrIDqXmZsFxVzvzwFfNsb0Axhjci0WtlAUc70GCGZeVwCn5jB/M84Y8yLQV2CXu4GvG9tr2Gv5NM3U+c/HQNECtGa9b8t8lnMfY0wSGARq5iR3s6OYa872Oeynk4VqyuvNFM2XGmN+PJcZmyXF/H7XAetE5BUReU1E7piz3M28Yq73T4BPikgb8DjwK3OTtZKZ7t/4tJRkPQo1f4nIJ4EtwHtKnZfZIiIO4O+x12A/Xzixq59uxC4tvigiFxpjBkqZqVn0APCfxpi/E5GrgW+IyGZjTLrUGVuIzscSRTuwNOv9ksxnOfcRESd20bV3TnI3O4q5ZkTkFuAPgLuMMbE5yttsmOp6y4HNwPMichy7TvfRBdygXczvtw141BiTMMYcAw5iB46FqJjr/RzwEIAx5lXAiz153mJV1N/42TofA8V2YK2IrBQRN3Zj9aMT9sle0/sjwLMm02K0QE15zSJyKfAv2EFiIddfwxTXa4wZNMbUGmNWGGNWYLfJ3GXsFRYXomK+049glyYQkVrsqqijc5jHmVTM9Z4ks4qmiGzADhTdc5rLufUo8KlM76ergEFjTMdMJX7eVT0ZY5Ii8gXgSezeE/9ujNkjIl8EdhhjHgW+il1UPYzdgHR/6XJ87oq85r8FyoDvZdrtTxpj7ipZps9Bkde7aBR5vU8Ct4nIXiAF/LaxlyRecIq83t8E/lVEfh27YfszC/lhT0S+gx3oazPtLn8MuACMMf+M3Q5zJ3AYCAOfndHzL+CfnVJKqTlwPlY9KaWUmgYNFEoppQrSQKGUUqogDRRKKaUK0kChlFKqIA0USimlCtJAoZRSqiANFErNMhG5IrNGgFdEApn1IDaXOl9KFUsH3Ck1B0Tkz7CnkfABbcaYvyxxlpQqmgYKpeZAZk6i7dhrX1xjjEmVOEtKFU2rnpSaGzXYc2mVY5cslFowtESh1BwQkUexV2JbCTQZY75Q4iwpVbTzbvZYpeaaiHwKSBhjvi0iFrBNRG4yxjxb6rwpVQwtUSillCpI2yiUUkoVpIFCKaVUQRoolFJKFaSBQimlVEEaKJRSShWkgUIppVRBGiiUUkoV9P8DqbkQqV7NyLcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grl = GRL(env, noise=0.03)\n",
    "demonstrations, XStore_steps, AStore_steps = grl.get_demonstrations(Ndemo=100, Kp=-100, Kd=-3)\n",
    "grl.test_demonstrations(demonstrations, Nsamp=5, render=False)\n",
    "# demonstrations['states'][0][:10], demonstrations['actions'][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: reward:   1.00, mean_env_reward:   1.00, mean_net_reward:  58.77, reward function loss: 0.0000\n",
      "2: reward:   3.00, mean_env_reward:   1.50, mean_net_reward:  59.17, reward function loss: -0.0322\n",
      "3: reward:   2.00, mean_env_reward:   1.60, mean_net_reward:  56.01, reward function loss: -0.0369\n",
      "4: reward:   1.00, mean_env_reward:   1.50, mean_net_reward:  59.21, reward function loss: -0.0779\n",
      "5: reward:   1.00, mean_env_reward:   1.43, mean_net_reward:  56.13, reward function loss: -0.0720\n",
      "6: reward:   2.00, mean_env_reward:   1.50, mean_net_reward:  54.79, reward function loss: -0.1084\n",
      "7: reward:   1.00, mean_env_reward:   1.44, mean_net_reward:  55.75, reward function loss: -0.1224\n",
      "8: reward:   1.00, mean_env_reward:   1.40, mean_net_reward:  52.04, reward function loss: -0.1397\n",
      "9: reward:   2.00, mean_env_reward:   1.45, mean_net_reward:  49.63, reward function loss: -0.1723\n",
      "10: reward:   1.00, mean_env_reward:   1.42, mean_net_reward:  49.28, reward function loss: -0.2147\n",
      "11: reward:   1.00, mean_env_reward:   1.38, mean_net_reward:  46.57, reward function loss: -0.2131\n",
      "12: reward:   1.00, mean_env_reward:   1.36, mean_net_reward:  44.40, reward function loss: -0.2349\n",
      "13: reward:   1.00, mean_env_reward:   1.33, mean_net_reward:  45.87, reward function loss: -0.2599\n",
      "14: reward:   1.00, mean_env_reward:   1.31, mean_net_reward:  43.65, reward function loss: -0.2050\n",
      "15: reward:   1.00, mean_env_reward:   1.29, mean_net_reward:  41.59, reward function loss: -0.2158\n",
      "16: reward:   1.00, mean_env_reward:   1.28, mean_net_reward:  40.52, reward function loss: -0.2587\n",
      "17: reward:   2.00, mean_env_reward:   1.32, mean_net_reward:  40.25, reward function loss: -0.2852\n",
      "18: reward:   1.00, mean_env_reward:   1.30, mean_net_reward:  38.66, reward function loss: -0.2437\n",
      "19: reward:   1.00, mean_env_reward:   1.29, mean_net_reward:  40.84, reward function loss: -0.2634\n",
      "20: reward:   1.00, mean_env_reward:   1.27, mean_net_reward:  40.60, reward function loss: -0.2010\n",
      "21: reward:   1.00, mean_env_reward:   1.26, mean_net_reward:  39.77, reward function loss: -0.1660\n",
      "22: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  38.99, reward function loss: -0.1929\n",
      "23: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  37.90, reward function loss: -0.2720\n",
      "24: reward:   1.00, mean_env_reward:   1.23, mean_net_reward:  39.23, reward function loss: -0.2917\n",
      "25: reward:   1.00, mean_env_reward:   1.22, mean_net_reward:  38.47, reward function loss: -0.2291\n",
      "26: reward:   1.00, mean_env_reward:   1.21, mean_net_reward:  37.58, reward function loss: -0.2235\n",
      "27: reward:   1.00, mean_env_reward:   1.21, mean_net_reward:  36.87, reward function loss: -0.2591\n",
      "28: reward:   1.00, mean_env_reward:   1.20, mean_net_reward:  35.80, reward function loss: -0.2927\n",
      "29: reward:   1.00, mean_env_reward:   1.19, mean_net_reward:  34.81, reward function loss: -0.3036\n",
      "30: reward:   2.00, mean_env_reward:   1.22, mean_net_reward:  33.88, reward function loss: -0.3335\n",
      "31: reward:   2.00, mean_env_reward:   1.24, mean_net_reward:  33.47, reward function loss: -0.3393\n",
      "32: reward:   3.00, mean_env_reward:   1.29, mean_net_reward:  35.17, reward function loss: -0.3170\n",
      "33: reward:   1.00, mean_env_reward:   1.29, mean_net_reward:  34.87, reward function loss: -0.1872\n",
      "34: reward:   1.00, mean_env_reward:   1.28, mean_net_reward:  34.03, reward function loss: -0.1897\n",
      "35: reward:   2.00, mean_env_reward:   1.30, mean_net_reward:  33.40, reward function loss: -0.2466\n",
      "36: reward:   1.00, mean_env_reward:   1.29, mean_net_reward:  34.19, reward function loss: -0.3182\n",
      "37: reward:   1.00, mean_env_reward:   1.28, mean_net_reward:  35.16, reward function loss: -0.2371\n",
      "38: reward:   1.00, mean_env_reward:   1.27, mean_net_reward:  35.18, reward function loss: -0.1707\n",
      "39: reward:   1.00, mean_env_reward:   1.27, mean_net_reward:  34.44, reward function loss: -0.1798\n",
      "40: reward:   2.00, mean_env_reward:   1.29, mean_net_reward:  34.30, reward function loss: -0.2524\n",
      "41: reward:   1.00, mean_env_reward:   1.28, mean_net_reward:  34.37, reward function loss: -0.2739\n",
      "42: reward:   1.00, mean_env_reward:   1.27, mean_net_reward:  33.96, reward function loss: -0.2472\n",
      "43: reward:   1.00, mean_env_reward:   1.27, mean_net_reward:  33.55, reward function loss: -0.2494\n",
      "44: reward:   1.00, mean_env_reward:   1.26, mean_net_reward:  33.04, reward function loss: -0.2662\n",
      "45: reward:   1.00, mean_env_reward:   1.26, mean_net_reward:  33.29, reward function loss: -0.2997\n",
      "46: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  32.96, reward function loss: -0.2828\n",
      "47: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  32.45, reward function loss: -0.2745\n",
      "48: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  31.97, reward function loss: -0.2926\n",
      "49: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  31.52, reward function loss: -0.3352\n",
      "50: reward:   2.00, mean_env_reward:   1.25, mean_net_reward:  31.51, reward function loss: -0.3353\n",
      "51: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  31.85, reward function loss: -0.3054\n",
      "52: reward:   2.00, mean_env_reward:   1.26, mean_net_reward:  32.07, reward function loss: -0.2747\n",
      "53: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  31.59, reward function loss: -0.2382\n",
      "54: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  31.32, reward function loss: -0.2658\n",
      "55: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  30.87, reward function loss: -0.2649\n",
      "56: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  30.60, reward function loss: -0.3213\n",
      "57: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  30.21, reward function loss: -0.3176\n",
      "58: reward:   2.00, mean_env_reward:   1.25, mean_net_reward:  29.78, reward function loss: -0.3236\n",
      "59: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  29.50, reward function loss: -0.3465\n",
      "60: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  29.06, reward function loss: -0.3391\n",
      "61: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  29.20, reward function loss: -0.3434\n",
      "62: reward:   1.00, mean_env_reward:   1.23, mean_net_reward:  28.78, reward function loss: -0.3050\n",
      "63: reward:   1.00, mean_env_reward:   1.23, mean_net_reward:  28.38, reward function loss: -0.3084\n",
      "64: reward:   1.00, mean_env_reward:   1.23, mean_net_reward:  28.46, reward function loss: -0.3408\n",
      "65: reward:   2.00, mean_env_reward:   1.24, mean_net_reward:  29.17, reward function loss: -0.3090\n",
      "66: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  28.90, reward function loss: -0.2138\n",
      "67: reward:   1.00, mean_env_reward:   1.23, mean_net_reward:  28.50, reward function loss: -0.2457\n",
      "68: reward:   1.00, mean_env_reward:   1.23, mean_net_reward:  28.17, reward function loss: -0.2763\n",
      "69: reward:   1.00, mean_env_reward:   1.23, mean_net_reward:  28.46, reward function loss: -0.3514\n",
      "70: reward:   1.00, mean_env_reward:   1.22, mean_net_reward:  28.46, reward function loss: -0.2896\n",
      "71: reward:   1.00, mean_env_reward:   1.22, mean_net_reward:  28.30, reward function loss: -0.2690\n",
      "72: reward:   1.00, mean_env_reward:   1.22, mean_net_reward:  28.23, reward function loss: -0.2846\n",
      "73: reward:   1.00, mean_env_reward:   1.21, mean_net_reward:  27.87, reward function loss: -0.2777\n",
      "74: reward:   1.00, mean_env_reward:   1.21, mean_net_reward:  27.77, reward function loss: -0.3184\n",
      "75: reward:   1.00, mean_env_reward:   1.21, mean_net_reward:  27.86, reward function loss: -0.3342\n",
      "76: reward:   1.00, mean_env_reward:   1.21, mean_net_reward:  27.58, reward function loss: -0.3073\n",
      "77: reward:   1.00, mean_env_reward:   1.20, mean_net_reward:  27.28, reward function loss: -0.3159\n",
      "78: reward:   1.00, mean_env_reward:   1.20, mean_net_reward:  27.58, reward function loss: -0.3386\n",
      "79: reward:   1.00, mean_env_reward:   1.20, mean_net_reward:  27.31, reward function loss: -0.2954\n",
      "80: reward:   1.00, mean_env_reward:   1.20, mean_net_reward:  27.00, reward function loss: -0.2947\n",
      "81: reward:   1.00, mean_env_reward:   1.19, mean_net_reward:  26.92, reward function loss: -0.3295\n",
      "82: reward:   1.00, mean_env_reward:   1.19, mean_net_reward:  26.79, reward function loss: -0.3351\n",
      "83: reward:   1.00, mean_env_reward:   1.19, mean_net_reward:  26.71, reward function loss: -0.3124\n",
      "84: reward:   1.00, mean_env_reward:   1.19, mean_net_reward:  26.49, reward function loss: -0.3115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85: reward:   1.00, mean_env_reward:   1.18, mean_net_reward:  26.24, reward function loss: -0.3197\n",
      "86: reward:   1.00, mean_env_reward:   1.18, mean_net_reward:  26.05, reward function loss: -0.3438\n",
      "87: reward:   2.00, mean_env_reward:   1.19, mean_net_reward:  25.80, reward function loss: -0.3447\n",
      "88: reward:   1.00, mean_env_reward:   1.19, mean_net_reward:  25.55, reward function loss: -0.3443\n",
      "89: reward:   1.00, mean_env_reward:   1.19, mean_net_reward:  25.33, reward function loss: -0.3577\n",
      "90: reward:   2.00, mean_env_reward:   1.20, mean_net_reward:  25.07, reward function loss: -0.3561\n",
      "91: reward:   1.00, mean_env_reward:   1.19, mean_net_reward:  24.82, reward function loss: -0.3604\n",
      "92: reward:   5.00, mean_env_reward:   1.23, mean_net_reward:  24.81, reward function loss: -0.3679\n",
      "93: reward:   1.00, mean_env_reward:   1.23, mean_net_reward:  24.60, reward function loss: -0.3321\n",
      "94: reward:   1.00, mean_env_reward:   1.23, mean_net_reward:  24.72, reward function loss: -0.3281\n",
      "95: reward:   1.00, mean_env_reward:   1.23, mean_net_reward:  24.63, reward function loss: -0.3254\n",
      "96: reward:   1.00, mean_env_reward:   1.22, mean_net_reward:  24.50, reward function loss: -0.3232\n",
      "97: reward:   2.00, mean_env_reward:   1.23, mean_net_reward:  24.46, reward function loss: -0.3174\n",
      "98: reward:   3.00, mean_env_reward:   1.25, mean_net_reward:  24.48, reward function loss: -0.3211\n",
      "99: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  24.33, reward function loss: -0.3068\n",
      "100: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  24.15, reward function loss: -0.3180\n",
      "101: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  23.59, reward function loss: -0.3231\n",
      "102: reward:   4.00, mean_env_reward:   1.26, mean_net_reward:  23.21, reward function loss: -0.3557\n",
      "103: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  22.88, reward function loss: -0.3407\n",
      "104: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  22.32, reward function loss: -0.3287\n",
      "105: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  22.07, reward function loss: -0.3207\n",
      "106: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  21.77, reward function loss: -0.3178\n",
      "107: reward:   2.00, mean_env_reward:   1.25, mean_net_reward:  21.22, reward function loss: -0.3137\n",
      "108: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  21.03, reward function loss: -0.3259\n",
      "109: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  20.94, reward function loss: -0.3265\n",
      "110: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  20.53, reward function loss: -0.3303\n",
      "111: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  20.42, reward function loss: -0.3322\n",
      "112: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  20.27, reward function loss: -0.3379\n",
      "113: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  19.76, reward function loss: -0.3497\n",
      "114: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  19.67, reward function loss: -0.3437\n",
      "115: reward:   1.00, mean_env_reward:   1.24, mean_net_reward:  19.59, reward function loss: -0.3426\n",
      "116: reward:   2.00, mean_env_reward:   1.25, mean_net_reward:  19.55, reward function loss: -0.3565\n",
      "117: reward:   2.00, mean_env_reward:   1.25, mean_net_reward:  19.26, reward function loss: -0.3367\n",
      "118: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  19.15, reward function loss: -0.3349\n",
      "119: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  18.61, reward function loss: -0.3516\n",
      "120: reward:   1.00, mean_env_reward:   1.25, mean_net_reward:  18.29, reward function loss: -0.3386\n",
      "121: reward:   2.00, mean_env_reward:   1.26, mean_net_reward:  18.55, reward function loss: -0.3383\n",
      "122: reward:   1.00, mean_env_reward:   1.26, mean_net_reward:  18.34, reward function loss: -0.3008\n",
      "123: reward:   1.00, mean_env_reward:   1.26, mean_net_reward:  18.27, reward function loss: -0.3207\n",
      "124: reward:   1.00, mean_env_reward:   1.26, mean_net_reward:  17.64, reward function loss: -0.3371\n",
      "125: reward:   1.00, mean_env_reward:   1.26, mean_net_reward:  17.56, reward function loss: -0.3553\n",
      "126: reward:   1.00, mean_env_reward:   1.26, mean_net_reward:  17.42, reward function loss: -0.3457\n",
      "127: reward:   1.00, mean_env_reward:   1.26, mean_net_reward:  17.40, reward function loss: -0.3546\n",
      "128: reward:   5.00, mean_env_reward:   1.30, mean_net_reward:  17.38, reward function loss: -0.3472\n",
      "129: reward:   1.00, mean_env_reward:   1.30, mean_net_reward:  17.34, reward function loss: -0.3444\n",
      "130: reward:   1.00, mean_env_reward:   1.29, mean_net_reward:  17.33, reward function loss: -0.3625\n",
      "131: reward:   1.00, mean_env_reward:   1.28, mean_net_reward:  17.29, reward function loss: -0.3637\n",
      "132: reward:   1.00, mean_env_reward:   1.26, mean_net_reward:  16.59, reward function loss: -0.3429\n",
      "133: reward:   1.00, mean_env_reward:   1.26, mean_net_reward:  16.42, reward function loss: -0.3268\n",
      "134: reward:   1.00, mean_env_reward:   1.26, mean_net_reward:  16.38, reward function loss: -0.3350\n",
      "135: reward:   3.00, mean_env_reward:   1.27, mean_net_reward:  16.34, reward function loss: -0.3486\n",
      "136: reward:   1.00, mean_env_reward:   1.27, mean_net_reward:  15.93, reward function loss: -0.3536\n",
      "137: reward:   2.00, mean_env_reward:   1.28, mean_net_reward:  15.30, reward function loss: -0.3318\n",
      "138: reward:   2.00, mean_env_reward:   1.29, mean_net_reward:  14.99, reward function loss: -0.3315\n",
      "139: reward:   2.00, mean_env_reward:   1.30, mean_net_reward:  14.98, reward function loss: -0.3341\n",
      "140: reward:   1.00, mean_env_reward:   1.29, mean_net_reward:  14.86, reward function loss: -0.3554\n",
      "141: reward:   2.00, mean_env_reward:   1.30, mean_net_reward:  14.54, reward function loss: -0.3435\n",
      "142: reward:   1.00, mean_env_reward:   1.30, mean_net_reward:  14.40, reward function loss: -0.3449\n",
      "143: reward:   1.00, mean_env_reward:   1.30, mean_net_reward:  14.27, reward function loss: -0.3553\n",
      "144: reward:   1.00, mean_env_reward:   1.30, mean_net_reward:  14.17, reward function loss: -0.3665\n",
      "145: reward:   1.00, mean_env_reward:   1.30, mean_net_reward:  13.85, reward function loss: -0.3703\n",
      "146: reward:   1.00, mean_env_reward:   1.30, mean_net_reward:  13.77, reward function loss: -0.3538\n",
      "147: reward:   6.00, mean_env_reward:   1.35, mean_net_reward:  13.73, reward function loss: -0.3443\n",
      "148: reward:   1.00, mean_env_reward:   1.35, mean_net_reward:  13.80, reward function loss: -0.3539\n",
      "149: reward:   1.00, mean_env_reward:   1.35, mean_net_reward:  13.81, reward function loss: -0.3384\n",
      "150: reward:   1.00, mean_env_reward:   1.34, mean_net_reward:  13.54, reward function loss: -0.3340\n",
      "151: reward:   1.00, mean_env_reward:   1.34, mean_net_reward:  13.26, reward function loss: -0.3484\n",
      "152: reward:   1.00, mean_env_reward:   1.33, mean_net_reward:  12.94, reward function loss: -0.3352\n",
      "153: reward:   1.00, mean_env_reward:   1.33, mean_net_reward:  12.92, reward function loss: -0.3249\n",
      "154: reward:   1.00, mean_env_reward:   1.33, mean_net_reward:  12.79, reward function loss: -0.3355\n",
      "155: reward:   1.00, mean_env_reward:   1.33, mean_net_reward:  12.81, reward function loss: -0.3593\n",
      "156: reward:   1.00, mean_env_reward:   1.33, mean_net_reward:  12.67, reward function loss: -0.3512\n",
      "157: reward:   2.00, mean_env_reward:   1.34, mean_net_reward:  12.81, reward function loss: -0.3552\n",
      "158: reward:   1.00, mean_env_reward:   1.33, mean_net_reward:  12.80, reward function loss: -0.3304\n",
      "159: reward:   2.00, mean_env_reward:   1.34, mean_net_reward:  12.68, reward function loss: -0.3393\n",
      "160: reward:   1.00, mean_env_reward:   1.34, mean_net_reward:  12.67, reward function loss: -0.3534\n",
      "161: reward:   1.00, mean_env_reward:   1.34, mean_net_reward:  12.35, reward function loss: -0.3701\n",
      "162: reward:   1.00, mean_env_reward:   1.34, mean_net_reward:  12.40, reward function loss: -0.3685\n",
      "163: reward:   2.00, mean_env_reward:   1.35, mean_net_reward:  12.40, reward function loss: -0.3603\n",
      "164: reward:   1.00, mean_env_reward:   1.35, mean_net_reward:  12.12, reward function loss: -0.3575\n",
      "165: reward:   1.00, mean_env_reward:   1.34, mean_net_reward:  11.38, reward function loss: -0.3656\n",
      "166: reward:   1.00, mean_env_reward:   1.34, mean_net_reward:  11.37, reward function loss: -0.3701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167: reward:   1.00, mean_env_reward:   1.34, mean_net_reward:  11.35, reward function loss: -0.3646\n",
      "168: reward:   1.00, mean_env_reward:   1.34, mean_net_reward:  11.34, reward function loss: -0.3660\n",
      "169: reward:   1.00, mean_env_reward:   1.34, mean_net_reward:  10.95, reward function loss: -0.3673\n",
      "170: reward:   1.00, mean_env_reward:   1.34, mean_net_reward:  10.67, reward function loss: -0.3580\n",
      "171: reward:   2.00, mean_env_reward:   1.35, mean_net_reward:  10.59, reward function loss: -0.3657\n",
      "172: reward:   2.00, mean_env_reward:   1.36, mean_net_reward:  10.44, reward function loss: -0.3608\n",
      "173: reward:   1.00, mean_env_reward:   1.36, mean_net_reward:  10.44, reward function loss: -0.3543\n",
      "174: reward:   1.00, mean_env_reward:   1.36, mean_net_reward:  10.25, reward function loss: -0.3602\n",
      "175: reward:   1.00, mean_env_reward:   1.36, mean_net_reward:   9.91, reward function loss: -0.3694\n",
      "176: reward:   6.00, mean_env_reward:   1.41, mean_net_reward:   9.98, reward function loss: -0.3747\n",
      "177: reward:   1.00, mean_env_reward:   1.41, mean_net_reward:  10.06, reward function loss: -0.3568\n",
      "178: reward:   1.00, mean_env_reward:   1.41, mean_net_reward:   9.57, reward function loss: -0.3444\n",
      "179: reward:   3.00, mean_env_reward:   1.43, mean_net_reward:   9.64, reward function loss: -0.3609\n",
      "180: reward:   1.00, mean_env_reward:   1.43, mean_net_reward:   9.66, reward function loss: -0.3348\n",
      "181: reward:   1.00, mean_env_reward:   1.43, mean_net_reward:   9.53, reward function loss: -0.3479\n",
      "182: reward:   2.00, mean_env_reward:   1.44, mean_net_reward:   9.42, reward function loss: -0.3599\n",
      "183: reward:   1.00, mean_env_reward:   1.44, mean_net_reward:   9.24, reward function loss: -0.3567\n",
      "184: reward:   1.00, mean_env_reward:   1.44, mean_net_reward:   9.22, reward function loss: -0.3552\n",
      "185: reward:   1.00, mean_env_reward:   1.44, mean_net_reward:   9.18, reward function loss: -0.3633\n",
      "186: reward:   1.00, mean_env_reward:   1.44, mean_net_reward:   9.08, reward function loss: -0.3644\n",
      "187: reward:   1.00, mean_env_reward:   1.43, mean_net_reward:   9.24, reward function loss: -0.3751\n",
      "188: reward:   1.00, mean_env_reward:   1.43, mean_net_reward:   9.20, reward function loss: -0.3500\n",
      "189: reward:   1.00, mean_env_reward:   1.43, mean_net_reward:   9.18, reward function loss: -0.3509\n",
      "190: reward:   1.00, mean_env_reward:   1.42, mean_net_reward:   9.19, reward function loss: -0.3641\n",
      "191: reward:   2.00, mean_env_reward:   1.43, mean_net_reward:   9.29, reward function loss: -0.3679\n",
      "192: reward:   2.00, mean_env_reward:   1.40, mean_net_reward:   9.05, reward function loss: -0.3603\n",
      "193: reward:   1.00, mean_env_reward:   1.40, mean_net_reward:   9.08, reward function loss: -0.3652\n",
      "194: reward:   1.00, mean_env_reward:   1.40, mean_net_reward:   8.79, reward function loss: -0.3611\n",
      "195: reward:   1.00, mean_env_reward:   1.40, mean_net_reward:   8.67, reward function loss: -0.3600\n",
      "196: reward:   3.00, mean_env_reward:   1.42, mean_net_reward:   8.60, reward function loss: -0.3604\n",
      "197: reward:   2.00, mean_env_reward:   1.42, mean_net_reward:   8.43, reward function loss: -0.3591\n",
      "198: reward:   1.00, mean_env_reward:   1.40, mean_net_reward:   8.27, reward function loss: -0.3633\n",
      "199: reward:   1.00, mean_env_reward:   1.40, mean_net_reward:   8.19, reward function loss: -0.3579\n",
      "200: reward:   1.00, mean_env_reward:   1.40, mean_net_reward:   8.15, reward function loss: -0.3601\n",
      "201: reward:   2.00, mean_env_reward:   1.41, mean_net_reward:   8.18, reward function loss: -0.3682\n",
      "202: reward:   1.00, mean_env_reward:   1.38, mean_net_reward:   8.06, reward function loss: -0.3679\n",
      "203: reward:   1.00, mean_env_reward:   1.38, mean_net_reward:   7.90, reward function loss: -0.3577\n",
      "204: reward:   2.00, mean_env_reward:   1.39, mean_net_reward:   7.94, reward function loss: -0.3617\n",
      "205: reward:   2.00, mean_env_reward:   1.40, mean_net_reward:   7.79, reward function loss: -0.3437\n",
      "206: reward:   1.00, mean_env_reward:   1.40, mean_net_reward:   7.69, reward function loss: -0.3415\n",
      "207: reward:   1.00, mean_env_reward:   1.39, mean_net_reward:   7.63, reward function loss: -0.3590\n",
      "208: reward:   1.00, mean_env_reward:   1.39, mean_net_reward:   7.61, reward function loss: -0.3600\n",
      "209: reward:   1.00, mean_env_reward:   1.39, mean_net_reward:   7.41, reward function loss: -0.3671\n",
      "210: reward:   2.00, mean_env_reward:   1.40, mean_net_reward:   7.39, reward function loss: -0.3678\n",
      "211: reward:   1.00, mean_env_reward:   1.40, mean_net_reward:   7.34, reward function loss: -0.3645\n",
      "212: reward:   1.00, mean_env_reward:   1.40, mean_net_reward:   7.35, reward function loss: -0.3636\n",
      "213: reward:   1.00, mean_env_reward:   1.40, mean_net_reward:   7.28, reward function loss: -0.3649\n",
      "214: reward:   2.00, mean_env_reward:   1.41, mean_net_reward:   7.30, reward function loss: -0.3647\n",
      "215: reward:   1.00, mean_env_reward:   1.41, mean_net_reward:   7.28, reward function loss: -0.3545\n",
      "216: reward:   1.00, mean_env_reward:   1.40, mean_net_reward:   7.08, reward function loss: -0.3601\n",
      "217: reward:   1.00, mean_env_reward:   1.39, mean_net_reward:   7.11, reward function loss: -0.3735\n",
      "218: reward:   2.00, mean_env_reward:   1.40, mean_net_reward:   7.17, reward function loss: -0.3645\n",
      "219: reward:   6.00, mean_env_reward:   1.45, mean_net_reward:   6.98, reward function loss: -0.3553\n",
      "220: reward:   1.00, mean_env_reward:   1.45, mean_net_reward:   6.98, reward function loss: -0.3545\n",
      "221: reward:   1.00, mean_env_reward:   1.44, mean_net_reward:   6.50, reward function loss: -0.3596\n",
      "222: reward:   1.00, mean_env_reward:   1.44, mean_net_reward:   6.53, reward function loss: -0.3719\n",
      "223: reward:   3.00, mean_env_reward:   1.46, mean_net_reward:   6.62, reward function loss: -0.3684\n",
      "224: reward:   1.00, mean_env_reward:   1.46, mean_net_reward:   6.62, reward function loss: -0.3515\n",
      "225: reward:   1.00, mean_env_reward:   1.46, mean_net_reward:   6.57, reward function loss: -0.3450\n",
      "226: reward:   1.00, mean_env_reward:   1.46, mean_net_reward:   6.59, reward function loss: -0.3488\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1d70998551a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# objective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mD_demo_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_demo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mD_samp_out_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_samp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mD_samp_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_samp_out_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/IRL/util.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisualize_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_rewards = []\n",
    "step_idx = 0\n",
    "done_episodes = 0\n",
    "DEMO_BATCH = 256\n",
    "BSIZE = 256 # batch size\n",
    "\n",
    "batch_episodes = 0\n",
    "batch_states, batch_actions, batch_qvals = deque([], BSIZE), deque([], BSIZE), deque([], BSIZE)\n",
    "net_rewards = deque([], 100)\n",
    "env_rewards = deque([], 100)\n",
    "loss_rwd = 0.\n",
    "\n",
    "while done_episodes < 500000:\n",
    "    states, actions, rewards, done = agent_net.generate_session(env, BSIZE)\n",
    "    \n",
    "    # Store samples in batch\n",
    "    batch_states.extend(states)\n",
    "    batch_actions.extend(actions)\n",
    "    batch_qvals.extend(grl.calc_qvals(rewards))\n",
    "    env_reward = np.sum(rewards)\n",
    "    env_rewards.extend([env_reward])\n",
    "    \n",
    "    if len(batch_actions) < BSIZE:\n",
    "        continue\n",
    "    \n",
    "    batch_episodes += 1\n",
    "        \n",
    "    # Get reward from reward_net\n",
    "    x = torch.cat((float32_preprocessor(states), float32_preprocessor(actions).view(-1,1)), dim=1).to(device)\n",
    "    net_reward = reward_net(x)\n",
    "    net_rewards.extend([np.sum(net_reward.cpu().detach().numpy())])\n",
    "         \n",
    "    done_episodes += 1\n",
    "\n",
    "    mean_env_rewards = float(np.mean(env_rewards))\n",
    "    mean_net_rewards = float(np.mean(net_rewards))\n",
    "\n",
    "    writer.add_scalar('Episodic Reward', env_reward, done_episodes)\n",
    "    writer.add_scalar('mean_env_reward', mean_env_rewards, done_episodes)\n",
    "    writer.add_scalar('mean_net_reward', mean_net_rewards, done_episodes)\n",
    "    writer.add_scalar('loss_reward_net', loss_rwd, done_episodes)        \n",
    "\n",
    "    print(f'{done_episodes}: reward: {env_reward:6.2f}, mean_env_reward: {mean_env_rewards:6.2f}, mean_net_reward: {mean_net_rewards:6.2f}, reward function loss: {loss_rwd:6.4f}')\n",
    "\n",
    "    ## Tensorboard logging \n",
    "    if done_episodes%1000==0 or mean_env_rewards>=100:\n",
    "        fig = reward_net.visualize_net(agent_net, Npoints=20)\n",
    "        writer.add_figure('Reward Net', fig, global_step=done_episodes/100)\n",
    "        \n",
    "        test_reward, test_fig = agent_net.test_agent(env,device)\n",
    "        writer.add_scalar('test_reward', test_reward, done_episodes)\n",
    "        writer.add_figure('Agent traj', test_fig, global_step=done_episodes/100)\n",
    "        torch.save(agent_net.state_dict(), 'pointspace_policy_net_origin.mod')\n",
    "        torch.save(reward_net.state_dict(), 'pointspace_reward_net_origin.mod')\n",
    "\n",
    "    if mean_env_rewards >= 100:\n",
    "        print(f'Solved in {step_idx} steps and {done_episodes} episodes!')\n",
    "        torch.save(agent_net.state_dict(), 'pointspace_policy_net_origin.mod')\n",
    "        torch.save(reward_net.state_dict(), 'pointspace_reward_net_origin.mod')\n",
    "        break\n",
    "\n",
    "    states_v = torch.FloatTensor(batch_states)\n",
    "    batch_actions_t = torch.LongTensor(batch_actions)\n",
    "    batch_qvals_v = torch.FloatTensor(batch_qvals)\n",
    "  \n",
    "    Total_steps_demo = len(AStore_steps)\n",
    "\n",
    "    # reward function learning\n",
    "    for rf_i in range(1):\n",
    "        # ToDo: Sample from initial steps\n",
    "        selected = np.random.choice(Total_steps_demo, DEMO_BATCH)\n",
    "        demo_states = np.take(XStore_steps, selected, axis=0)\n",
    "        demo_actions = np.take(AStore_steps, selected, axis=0)\n",
    "        \n",
    "        demo_batch_states = torch.FloatTensor(demo_states)\n",
    "        demo_batch_actions = torch.FloatTensor(demo_actions)\n",
    "        \n",
    "        D_demo = torch.cat([demo_batch_states, demo_batch_actions.view(-1, 1)], dim=-1).to(device)\n",
    "        D_samp = torch.cat([states_v, batch_actions_t.float().view(-1, 1)], dim=-1).to(device)\n",
    "        D_samp = torch.cat([D_demo, D_samp])\n",
    "                \n",
    "        # dummy importance weights - fix later\n",
    "        z = torch.ones((D_samp.shape[0], 1)).to(device)\n",
    "\n",
    "        # objective\n",
    "        D_demo_out = reward_net(D_demo)\n",
    "        D_samp_out_net = reward_net(D_samp)\n",
    "        D_samp_out = z * torch.exp(D_samp_out_net)\n",
    "        \n",
    "        loss_rwd = -torch.mean(D_demo_out) + torch.log(torch.mean(D_samp_out))\n",
    "        optimizer_reward.zero_grad()\n",
    "        loss_rwd.backward()\n",
    "        optimizer_reward.step()\n",
    "    \n",
    "    # agent\n",
    "    optimizer_agent.zero_grad()\n",
    "    logits_v = agent_net(states_v.to(device))\n",
    "    log_prob_v = torch.log_softmax(logits_v.cpu(), dim=1) # p(a|s)\n",
    "    \n",
    "    # batch_qvals_v = E(s)\n",
    "    # REINFORCE\n",
    "    log_prob_actions_v = -batch_qvals_v * log_prob_v[range(len(batch_states)), batch_actions_t] #q(s,a)=p(a|s)E(s)\n",
    "    loss_v = log_prob_actions_v.mean()\n",
    "    writer.add_scalar('loss_agent_net', loss_v, done_episodes) \n",
    "    \n",
    "    loss_v.backward()\n",
    "    optimizer_agent.step()\n",
    "\n",
    "    batch_episodes = 0\n",
    "\n",
    "env.close()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing \n",
    "agent_net.eval()\n",
    "\n",
    "for i in range(10):\n",
    "    state = env.reset()\n",
    "    Reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = agent_net.get_action(state)\n",
    "        state, reward, done, _ = env.step(int(action))\n",
    "        Reward += reward\n",
    "    print(\"Trial :\", i, \" Reward: \", Reward)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
