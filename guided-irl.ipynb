{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from collections import namedtuple\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import ptan\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from ptan.agent import float32_preprocessor\n",
    "\n",
    "from util import PGN, RewardNet\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 0.01\n",
    "EPISODES_TO_TRAIN = 4\n",
    "DEMO_BATCH = 50\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "EpisodeStep = namedtuple('EpisodeStep', field_names=['state', 'action', 'reward', 'next_state'])\n",
    "Trajectory = namedtuple('Trajectory', field_names=['prob', 'episode_steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_qvals(rewards):\n",
    "    res = []\n",
    "    sum_r = 0.0\n",
    "    for r in reversed(rewards):\n",
    "        sum_r *= GAMMA\n",
    "        sum_r += r\n",
    "        res.append(sum_r)\n",
    "    return list(reversed(res))\n",
    "\n",
    "\n",
    "def process_demonstrations(demo_samples):\n",
    "    traj_states, traj_actions, traj_qvals, traj_prob = [], [], [], []\n",
    "    for traj in demo_samples:\n",
    "        states, actions, rewards, qvals = [], [], [], []\n",
    "        traj_prob.append(traj.prob)\n",
    "        for step in traj.episode_steps:\n",
    "            states.append(step.state)\n",
    "            actions.append(step.action)\n",
    "            rewards.append(step.reward)\n",
    "        qvals.extend(calc_qvals(rewards))\n",
    "\n",
    "        traj_states.append(states)\n",
    "        traj_actions.append(actions)\n",
    "        traj_qvals.append(qvals)\n",
    "    traj_states = np.array(traj_states, dtype=np.object)\n",
    "    traj_actions = np.array(traj_actions, dtype=np.object)\n",
    "    traj_qvals = np.array(traj_qvals, dtype=np.object)\n",
    "    traj_prob = np.array(traj_prob, dtype=np.float)\n",
    "    return {'states': traj_states, 'actions': traj_actions, 'qvals': traj_qvals, 'traj_probs': traj_prob}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "agent_net = PGN(env.observation_space.shape[0], env.action_space.n)\n",
    "reward_net = RewardNet(env.observation_space.shape[0] + 1)\n",
    "agent = ptan.agent.PolicyAgent(agent_net, preprocessor=float32_preprocessor, apply_softmax=True)\n",
    "exp_source = ptan.experience.ExperienceSourceFirstLast(env, agent, gamma=GAMMA)\n",
    "optimizer_agent = optim.Adam(agent_net.parameters(), lr=LEARNING_RATE)\n",
    "optimizer_reward = optim.Adam(reward_net.parameters(), lr=1e-2, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of demonstrations: 100\n"
     ]
    }
   ],
   "source": [
    "with open('demonstrations.list.pkl', 'rb') as f:\n",
    "    demonstrations = pickle.load(f)\n",
    "assert (len(demonstrations) > DEMO_BATCH)\n",
    "print(f'Number of demonstrations: {len(demonstrations)}')\n",
    "demonstrations = process_demonstrations(demonstrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10: reward:  10.00, mean_100:  10.00, episodes: 1, reward function loss: 0.0000\n",
      "23: reward:  13.00, mean_100:  11.50, episodes: 2, reward function loss: 0.0000\n",
      "38: reward:  15.00, mean_100:  12.67, episodes: 3, reward function loss: 0.0000\n",
      "72: reward:  34.00, mean_100:  18.00, episodes: 4, reward function loss: 0.0001\n",
      "84: reward:  12.00, mean_100:  16.80, episodes: 5, reward function loss: 0.0001\n",
      "101: reward:  17.00, mean_100:  16.83, episodes: 6, reward function loss: 0.0001\n",
      "112: reward:  11.00, mean_100:  16.00, episodes: 7, reward function loss: 0.0001\n",
      "142: reward:  30.00, mean_100:  17.75, episodes: 8, reward function loss: -0.0000\n",
      "161: reward:  19.00, mean_100:  17.89, episodes: 9, reward function loss: -0.0000\n",
      "177: reward:  16.00, mean_100:  17.70, episodes: 10, reward function loss: -0.0000\n",
      "186: reward:   9.00, mean_100:  16.91, episodes: 11, reward function loss: -0.0000\n",
      "205: reward:  19.00, mean_100:  17.08, episodes: 12, reward function loss: -0.0000\n",
      "216: reward:  11.00, mean_100:  16.62, episodes: 13, reward function loss: -0.0000\n",
      "242: reward:  26.00, mean_100:  17.29, episodes: 14, reward function loss: -0.0000\n",
      "256: reward:  14.00, mean_100:  17.07, episodes: 15, reward function loss: -0.0000\n",
      "267: reward:  11.00, mean_100:  16.69, episodes: 16, reward function loss: -0.0000\n",
      "285: reward:  18.00, mean_100:  16.76, episodes: 17, reward function loss: -0.0000\n",
      "301: reward:  16.00, mean_100:  16.72, episodes: 18, reward function loss: -0.0000\n",
      "322: reward:  21.00, mean_100:  16.95, episodes: 19, reward function loss: -0.0000\n",
      "344: reward:  22.00, mean_100:  17.20, episodes: 20, reward function loss: -0.0000\n",
      "391: reward:  47.00, mean_100:  18.62, episodes: 21, reward function loss: -0.0000\n",
      "405: reward:  14.00, mean_100:  18.41, episodes: 22, reward function loss: -0.0000\n",
      "420: reward:  15.00, mean_100:  18.26, episodes: 23, reward function loss: -0.0000\n",
      "453: reward:  33.00, mean_100:  18.88, episodes: 24, reward function loss: -0.0001\n",
      "478: reward:  25.00, mean_100:  19.12, episodes: 25, reward function loss: -0.0001\n",
      "500: reward:  22.00, mean_100:  19.23, episodes: 26, reward function loss: -0.0001\n",
      "514: reward:  14.00, mean_100:  19.04, episodes: 27, reward function loss: -0.0001\n",
      "528: reward:  14.00, mean_100:  18.86, episodes: 28, reward function loss: -0.0001\n",
      "548: reward:  20.00, mean_100:  18.90, episodes: 29, reward function loss: -0.0001\n",
      "563: reward:  15.00, mean_100:  18.77, episodes: 30, reward function loss: -0.0001\n",
      "578: reward:  15.00, mean_100:  18.65, episodes: 31, reward function loss: -0.0001\n",
      "600: reward:  22.00, mean_100:  18.75, episodes: 32, reward function loss: -0.0000\n",
      "613: reward:  13.00, mean_100:  18.58, episodes: 33, reward function loss: -0.0000\n",
      "634: reward:  21.00, mean_100:  18.65, episodes: 34, reward function loss: -0.0000\n",
      "665: reward:  31.00, mean_100:  19.00, episodes: 35, reward function loss: -0.0000\n",
      "684: reward:  19.00, mean_100:  19.00, episodes: 36, reward function loss: -0.0000\n",
      "698: reward:  14.00, mean_100:  18.86, episodes: 37, reward function loss: -0.0000\n",
      "730: reward:  32.00, mean_100:  19.21, episodes: 38, reward function loss: -0.0000\n",
      "755: reward:  25.00, mean_100:  19.36, episodes: 39, reward function loss: -0.0000\n",
      "773: reward:  18.00, mean_100:  19.32, episodes: 40, reward function loss: -0.0000\n",
      "792: reward:  19.00, mean_100:  19.32, episodes: 41, reward function loss: -0.0000\n",
      "835: reward:  43.00, mean_100:  19.88, episodes: 42, reward function loss: -0.0000\n",
      "851: reward:  16.00, mean_100:  19.79, episodes: 43, reward function loss: -0.0000\n",
      "871: reward:  20.00, mean_100:  19.80, episodes: 44, reward function loss: -0.0000\n",
      "889: reward:  18.00, mean_100:  19.76, episodes: 45, reward function loss: -0.0000\n",
      "910: reward:  21.00, mean_100:  19.78, episodes: 46, reward function loss: -0.0000\n",
      "929: reward:  19.00, mean_100:  19.77, episodes: 47, reward function loss: -0.0000\n",
      "945: reward:  16.00, mean_100:  19.69, episodes: 48, reward function loss: -0.0000\n",
      "967: reward:  22.00, mean_100:  19.73, episodes: 49, reward function loss: -0.0000\n",
      "1009: reward:  42.00, mean_100:  20.18, episodes: 50, reward function loss: -0.0000\n",
      "1024: reward:  15.00, mean_100:  20.08, episodes: 51, reward function loss: -0.0000\n",
      "1058: reward:  34.00, mean_100:  20.35, episodes: 52, reward function loss: -0.0000\n",
      "1125: reward:  67.00, mean_100:  21.23, episodes: 53, reward function loss: -0.0000\n",
      "1143: reward:  18.00, mean_100:  21.17, episodes: 54, reward function loss: -0.0000\n",
      "1176: reward:  33.00, mean_100:  21.38, episodes: 55, reward function loss: -0.0000\n",
      "1204: reward:  28.00, mean_100:  21.50, episodes: 56, reward function loss: -0.0001\n",
      "1224: reward:  20.00, mean_100:  21.47, episodes: 57, reward function loss: -0.0001\n",
      "1259: reward:  35.00, mean_100:  21.71, episodes: 58, reward function loss: -0.0001\n",
      "1279: reward:  20.00, mean_100:  21.68, episodes: 59, reward function loss: -0.0001\n",
      "1288: reward:   9.00, mean_100:  21.47, episodes: 60, reward function loss: -0.0001\n",
      "1321: reward:  33.00, mean_100:  21.66, episodes: 61, reward function loss: -0.0001\n",
      "1346: reward:  25.00, mean_100:  21.71, episodes: 62, reward function loss: -0.0001\n",
      "1369: reward:  23.00, mean_100:  21.73, episodes: 63, reward function loss: -0.0001\n",
      "1383: reward:  14.00, mean_100:  21.61, episodes: 64, reward function loss: -0.0003\n",
      "1408: reward:  25.00, mean_100:  21.66, episodes: 65, reward function loss: -0.0003\n",
      "1455: reward:  47.00, mean_100:  22.05, episodes: 66, reward function loss: -0.0003\n",
      "1495: reward:  40.00, mean_100:  22.31, episodes: 67, reward function loss: -0.0003\n",
      "1519: reward:  24.00, mean_100:  22.34, episodes: 68, reward function loss: -0.0007\n",
      "1582: reward:  63.00, mean_100:  22.93, episodes: 69, reward function loss: -0.0007\n",
      "1601: reward:  19.00, mean_100:  22.87, episodes: 70, reward function loss: -0.0007\n",
      "1650: reward:  49.00, mean_100:  23.24, episodes: 71, reward function loss: -0.0007\n",
      "1723: reward:  73.00, mean_100:  23.93, episodes: 72, reward function loss: -0.0025\n",
      "1741: reward:  18.00, mean_100:  23.85, episodes: 73, reward function loss: -0.0025\n",
      "1859: reward: 118.00, mean_100:  25.12, episodes: 74, reward function loss: -0.0025\n",
      "1885: reward:  26.00, mean_100:  25.13, episodes: 75, reward function loss: -0.0025\n",
      "1922: reward:  37.00, mean_100:  25.29, episodes: 76, reward function loss: -0.0031\n",
      "1962: reward:  40.00, mean_100:  25.48, episodes: 77, reward function loss: -0.0031\n",
      "1991: reward:  29.00, mean_100:  25.53, episodes: 78, reward function loss: -0.0031\n",
      "2078: reward:  87.00, mean_100:  26.30, episodes: 79, reward function loss: -0.0031\n",
      "2102: reward:  24.00, mean_100:  26.27, episodes: 80, reward function loss: -0.0012\n",
      "2117: reward:  15.00, mean_100:  26.14, episodes: 81, reward function loss: -0.0012\n",
      "2168: reward:  51.00, mean_100:  26.44, episodes: 82, reward function loss: -0.0012\n",
      "2197: reward:  29.00, mean_100:  26.47, episodes: 83, reward function loss: -0.0012\n",
      "2261: reward:  64.00, mean_100:  26.92, episodes: 84, reward function loss: -0.0024\n",
      "2312: reward:  51.00, mean_100:  27.20, episodes: 85, reward function loss: -0.0024\n",
      "2324: reward:  12.00, mean_100:  27.02, episodes: 86, reward function loss: -0.0024\n",
      "2350: reward:  26.00, mean_100:  27.01, episodes: 87, reward function loss: -0.0024\n",
      "2390: reward:  40.00, mean_100:  27.16, episodes: 88, reward function loss: -0.0014\n",
      "2471: reward:  81.00, mean_100:  27.76, episodes: 89, reward function loss: -0.0014\n",
      "2491: reward:  20.00, mean_100:  27.68, episodes: 90, reward function loss: -0.0014\n",
      "2523: reward:  32.00, mean_100:  27.73, episodes: 91, reward function loss: -0.0014\n",
      "2562: reward:  39.00, mean_100:  27.85, episodes: 92, reward function loss: -0.0015\n",
      "2592: reward:  30.00, mean_100:  27.87, episodes: 93, reward function loss: -0.0015\n",
      "2623: reward:  31.00, mean_100:  27.90, episodes: 94, reward function loss: -0.0015\n",
      "2685: reward:  62.00, mean_100:  28.26, episodes: 95, reward function loss: -0.0015\n",
      "2761: reward:  76.00, mean_100:  28.76, episodes: 96, reward function loss: -0.0022\n",
      "2790: reward:  29.00, mean_100:  28.76, episodes: 97, reward function loss: -0.0022\n",
      "2867: reward:  77.00, mean_100:  29.26, episodes: 98, reward function loss: -0.0022\n",
      "2909: reward:  42.00, mean_100:  29.38, episodes: 99, reward function loss: -0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2945: reward:  36.00, mean_100:  29.45, episodes: 100, reward function loss: -0.0009\n",
      "2987: reward:  42.00, mean_100:  29.77, episodes: 101, reward function loss: -0.0009\n",
      "3002: reward:  15.00, mean_100:  29.79, episodes: 102, reward function loss: -0.0009\n",
      "3082: reward:  80.00, mean_100:  30.44, episodes: 103, reward function loss: -0.0009\n",
      "3134: reward:  52.00, mean_100:  30.62, episodes: 104, reward function loss: -0.0000\n",
      "3174: reward:  40.00, mean_100:  30.90, episodes: 105, reward function loss: -0.0000\n",
      "3288: reward: 114.00, mean_100:  31.87, episodes: 106, reward function loss: -0.0000\n",
      "3335: reward:  47.00, mean_100:  32.23, episodes: 107, reward function loss: -0.0000\n",
      "3450: reward: 115.00, mean_100:  33.08, episodes: 108, reward function loss: -0.0004\n",
      "3516: reward:  66.00, mean_100:  33.55, episodes: 109, reward function loss: -0.0004\n",
      "3565: reward:  49.00, mean_100:  33.88, episodes: 110, reward function loss: -0.0004\n",
      "3635: reward:  70.00, mean_100:  34.49, episodes: 111, reward function loss: -0.0004\n",
      "3700: reward:  65.00, mean_100:  34.95, episodes: 112, reward function loss: -0.0017\n",
      "3821: reward: 121.00, mean_100:  36.05, episodes: 113, reward function loss: -0.0017\n",
      "3943: reward: 122.00, mean_100:  37.01, episodes: 114, reward function loss: -0.0017\n",
      "4015: reward:  72.00, mean_100:  37.59, episodes: 115, reward function loss: -0.0017\n",
      "4117: reward: 102.00, mean_100:  38.50, episodes: 116, reward function loss: -0.0029\n",
      "4166: reward:  49.00, mean_100:  38.81, episodes: 117, reward function loss: -0.0029\n",
      "4219: reward:  53.00, mean_100:  39.18, episodes: 118, reward function loss: -0.0029\n",
      "4245: reward:  26.00, mean_100:  39.23, episodes: 119, reward function loss: -0.0029\n",
      "4273: reward:  28.00, mean_100:  39.29, episodes: 120, reward function loss: -0.0031\n",
      "4420: reward: 147.00, mean_100:  40.29, episodes: 121, reward function loss: -0.0031\n",
      "4485: reward:  65.00, mean_100:  40.80, episodes: 122, reward function loss: -0.0031\n",
      "4632: reward: 147.00, mean_100:  42.12, episodes: 123, reward function loss: -0.0031\n",
      "4716: reward:  84.00, mean_100:  42.63, episodes: 124, reward function loss: -0.0024\n",
      "4830: reward: 114.00, mean_100:  43.52, episodes: 125, reward function loss: -0.0024\n",
      "4902: reward:  72.00, mean_100:  44.02, episodes: 126, reward function loss: -0.0024\n",
      "5041: reward: 139.00, mean_100:  45.27, episodes: 127, reward function loss: -0.0024\n",
      "5080: reward:  39.00, mean_100:  45.52, episodes: 128, reward function loss: -0.0055\n",
      "5233: reward: 153.00, mean_100:  46.85, episodes: 129, reward function loss: -0.0055\n",
      "5305: reward:  72.00, mean_100:  47.42, episodes: 130, reward function loss: -0.0055\n",
      "5334: reward:  29.00, mean_100:  47.56, episodes: 131, reward function loss: -0.0055\n",
      "5448: reward: 114.00, mean_100:  48.48, episodes: 132, reward function loss: -0.0063\n",
      "5482: reward:  34.00, mean_100:  48.69, episodes: 133, reward function loss: -0.0063\n",
      "5519: reward:  37.00, mean_100:  48.85, episodes: 134, reward function loss: -0.0063\n",
      "5633: reward: 114.00, mean_100:  49.68, episodes: 135, reward function loss: -0.0063\n",
      "5816: reward: 183.00, mean_100:  51.32, episodes: 136, reward function loss: -0.0032\n",
      "5871: reward:  55.00, mean_100:  51.73, episodes: 137, reward function loss: -0.0032\n",
      "5998: reward: 127.00, mean_100:  52.68, episodes: 138, reward function loss: -0.0032\n",
      "6029: reward:  31.00, mean_100:  52.74, episodes: 139, reward function loss: -0.0032\n",
      "6088: reward:  59.00, mean_100:  53.15, episodes: 140, reward function loss: -0.0007\n",
      "6281: reward: 193.00, mean_100:  54.89, episodes: 141, reward function loss: -0.0007\n",
      "6506: reward: 225.00, mean_100:  56.71, episodes: 142, reward function loss: -0.0007\n",
      "6688: reward: 182.00, mean_100:  58.37, episodes: 143, reward function loss: -0.0007\n",
      "6830: reward: 142.00, mean_100:  59.59, episodes: 144, reward function loss: -0.0032\n",
      "6996: reward: 166.00, mean_100:  61.07, episodes: 145, reward function loss: -0.0032\n",
      "7191: reward: 195.00, mean_100:  62.81, episodes: 146, reward function loss: -0.0032\n",
      "7287: reward:  96.00, mean_100:  63.58, episodes: 147, reward function loss: -0.0032\n",
      "7514: reward: 227.00, mean_100:  65.69, episodes: 148, reward function loss: -0.0072\n",
      "7590: reward:  76.00, mean_100:  66.23, episodes: 149, reward function loss: -0.0072\n",
      "7807: reward: 217.00, mean_100:  67.98, episodes: 150, reward function loss: -0.0072\n",
      "7905: reward:  98.00, mean_100:  68.81, episodes: 151, reward function loss: -0.0072\n",
      "8049: reward: 144.00, mean_100:  69.91, episodes: 152, reward function loss: -0.0004\n",
      "8206: reward: 157.00, mean_100:  70.81, episodes: 153, reward function loss: -0.0004\n",
      "8363: reward: 157.00, mean_100:  72.20, episodes: 154, reward function loss: -0.0004\n",
      "8494: reward: 131.00, mean_100:  73.18, episodes: 155, reward function loss: -0.0004\n",
      "8557: reward:  63.00, mean_100:  73.53, episodes: 156, reward function loss: -0.0001\n",
      "8788: reward: 231.00, mean_100:  75.64, episodes: 157, reward function loss: -0.0001\n",
      "9074: reward: 286.00, mean_100:  78.15, episodes: 158, reward function loss: -0.0001\n",
      "9230: reward: 156.00, mean_100:  79.51, episodes: 159, reward function loss: -0.0001\n",
      "9401: reward: 171.00, mean_100:  81.13, episodes: 160, reward function loss: -0.0039\n",
      "9593: reward: 192.00, mean_100:  82.72, episodes: 161, reward function loss: -0.0039\n",
      "9824: reward: 231.00, mean_100:  84.78, episodes: 162, reward function loss: -0.0039\n",
      "10043: reward: 219.00, mean_100:  86.74, episodes: 163, reward function loss: -0.0039\n",
      "10240: reward: 197.00, mean_100:  88.57, episodes: 164, reward function loss: -0.0001\n",
      "10493: reward: 253.00, mean_100:  90.85, episodes: 165, reward function loss: -0.0001\n",
      "10685: reward: 192.00, mean_100:  92.30, episodes: 166, reward function loss: -0.0001\n",
      "10858: reward: 173.00, mean_100:  93.63, episodes: 167, reward function loss: -0.0001\n",
      "11094: reward: 236.00, mean_100:  95.75, episodes: 168, reward function loss: -0.0134\n",
      "11292: reward: 198.00, mean_100:  97.10, episodes: 169, reward function loss: -0.0134\n",
      "11550: reward: 258.00, mean_100:  99.49, episodes: 170, reward function loss: -0.0134\n",
      "11833: reward: 283.00, mean_100: 101.83, episodes: 171, reward function loss: -0.0134\n",
      "12333: reward: 500.00, mean_100: 106.10, episodes: 172, reward function loss: -0.0142\n",
      "12833: reward: 500.00, mean_100: 110.92, episodes: 173, reward function loss: -0.0142\n",
      "13026: reward: 193.00, mean_100: 111.67, episodes: 174, reward function loss: -0.0142\n",
      "13301: reward: 275.00, mean_100: 114.16, episodes: 175, reward function loss: -0.0142\n",
      "13801: reward: 500.00, mean_100: 118.79, episodes: 176, reward function loss: -0.0163\n",
      "14081: reward: 280.00, mean_100: 121.19, episodes: 177, reward function loss: -0.0163\n",
      "14207: reward: 126.00, mean_100: 122.16, episodes: 178, reward function loss: -0.0163\n",
      "14653: reward: 446.00, mean_100: 125.75, episodes: 179, reward function loss: -0.0163\n",
      "14936: reward: 283.00, mean_100: 128.34, episodes: 180, reward function loss: -0.0127\n",
      "15118: reward: 182.00, mean_100: 130.01, episodes: 181, reward function loss: -0.0127\n",
      "15618: reward: 500.00, mean_100: 134.50, episodes: 182, reward function loss: -0.0127\n",
      "15984: reward: 366.00, mean_100: 137.87, episodes: 183, reward function loss: -0.0127\n",
      "16484: reward: 500.00, mean_100: 142.23, episodes: 184, reward function loss: -0.0101\n",
      "16911: reward: 427.00, mean_100: 145.99, episodes: 185, reward function loss: -0.0101\n",
      "17167: reward: 256.00, mean_100: 148.43, episodes: 186, reward function loss: -0.0101\n",
      "17443: reward: 276.00, mean_100: 150.93, episodes: 187, reward function loss: -0.0101\n",
      "17943: reward: 500.00, mean_100: 155.53, episodes: 188, reward function loss: -0.0027\n",
      "18406: reward: 463.00, mean_100: 159.35, episodes: 189, reward function loss: -0.0027\n",
      "18906: reward: 500.00, mean_100: 164.15, episodes: 190, reward function loss: -0.0027\n",
      "19406: reward: 500.00, mean_100: 168.83, episodes: 191, reward function loss: -0.0027\n",
      "19857: reward: 451.00, mean_100: 172.95, episodes: 192, reward function loss: 0.0000\n",
      "20073: reward: 216.00, mean_100: 174.81, episodes: 193, reward function loss: 0.0000\n",
      "20573: reward: 500.00, mean_100: 179.50, episodes: 194, reward function loss: 0.0000\n",
      "21073: reward: 500.00, mean_100: 183.88, episodes: 195, reward function loss: 0.0000\n",
      "21387: reward: 314.00, mean_100: 186.26, episodes: 196, reward function loss: -0.0005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21887: reward: 500.00, mean_100: 190.97, episodes: 197, reward function loss: -0.0005\n",
      "22163: reward: 276.00, mean_100: 192.96, episodes: 198, reward function loss: -0.0005\n",
      "22620: reward: 457.00, mean_100: 197.11, episodes: 199, reward function loss: -0.0005\n",
      "23010: reward: 390.00, mean_100: 200.65, episodes: 200, reward function loss: -0.0001\n",
      "23510: reward: 500.00, mean_100: 205.23, episodes: 201, reward function loss: -0.0001\n",
      "24010: reward: 500.00, mean_100: 210.08, episodes: 202, reward function loss: -0.0001\n",
      "24324: reward: 314.00, mean_100: 212.42, episodes: 203, reward function loss: -0.0001\n",
      "24824: reward: 500.00, mean_100: 216.90, episodes: 204, reward function loss: -0.0000\n",
      "24903: reward:  79.00, mean_100: 217.29, episodes: 205, reward function loss: -0.0000\n",
      "25403: reward: 500.00, mean_100: 221.15, episodes: 206, reward function loss: -0.0000\n",
      "25858: reward: 455.00, mean_100: 225.23, episodes: 207, reward function loss: -0.0000\n",
      "26358: reward: 500.00, mean_100: 229.08, episodes: 208, reward function loss: -0.0001\n",
      "26610: reward: 252.00, mean_100: 230.94, episodes: 209, reward function loss: -0.0001\n",
      "27053: reward: 443.00, mean_100: 234.88, episodes: 210, reward function loss: -0.0001\n",
      "27522: reward: 469.00, mean_100: 238.87, episodes: 211, reward function loss: -0.0001\n",
      "27882: reward: 360.00, mean_100: 241.82, episodes: 212, reward function loss: -0.0004\n",
      "28188: reward: 306.00, mean_100: 243.67, episodes: 213, reward function loss: -0.0004\n",
      "28489: reward: 301.00, mean_100: 245.46, episodes: 214, reward function loss: -0.0004\n",
      "28794: reward: 305.00, mean_100: 247.79, episodes: 215, reward function loss: -0.0004\n",
      "29059: reward: 265.00, mean_100: 249.42, episodes: 216, reward function loss: 0.0000\n",
      "29284: reward: 225.00, mean_100: 251.18, episodes: 217, reward function loss: 0.0000\n",
      "29491: reward: 207.00, mean_100: 252.72, episodes: 218, reward function loss: 0.0000\n",
      "29772: reward: 281.00, mean_100: 255.27, episodes: 219, reward function loss: 0.0000\n",
      "29974: reward: 202.00, mean_100: 257.01, episodes: 220, reward function loss: -0.0001\n",
      "30165: reward: 191.00, mean_100: 257.45, episodes: 221, reward function loss: -0.0001\n",
      "30340: reward: 175.00, mean_100: 258.55, episodes: 222, reward function loss: -0.0001\n",
      "30545: reward: 205.00, mean_100: 259.13, episodes: 223, reward function loss: -0.0001\n",
      "30760: reward: 215.00, mean_100: 260.44, episodes: 224, reward function loss: -0.0000\n",
      "30930: reward: 170.00, mean_100: 261.00, episodes: 225, reward function loss: -0.0000\n",
      "31095: reward: 165.00, mean_100: 261.93, episodes: 226, reward function loss: -0.0000\n",
      "31252: reward: 157.00, mean_100: 262.11, episodes: 227, reward function loss: -0.0000\n",
      "31436: reward: 184.00, mean_100: 263.56, episodes: 228, reward function loss: -0.0000\n",
      "31589: reward: 153.00, mean_100: 263.56, episodes: 229, reward function loss: -0.0000\n",
      "31746: reward: 157.00, mean_100: 264.41, episodes: 230, reward function loss: -0.0000\n",
      "31919: reward: 173.00, mean_100: 265.85, episodes: 231, reward function loss: -0.0000\n",
      "32082: reward: 163.00, mean_100: 266.34, episodes: 232, reward function loss: 0.0000\n",
      "32235: reward: 153.00, mean_100: 267.53, episodes: 233, reward function loss: 0.0000\n",
      "32383: reward: 148.00, mean_100: 268.64, episodes: 234, reward function loss: 0.0000\n",
      "32527: reward: 144.00, mean_100: 268.94, episodes: 235, reward function loss: 0.0000\n",
      "32670: reward: 143.00, mean_100: 268.54, episodes: 236, reward function loss: -0.0000\n",
      "32816: reward: 146.00, mean_100: 269.45, episodes: 237, reward function loss: -0.0000\n",
      "32960: reward: 144.00, mean_100: 269.62, episodes: 238, reward function loss: -0.0000\n",
      "33110: reward: 150.00, mean_100: 270.81, episodes: 239, reward function loss: -0.0000\n",
      "33242: reward: 132.00, mean_100: 271.54, episodes: 240, reward function loss: -0.0000\n",
      "33382: reward: 140.00, mean_100: 271.01, episodes: 241, reward function loss: -0.0000\n",
      "33499: reward: 117.00, mean_100: 269.93, episodes: 242, reward function loss: -0.0000\n",
      "33641: reward: 142.00, mean_100: 269.53, episodes: 243, reward function loss: -0.0000\n",
      "33797: reward: 156.00, mean_100: 269.67, episodes: 244, reward function loss: -0.0000\n",
      "33827: reward:  30.00, mean_100: 268.31, episodes: 245, reward function loss: -0.0000\n",
      "33964: reward: 137.00, mean_100: 267.73, episodes: 246, reward function loss: -0.0000\n",
      "34120: reward: 156.00, mean_100: 268.33, episodes: 247, reward function loss: -0.0000\n",
      "34281: reward: 161.00, mean_100: 267.67, episodes: 248, reward function loss: -0.0000\n",
      "34314: reward:  33.00, mean_100: 267.24, episodes: 249, reward function loss: -0.0000\n",
      "34473: reward: 159.00, mean_100: 266.66, episodes: 250, reward function loss: -0.0000\n",
      "34627: reward: 154.00, mean_100: 267.22, episodes: 251, reward function loss: -0.0000\n",
      "34778: reward: 151.00, mean_100: 267.29, episodes: 252, reward function loss: -0.0000\n",
      "34946: reward: 168.00, mean_100: 267.40, episodes: 253, reward function loss: -0.0000\n",
      "35096: reward: 150.00, mean_100: 267.33, episodes: 254, reward function loss: -0.0000\n",
      "35253: reward: 157.00, mean_100: 267.59, episodes: 255, reward function loss: -0.0000\n",
      "35424: reward: 171.00, mean_100: 268.67, episodes: 256, reward function loss: -0.0000\n",
      "35609: reward: 185.00, mean_100: 268.21, episodes: 257, reward function loss: -0.0000\n",
      "35790: reward: 181.00, mean_100: 267.16, episodes: 258, reward function loss: -0.0000\n",
      "35969: reward: 179.00, mean_100: 267.39, episodes: 259, reward function loss: -0.0000\n",
      "36143: reward: 174.00, mean_100: 267.42, episodes: 260, reward function loss: -0.0000\n",
      "36320: reward: 177.00, mean_100: 267.27, episodes: 261, reward function loss: -0.0000\n",
      "36495: reward: 175.00, mean_100: 266.71, episodes: 262, reward function loss: -0.0000\n",
      "36682: reward: 187.00, mean_100: 266.39, episodes: 263, reward function loss: -0.0000\n",
      "36848: reward: 166.00, mean_100: 266.08, episodes: 264, reward function loss: -0.0000\n",
      "37019: reward: 171.00, mean_100: 265.26, episodes: 265, reward function loss: -0.0000\n",
      "37197: reward: 178.00, mean_100: 265.12, episodes: 266, reward function loss: -0.0000\n",
      "37381: reward: 184.00, mean_100: 265.23, episodes: 267, reward function loss: -0.0000\n",
      "37552: reward: 171.00, mean_100: 264.58, episodes: 268, reward function loss: -0.0000\n",
      "37728: reward: 176.00, mean_100: 264.36, episodes: 269, reward function loss: -0.0000\n",
      "37907: reward: 179.00, mean_100: 263.57, episodes: 270, reward function loss: -0.0000\n",
      "38098: reward: 191.00, mean_100: 262.65, episodes: 271, reward function loss: -0.0000\n",
      "38275: reward: 177.00, mean_100: 259.42, episodes: 272, reward function loss: -0.0000\n",
      "38444: reward: 169.00, mean_100: 256.11, episodes: 273, reward function loss: -0.0000\n",
      "38601: reward: 157.00, mean_100: 255.75, episodes: 274, reward function loss: -0.0000\n",
      "38760: reward: 159.00, mean_100: 254.59, episodes: 275, reward function loss: -0.0000\n",
      "38928: reward: 168.00, mean_100: 251.27, episodes: 276, reward function loss: -0.0000\n",
      "39079: reward: 151.00, mean_100: 249.98, episodes: 277, reward function loss: -0.0000\n",
      "39245: reward: 166.00, mean_100: 250.38, episodes: 278, reward function loss: -0.0000\n",
      "39407: reward: 162.00, mean_100: 247.54, episodes: 279, reward function loss: -0.0000\n",
      "39563: reward: 156.00, mean_100: 246.27, episodes: 280, reward function loss: -0.0000\n",
      "39714: reward: 151.00, mean_100: 245.96, episodes: 281, reward function loss: -0.0000\n",
      "39858: reward: 144.00, mean_100: 242.40, episodes: 282, reward function loss: -0.0000\n",
      "40012: reward: 154.00, mean_100: 240.28, episodes: 283, reward function loss: -0.0000\n",
      "40157: reward: 145.00, mean_100: 236.73, episodes: 284, reward function loss: -0.0001\n",
      "40265: reward: 108.00, mean_100: 233.54, episodes: 285, reward function loss: -0.0001\n",
      "40409: reward: 144.00, mean_100: 232.42, episodes: 286, reward function loss: -0.0001\n",
      "40565: reward: 156.00, mean_100: 231.22, episodes: 287, reward function loss: -0.0001\n",
      "40589: reward:  24.00, mean_100: 226.46, episodes: 288, reward function loss: -0.0001\n",
      "40720: reward: 131.00, mean_100: 223.14, episodes: 289, reward function loss: -0.0001\n",
      "40862: reward: 142.00, mean_100: 219.56, episodes: 290, reward function loss: -0.0001\n",
      "40999: reward: 137.00, mean_100: 215.93, episodes: 291, reward function loss: -0.0001\n",
      "41023: reward:  24.00, mean_100: 211.66, episodes: 292, reward function loss: -0.0002\n",
      "41143: reward: 120.00, mean_100: 210.70, episodes: 293, reward function loss: -0.0002\n",
      "41270: reward: 127.00, mean_100: 206.97, episodes: 294, reward function loss: -0.0002\n",
      "41301: reward:  31.00, mean_100: 202.28, episodes: 295, reward function loss: -0.0002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41432: reward: 131.00, mean_100: 200.45, episodes: 296, reward function loss: -0.0004\n",
      "41543: reward: 111.00, mean_100: 196.56, episodes: 297, reward function loss: -0.0004\n",
      "41645: reward: 102.00, mean_100: 194.82, episodes: 298, reward function loss: -0.0004\n",
      "41767: reward: 122.00, mean_100: 191.47, episodes: 299, reward function loss: -0.0004\n",
      "41871: reward: 104.00, mean_100: 188.61, episodes: 300, reward function loss: -0.0017\n",
      "41896: reward:  25.00, mean_100: 183.86, episodes: 301, reward function loss: -0.0017\n",
      "42007: reward: 111.00, mean_100: 179.97, episodes: 302, reward function loss: -0.0017\n",
      "42113: reward: 106.00, mean_100: 177.89, episodes: 303, reward function loss: -0.0017\n",
      "42138: reward:  25.00, mean_100: 173.14, episodes: 304, reward function loss: -0.0017\n",
      "42166: reward:  28.00, mean_100: 172.63, episodes: 305, reward function loss: -0.0017\n",
      "42278: reward: 112.00, mean_100: 168.75, episodes: 306, reward function loss: -0.0017\n",
      "42299: reward:  21.00, mean_100: 164.41, episodes: 307, reward function loss: -0.0017\n",
      "42326: reward:  27.00, mean_100: 159.68, episodes: 308, reward function loss: -0.0019\n",
      "42352: reward:  26.00, mean_100: 157.42, episodes: 309, reward function loss: -0.0019\n",
      "42376: reward:  24.00, mean_100: 153.23, episodes: 310, reward function loss: -0.0019\n",
      "42472: reward:  96.00, mean_100: 149.50, episodes: 311, reward function loss: -0.0019\n",
      "42499: reward:  27.00, mean_100: 146.17, episodes: 312, reward function loss: -0.0034\n",
      "42523: reward:  24.00, mean_100: 143.35, episodes: 313, reward function loss: -0.0034\n",
      "42614: reward:  91.00, mean_100: 141.25, episodes: 314, reward function loss: -0.0034\n",
      "42642: reward:  28.00, mean_100: 138.48, episodes: 315, reward function loss: -0.0034\n",
      "42659: reward:  17.00, mean_100: 136.00, episodes: 316, reward function loss: -0.0031\n",
      "42679: reward:  20.00, mean_100: 133.95, episodes: 317, reward function loss: -0.0031\n",
      "42704: reward:  25.00, mean_100: 132.13, episodes: 318, reward function loss: -0.0031\n",
      "42806: reward: 102.00, mean_100: 130.34, episodes: 319, reward function loss: -0.0031\n",
      "42830: reward:  24.00, mean_100: 128.56, episodes: 320, reward function loss: -0.0035\n",
      "42844: reward:  14.00, mean_100: 126.79, episodes: 321, reward function loss: -0.0035\n",
      "42946: reward: 102.00, mean_100: 126.06, episodes: 322, reward function loss: -0.0035\n",
      "42972: reward:  26.00, mean_100: 124.27, episodes: 323, reward function loss: -0.0035\n",
      "42987: reward:  15.00, mean_100: 122.27, episodes: 324, reward function loss: -0.0030\n",
      "43008: reward:  21.00, mean_100: 120.78, episodes: 325, reward function loss: -0.0030\n",
      "43110: reward: 102.00, mean_100: 120.15, episodes: 326, reward function loss: -0.0030\n",
      "43141: reward:  31.00, mean_100: 118.89, episodes: 327, reward function loss: -0.0030\n",
      "43263: reward: 122.00, mean_100: 118.27, episodes: 328, reward function loss: -0.0057\n",
      "43368: reward: 105.00, mean_100: 117.79, episodes: 329, reward function loss: -0.0057\n",
      "43472: reward: 104.00, mean_100: 117.26, episodes: 330, reward function loss: -0.0057\n",
      "43575: reward: 103.00, mean_100: 116.56, episodes: 331, reward function loss: -0.0057\n",
      "43590: reward:  15.00, mean_100: 115.08, episodes: 332, reward function loss: -0.0070\n",
      "43619: reward:  29.00, mean_100: 113.84, episodes: 333, reward function loss: -0.0070\n",
      "43638: reward:  19.00, mean_100: 112.55, episodes: 334, reward function loss: -0.0070\n",
      "43662: reward:  24.00, mean_100: 111.35, episodes: 335, reward function loss: -0.0070\n",
      "43685: reward:  23.00, mean_100: 110.15, episodes: 336, reward function loss: -0.0014\n",
      "43795: reward: 110.00, mean_100: 109.79, episodes: 337, reward function loss: -0.0014\n",
      "43889: reward:  94.00, mean_100: 109.29, episodes: 338, reward function loss: -0.0014\n",
      "43993: reward: 104.00, mean_100: 108.83, episodes: 339, reward function loss: -0.0014\n",
      "44101: reward: 108.00, mean_100: 108.59, episodes: 340, reward function loss: -0.0089\n",
      "44205: reward: 104.00, mean_100: 108.23, episodes: 341, reward function loss: -0.0089\n",
      "44225: reward:  20.00, mean_100: 107.26, episodes: 342, reward function loss: -0.0089\n",
      "44333: reward: 108.00, mean_100: 106.92, episodes: 343, reward function loss: -0.0089\n",
      "44446: reward: 113.00, mean_100: 106.49, episodes: 344, reward function loss: -0.0072\n",
      "44474: reward:  28.00, mean_100: 106.47, episodes: 345, reward function loss: -0.0072\n",
      "44585: reward: 111.00, mean_100: 106.21, episodes: 346, reward function loss: -0.0072\n",
      "44623: reward:  38.00, mean_100: 105.03, episodes: 347, reward function loss: -0.0072\n",
      "44732: reward: 109.00, mean_100: 104.51, episodes: 348, reward function loss: -0.0058\n",
      "44839: reward: 107.00, mean_100: 105.25, episodes: 349, reward function loss: -0.0058\n",
      "44952: reward: 113.00, mean_100: 104.79, episodes: 350, reward function loss: -0.0058\n",
      "45048: reward:  96.00, mean_100: 104.21, episodes: 351, reward function loss: -0.0058\n",
      "45152: reward: 104.00, mean_100: 103.74, episodes: 352, reward function loss: -0.0093\n",
      "45271: reward: 119.00, mean_100: 103.25, episodes: 353, reward function loss: -0.0093\n",
      "45383: reward: 112.00, mean_100: 102.87, episodes: 354, reward function loss: -0.0093\n",
      "45501: reward: 118.00, mean_100: 102.48, episodes: 355, reward function loss: -0.0093\n",
      "45621: reward: 120.00, mean_100: 101.97, episodes: 356, reward function loss: -0.0103\n",
      "45736: reward: 115.00, mean_100: 101.27, episodes: 357, reward function loss: -0.0103\n",
      "45860: reward: 124.00, mean_100: 100.70, episodes: 358, reward function loss: -0.0103\n",
      "45972: reward: 112.00, mean_100: 100.03, episodes: 359, reward function loss: -0.0103\n",
      "46090: reward: 118.00, mean_100:  99.47, episodes: 360, reward function loss: -0.0045\n",
      "46209: reward: 119.00, mean_100:  98.89, episodes: 361, reward function loss: -0.0045\n",
      "46334: reward: 125.00, mean_100:  98.39, episodes: 362, reward function loss: -0.0045\n",
      "46449: reward: 115.00, mean_100:  97.67, episodes: 363, reward function loss: -0.0045\n",
      "46562: reward: 113.00, mean_100:  97.14, episodes: 364, reward function loss: -0.0088\n",
      "46681: reward: 119.00, mean_100:  96.62, episodes: 365, reward function loss: -0.0088\n",
      "46808: reward: 127.00, mean_100:  96.11, episodes: 366, reward function loss: -0.0088\n",
      "46841: reward:  33.00, mean_100:  94.60, episodes: 367, reward function loss: -0.0088\n",
      "46955: reward: 114.00, mean_100:  94.03, episodes: 368, reward function loss: -0.0076\n",
      "47081: reward: 126.00, mean_100:  93.53, episodes: 369, reward function loss: -0.0076\n",
      "47212: reward: 131.00, mean_100:  93.05, episodes: 370, reward function loss: -0.0076\n",
      "47328: reward: 116.00, mean_100:  92.30, episodes: 371, reward function loss: -0.0076\n",
      "47454: reward: 126.00, mean_100:  91.79, episodes: 372, reward function loss: -0.0103\n",
      "47577: reward: 123.00, mean_100:  91.33, episodes: 373, reward function loss: -0.0103\n",
      "47713: reward: 136.00, mean_100:  91.12, episodes: 374, reward function loss: -0.0103\n",
      "47841: reward: 128.00, mean_100:  90.81, episodes: 375, reward function loss: -0.0103\n",
      "47965: reward: 124.00, mean_100:  90.37, episodes: 376, reward function loss: -0.0108\n",
      "48097: reward: 132.00, mean_100:  90.18, episodes: 377, reward function loss: -0.0108\n",
      "48124: reward:  27.00, mean_100:  88.79, episodes: 378, reward function loss: -0.0108\n",
      "48264: reward: 140.00, mean_100:  88.57, episodes: 379, reward function loss: -0.0108\n",
      "48398: reward: 134.00, mean_100:  88.35, episodes: 380, reward function loss: -0.0086\n",
      "48540: reward: 142.00, mean_100:  88.26, episodes: 381, reward function loss: -0.0086\n",
      "48665: reward: 125.00, mean_100:  88.07, episodes: 382, reward function loss: -0.0086\n",
      "48806: reward: 141.00, mean_100:  87.94, episodes: 383, reward function loss: -0.0086\n",
      "48937: reward: 131.00, mean_100:  87.80, episodes: 384, reward function loss: -0.0117\n",
      "49068: reward: 131.00, mean_100:  88.03, episodes: 385, reward function loss: -0.0117\n",
      "49190: reward: 122.00, mean_100:  87.81, episodes: 386, reward function loss: -0.0117\n",
      "49323: reward: 133.00, mean_100:  87.58, episodes: 387, reward function loss: -0.0117\n",
      "49445: reward: 122.00, mean_100:  88.56, episodes: 388, reward function loss: -0.0101\n",
      "49569: reward: 124.00, mean_100:  88.49, episodes: 389, reward function loss: -0.0101\n",
      "49700: reward: 131.00, mean_100:  88.38, episodes: 390, reward function loss: -0.0101\n",
      "49835: reward: 135.00, mean_100:  88.36, episodes: 391, reward function loss: -0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49974: reward: 139.00, mean_100:  89.51, episodes: 392, reward function loss: -0.0110\n",
      "50119: reward: 145.00, mean_100:  89.76, episodes: 393, reward function loss: -0.0110\n",
      "50253: reward: 134.00, mean_100:  89.83, episodes: 394, reward function loss: -0.0110\n",
      "50400: reward: 147.00, mean_100:  90.99, episodes: 395, reward function loss: -0.0110\n",
      "50528: reward: 128.00, mean_100:  90.96, episodes: 396, reward function loss: -0.0115\n",
      "50673: reward: 145.00, mean_100:  91.30, episodes: 397, reward function loss: -0.0115\n",
      "50808: reward: 135.00, mean_100:  91.63, episodes: 398, reward function loss: -0.0115\n",
      "50952: reward: 144.00, mean_100:  91.85, episodes: 399, reward function loss: -0.0115\n",
      "51094: reward: 142.00, mean_100:  92.23, episodes: 400, reward function loss: -0.0104\n",
      "51237: reward: 143.00, mean_100:  93.41, episodes: 401, reward function loss: -0.0104\n",
      "51365: reward: 128.00, mean_100:  93.58, episodes: 402, reward function loss: -0.0104\n",
      "51516: reward: 151.00, mean_100:  94.03, episodes: 403, reward function loss: -0.0104\n",
      "51656: reward: 140.00, mean_100:  95.18, episodes: 404, reward function loss: -0.0028\n",
      "51803: reward: 147.00, mean_100:  96.37, episodes: 405, reward function loss: -0.0028\n",
      "51936: reward: 133.00, mean_100:  96.58, episodes: 406, reward function loss: -0.0028\n",
      "52076: reward: 140.00, mean_100:  97.77, episodes: 407, reward function loss: -0.0028\n",
      "52227: reward: 151.00, mean_100:  99.01, episodes: 408, reward function loss: -0.0112\n",
      "52360: reward: 133.00, mean_100: 100.08, episodes: 409, reward function loss: -0.0112\n",
      "52505: reward: 145.00, mean_100: 101.29, episodes: 410, reward function loss: -0.0112\n",
      "52666: reward: 161.00, mean_100: 101.94, episodes: 411, reward function loss: -0.0112\n",
      "52808: reward: 142.00, mean_100: 103.09, episodes: 412, reward function loss: -0.0113\n",
      "52960: reward: 152.00, mean_100: 104.37, episodes: 413, reward function loss: -0.0113\n",
      "53108: reward: 148.00, mean_100: 104.94, episodes: 414, reward function loss: -0.0113\n",
      "53265: reward: 157.00, mean_100: 106.23, episodes: 415, reward function loss: -0.0113\n",
      "53404: reward: 139.00, mean_100: 107.45, episodes: 416, reward function loss: -0.0116\n",
      "53555: reward: 151.00, mean_100: 108.76, episodes: 417, reward function loss: -0.0116\n",
      "53703: reward: 148.00, mean_100: 109.99, episodes: 418, reward function loss: -0.0116\n",
      "53861: reward: 158.00, mean_100: 110.55, episodes: 419, reward function loss: -0.0116\n",
      "54029: reward: 168.00, mean_100: 111.99, episodes: 420, reward function loss: -0.0125\n",
      "54176: reward: 147.00, mean_100: 113.32, episodes: 421, reward function loss: -0.0125\n",
      "54320: reward: 144.00, mean_100: 113.74, episodes: 422, reward function loss: -0.0125\n",
      "54476: reward: 156.00, mean_100: 115.04, episodes: 423, reward function loss: -0.0125\n",
      "54640: reward: 164.00, mean_100: 116.53, episodes: 424, reward function loss: -0.0126\n",
      "54793: reward: 153.00, mean_100: 117.85, episodes: 425, reward function loss: -0.0126\n",
      "54955: reward: 162.00, mean_100: 118.45, episodes: 426, reward function loss: -0.0126\n",
      "55125: reward: 170.00, mean_100: 119.84, episodes: 427, reward function loss: -0.0126\n",
      "55296: reward: 171.00, mean_100: 120.33, episodes: 428, reward function loss: -0.0134\n",
      "55452: reward: 156.00, mean_100: 120.84, episodes: 429, reward function loss: -0.0134\n",
      "55620: reward: 168.00, mean_100: 121.48, episodes: 430, reward function loss: -0.0134\n",
      "55786: reward: 166.00, mean_100: 122.11, episodes: 431, reward function loss: -0.0134\n",
      "55941: reward: 155.00, mean_100: 123.51, episodes: 432, reward function loss: -0.0135\n",
      "56101: reward: 160.00, mean_100: 124.82, episodes: 433, reward function loss: -0.0135\n",
      "56289: reward: 188.00, mean_100: 126.51, episodes: 434, reward function loss: -0.0135\n",
      "56454: reward: 165.00, mean_100: 127.92, episodes: 435, reward function loss: -0.0135\n",
      "56628: reward: 174.00, mean_100: 129.43, episodes: 436, reward function loss: -0.0139\n",
      "56804: reward: 176.00, mean_100: 130.09, episodes: 437, reward function loss: -0.0139\n",
      "56975: reward: 171.00, mean_100: 130.86, episodes: 438, reward function loss: -0.0139\n",
      "57151: reward: 176.00, mean_100: 131.58, episodes: 439, reward function loss: -0.0139\n",
      "57334: reward: 183.00, mean_100: 132.33, episodes: 440, reward function loss: -0.0148\n",
      "57507: reward: 173.00, mean_100: 133.02, episodes: 441, reward function loss: -0.0148\n",
      "57687: reward: 180.00, mean_100: 134.62, episodes: 442, reward function loss: -0.0148\n",
      "57850: reward: 163.00, mean_100: 135.17, episodes: 443, reward function loss: -0.0148\n",
      "58024: reward: 174.00, mean_100: 135.78, episodes: 444, reward function loss: -0.0097\n",
      "58213: reward: 189.00, mean_100: 137.39, episodes: 445, reward function loss: -0.0097\n",
      "58393: reward: 180.00, mean_100: 138.08, episodes: 446, reward function loss: -0.0097\n",
      "58570: reward: 177.00, mean_100: 139.47, episodes: 447, reward function loss: -0.0097\n",
      "58740: reward: 170.00, mean_100: 140.08, episodes: 448, reward function loss: -0.0136\n",
      "58922: reward: 182.00, mean_100: 140.83, episodes: 449, reward function loss: -0.0136\n",
      "59093: reward: 171.00, mean_100: 141.41, episodes: 450, reward function loss: -0.0136\n",
      "59296: reward: 203.00, mean_100: 142.48, episodes: 451, reward function loss: -0.0136\n",
      "59495: reward: 199.00, mean_100: 143.43, episodes: 452, reward function loss: -0.0147\n",
      "59682: reward: 187.00, mean_100: 144.11, episodes: 453, reward function loss: -0.0147\n",
      "59880: reward: 198.00, mean_100: 144.97, episodes: 454, reward function loss: -0.0147\n",
      "60071: reward: 191.00, mean_100: 145.70, episodes: 455, reward function loss: -0.0147\n",
      "60257: reward: 186.00, mean_100: 146.36, episodes: 456, reward function loss: -0.0146\n",
      "60467: reward: 210.00, mean_100: 147.31, episodes: 457, reward function loss: -0.0146\n",
      "60675: reward: 208.00, mean_100: 148.15, episodes: 458, reward function loss: -0.0146\n",
      "60859: reward: 184.00, mean_100: 148.87, episodes: 459, reward function loss: -0.0146\n",
      "61071: reward: 212.00, mean_100: 149.81, episodes: 460, reward function loss: -0.0163\n",
      "61264: reward: 193.00, mean_100: 150.55, episodes: 461, reward function loss: -0.0163\n",
      "61491: reward: 227.00, mean_100: 151.57, episodes: 462, reward function loss: -0.0163\n",
      "61690: reward: 199.00, mean_100: 152.41, episodes: 463, reward function loss: -0.0163\n",
      "61884: reward: 194.00, mean_100: 153.22, episodes: 464, reward function loss: -0.0150\n",
      "62111: reward: 227.00, mean_100: 154.30, episodes: 465, reward function loss: -0.0150\n",
      "62311: reward: 200.00, mean_100: 155.03, episodes: 466, reward function loss: -0.0150\n",
      "62559: reward: 248.00, mean_100: 157.18, episodes: 467, reward function loss: -0.0150\n",
      "62789: reward: 230.00, mean_100: 158.34, episodes: 468, reward function loss: -0.0171\n",
      "63046: reward: 257.00, mean_100: 159.65, episodes: 469, reward function loss: -0.0171\n",
      "63285: reward: 239.00, mean_100: 160.73, episodes: 470, reward function loss: -0.0171\n",
      "63525: reward: 240.00, mean_100: 161.97, episodes: 471, reward function loss: -0.0171\n",
      "63739: reward: 214.00, mean_100: 162.85, episodes: 472, reward function loss: -0.0141\n",
      "63999: reward: 260.00, mean_100: 164.22, episodes: 473, reward function loss: -0.0141\n",
      "64259: reward: 260.00, mean_100: 165.46, episodes: 474, reward function loss: -0.0141\n",
      "64511: reward: 252.00, mean_100: 166.70, episodes: 475, reward function loss: -0.0141\n",
      "64776: reward: 265.00, mean_100: 168.11, episodes: 476, reward function loss: -0.0196\n",
      "65062: reward: 286.00, mean_100: 169.65, episodes: 477, reward function loss: -0.0196\n",
      "65330: reward: 268.00, mean_100: 172.06, episodes: 478, reward function loss: -0.0196\n",
      "65632: reward: 302.00, mean_100: 173.68, episodes: 479, reward function loss: -0.0196\n",
      "65888: reward: 256.00, mean_100: 174.90, episodes: 480, reward function loss: -0.0146\n",
      "66169: reward: 281.00, mean_100: 176.29, episodes: 481, reward function loss: -0.0146\n",
      "66498: reward: 329.00, mean_100: 178.33, episodes: 482, reward function loss: -0.0146\n",
      "66791: reward: 293.00, mean_100: 179.85, episodes: 483, reward function loss: -0.0146\n",
      "67101: reward: 310.00, mean_100: 181.64, episodes: 484, reward function loss: -0.0189\n",
      "67459: reward: 358.00, mean_100: 183.91, episodes: 485, reward function loss: -0.0189\n",
      "67778: reward: 319.00, mean_100: 185.88, episodes: 486, reward function loss: -0.0189\n",
      "68157: reward: 379.00, mean_100: 188.34, episodes: 487, reward function loss: -0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68516: reward: 359.00, mean_100: 190.71, episodes: 488, reward function loss: -0.0222\n",
      "68894: reward: 378.00, mean_100: 193.25, episodes: 489, reward function loss: -0.0222\n",
      "69264: reward: 370.00, mean_100: 195.64, episodes: 490, reward function loss: -0.0222\n",
      "69618: reward: 354.00, mean_100: 197.83, episodes: 491, reward function loss: -0.0222\n",
      "69984: reward: 366.00, mean_100: 200.10, episodes: 492, reward function loss: -0.0228\n",
      "70416: reward: 432.00, mean_100: 202.97, episodes: 493, reward function loss: -0.0228\n",
      "70812: reward: 396.00, mean_100: 205.59, episodes: 494, reward function loss: -0.0228\n",
      "71222: reward: 410.00, mean_100: 208.22, episodes: 495, reward function loss: -0.0228\n",
      "71644: reward: 422.00, mean_100: 211.16, episodes: 496, reward function loss: -0.0279\n",
      "72144: reward: 500.00, mean_100: 214.71, episodes: 497, reward function loss: -0.0279\n",
      "72623: reward: 479.00, mean_100: 218.15, episodes: 498, reward function loss: -0.0279\n",
      "73059: reward: 436.00, mean_100: 221.07, episodes: 499, reward function loss: -0.0279\n",
      "73507: reward: 448.00, mean_100: 224.13, episodes: 500, reward function loss: -0.0320\n",
      "73964: reward: 457.00, mean_100: 227.27, episodes: 501, reward function loss: -0.0320\n",
      "74464: reward: 500.00, mean_100: 230.99, episodes: 502, reward function loss: -0.0320\n",
      "74964: reward: 500.00, mean_100: 234.48, episodes: 503, reward function loss: -0.0320\n",
      "75448: reward: 484.00, mean_100: 237.92, episodes: 504, reward function loss: -0.0294\n",
      "75948: reward: 500.00, mean_100: 241.45, episodes: 505, reward function loss: -0.0294\n",
      "76448: reward: 500.00, mean_100: 245.12, episodes: 506, reward function loss: -0.0294\n",
      "76948: reward: 500.00, mean_100: 248.72, episodes: 507, reward function loss: -0.0294\n",
      "77448: reward: 500.00, mean_100: 252.21, episodes: 508, reward function loss: -0.0301\n",
      "77948: reward: 500.00, mean_100: 255.88, episodes: 509, reward function loss: -0.0301\n",
      "78448: reward: 500.00, mean_100: 259.43, episodes: 510, reward function loss: -0.0301\n",
      "78948: reward: 500.00, mean_100: 262.82, episodes: 511, reward function loss: -0.0301\n",
      "79448: reward: 500.00, mean_100: 266.40, episodes: 512, reward function loss: -0.0288\n",
      "79948: reward: 500.00, mean_100: 269.88, episodes: 513, reward function loss: -0.0288\n",
      "80448: reward: 500.00, mean_100: 273.40, episodes: 514, reward function loss: -0.0288\n",
      "80948: reward: 500.00, mean_100: 276.83, episodes: 515, reward function loss: -0.0288\n",
      "81448: reward: 500.00, mean_100: 280.44, episodes: 516, reward function loss: -0.0249\n",
      "81948: reward: 500.00, mean_100: 283.93, episodes: 517, reward function loss: -0.0249\n",
      "82448: reward: 500.00, mean_100: 287.45, episodes: 518, reward function loss: -0.0249\n",
      "82948: reward: 500.00, mean_100: 290.87, episodes: 519, reward function loss: -0.0249\n",
      "83448: reward: 500.00, mean_100: 294.19, episodes: 520, reward function loss: -0.0262\n",
      "83948: reward: 500.00, mean_100: 297.72, episodes: 521, reward function loss: -0.0262\n",
      "84448: reward: 500.00, mean_100: 301.28, episodes: 522, reward function loss: -0.0262\n",
      "84948: reward: 500.00, mean_100: 304.72, episodes: 523, reward function loss: -0.0262\n",
      "85448: reward: 500.00, mean_100: 308.08, episodes: 524, reward function loss: -0.0153\n",
      "85948: reward: 500.00, mean_100: 311.55, episodes: 525, reward function loss: -0.0153\n",
      "86448: reward: 500.00, mean_100: 314.93, episodes: 526, reward function loss: -0.0153\n",
      "86948: reward: 500.00, mean_100: 318.23, episodes: 527, reward function loss: -0.0153\n",
      "87448: reward: 500.00, mean_100: 321.52, episodes: 528, reward function loss: -0.0007\n",
      "87948: reward: 500.00, mean_100: 324.96, episodes: 529, reward function loss: -0.0007\n",
      "88448: reward: 500.00, mean_100: 328.28, episodes: 530, reward function loss: -0.0007\n",
      "88948: reward: 500.00, mean_100: 331.62, episodes: 531, reward function loss: -0.0007\n",
      "89448: reward: 500.00, mean_100: 335.07, episodes: 532, reward function loss: -0.0000\n",
      "89948: reward: 500.00, mean_100: 338.47, episodes: 533, reward function loss: -0.0000\n",
      "90448: reward: 500.00, mean_100: 341.59, episodes: 534, reward function loss: -0.0000\n",
      "90948: reward: 500.00, mean_100: 344.94, episodes: 535, reward function loss: -0.0000\n",
      "91448: reward: 500.00, mean_100: 348.20, episodes: 536, reward function loss: -0.0000\n",
      "91948: reward: 500.00, mean_100: 351.44, episodes: 537, reward function loss: -0.0000\n",
      "92448: reward: 500.00, mean_100: 354.73, episodes: 538, reward function loss: -0.0000\n",
      "92948: reward: 500.00, mean_100: 357.97, episodes: 539, reward function loss: -0.0000\n",
      "93448: reward: 500.00, mean_100: 361.14, episodes: 540, reward function loss: -0.0000\n",
      "93948: reward: 500.00, mean_100: 364.41, episodes: 541, reward function loss: -0.0000\n",
      "94448: reward: 500.00, mean_100: 367.61, episodes: 542, reward function loss: -0.0000\n",
      "94948: reward: 500.00, mean_100: 370.98, episodes: 543, reward function loss: -0.0000\n",
      "95448: reward: 500.00, mean_100: 374.24, episodes: 544, reward function loss: -0.0000\n",
      "95948: reward: 500.00, mean_100: 377.35, episodes: 545, reward function loss: -0.0000\n",
      "96448: reward: 500.00, mean_100: 380.55, episodes: 546, reward function loss: -0.0000\n",
      "96948: reward: 500.00, mean_100: 383.78, episodes: 547, reward function loss: -0.0000\n",
      "97448: reward: 500.00, mean_100: 387.08, episodes: 548, reward function loss: -0.0000\n",
      "97948: reward: 500.00, mean_100: 390.26, episodes: 549, reward function loss: -0.0000\n",
      "98448: reward: 500.00, mean_100: 393.55, episodes: 550, reward function loss: -0.0000\n",
      "98948: reward: 500.00, mean_100: 396.52, episodes: 551, reward function loss: -0.0000\n",
      "99448: reward: 500.00, mean_100: 399.53, episodes: 552, reward function loss: -0.0000\n",
      "99948: reward: 500.00, mean_100: 402.66, episodes: 553, reward function loss: -0.0000\n",
      "100448: reward: 500.00, mean_100: 405.68, episodes: 554, reward function loss: -0.0000\n",
      "100948: reward: 500.00, mean_100: 408.77, episodes: 555, reward function loss: -0.0000\n",
      "101448: reward: 500.00, mean_100: 411.91, episodes: 556, reward function loss: -0.0000\n",
      "101948: reward: 500.00, mean_100: 414.81, episodes: 557, reward function loss: -0.0000\n",
      "102448: reward: 500.00, mean_100: 417.73, episodes: 558, reward function loss: -0.0000\n",
      "102948: reward: 500.00, mean_100: 420.89, episodes: 559, reward function loss: -0.0000\n",
      "103448: reward: 500.00, mean_100: 423.77, episodes: 560, reward function loss: -0.0000\n",
      "103948: reward: 500.00, mean_100: 426.84, episodes: 561, reward function loss: -0.0000\n",
      "104448: reward: 500.00, mean_100: 429.57, episodes: 562, reward function loss: -0.0000\n",
      "104948: reward: 500.00, mean_100: 432.58, episodes: 563, reward function loss: -0.0000\n",
      "105448: reward: 500.00, mean_100: 435.64, episodes: 564, reward function loss: -0.0000\n",
      "105948: reward: 500.00, mean_100: 438.37, episodes: 565, reward function loss: -0.0000\n",
      "106448: reward: 500.00, mean_100: 441.37, episodes: 566, reward function loss: -0.0000\n",
      "106948: reward: 500.00, mean_100: 443.89, episodes: 567, reward function loss: -0.0000\n",
      "107448: reward: 500.00, mean_100: 446.59, episodes: 568, reward function loss: -0.0000\n",
      "107948: reward: 500.00, mean_100: 449.02, episodes: 569, reward function loss: -0.0000\n",
      "108448: reward: 500.00, mean_100: 451.63, episodes: 570, reward function loss: -0.0000\n",
      "108948: reward: 500.00, mean_100: 454.23, episodes: 571, reward function loss: -0.0000\n",
      "109448: reward: 500.00, mean_100: 457.09, episodes: 572, reward function loss: -0.0000\n",
      "109948: reward: 500.00, mean_100: 459.49, episodes: 573, reward function loss: -0.0000\n",
      "110448: reward: 500.00, mean_100: 461.89, episodes: 574, reward function loss: -0.0000\n",
      "110948: reward: 500.00, mean_100: 464.37, episodes: 575, reward function loss: -0.0000\n",
      "111448: reward: 500.00, mean_100: 466.72, episodes: 576, reward function loss: -0.0000\n",
      "111948: reward: 500.00, mean_100: 468.86, episodes: 577, reward function loss: -0.0000\n",
      "112448: reward: 500.00, mean_100: 471.18, episodes: 578, reward function loss: -0.0000\n",
      "112948: reward: 500.00, mean_100: 473.16, episodes: 579, reward function loss: -0.0000\n",
      "113448: reward: 500.00, mean_100: 475.60, episodes: 580, reward function loss: -0.0001\n",
      "113948: reward: 500.00, mean_100: 477.79, episodes: 581, reward function loss: -0.0001\n",
      "114448: reward: 500.00, mean_100: 479.50, episodes: 582, reward function loss: -0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114948: reward: 500.00, mean_100: 481.57, episodes: 583, reward function loss: -0.0001\n",
      "115448: reward: 500.00, mean_100: 483.47, episodes: 584, reward function loss: -0.0001\n",
      "115948: reward: 500.00, mean_100: 484.89, episodes: 585, reward function loss: -0.0001\n",
      "116448: reward: 500.00, mean_100: 486.70, episodes: 586, reward function loss: -0.0001\n",
      "116948: reward: 500.00, mean_100: 487.91, episodes: 587, reward function loss: -0.0001\n",
      "117448: reward: 500.00, mean_100: 489.32, episodes: 588, reward function loss: -0.0002\n",
      "117948: reward: 500.00, mean_100: 490.54, episodes: 589, reward function loss: -0.0002\n",
      "118448: reward: 500.00, mean_100: 491.84, episodes: 590, reward function loss: -0.0002\n",
      "118948: reward: 500.00, mean_100: 493.30, episodes: 591, reward function loss: -0.0002\n",
      "119448: reward: 500.00, mean_100: 494.64, episodes: 592, reward function loss: -0.0018\n",
      "119948: reward: 500.00, mean_100: 495.32, episodes: 593, reward function loss: -0.0018\n",
      "120448: reward: 500.00, mean_100: 496.36, episodes: 594, reward function loss: -0.0018\n",
      "120948: reward: 500.00, mean_100: 497.26, episodes: 595, reward function loss: -0.0018\n",
      "121448: reward: 500.00, mean_100: 498.04, episodes: 596, reward function loss: -0.0194\n",
      "121948: reward: 500.00, mean_100: 498.04, episodes: 597, reward function loss: -0.0194\n",
      "122448: reward: 500.00, mean_100: 498.25, episodes: 598, reward function loss: -0.0194\n",
      "122948: reward: 500.00, mean_100: 498.89, episodes: 599, reward function loss: -0.0194\n",
      "123448: reward: 500.00, mean_100: 499.41, episodes: 600, reward function loss: -0.0456\n",
      "123948: reward: 500.00, mean_100: 499.84, episodes: 601, reward function loss: -0.0456\n",
      "124448: reward: 500.00, mean_100: 499.84, episodes: 602, reward function loss: -0.0456\n",
      "124948: reward: 500.00, mean_100: 499.84, episodes: 603, reward function loss: -0.0456\n",
      "125448: reward: 500.00, mean_100: 500.00, episodes: 604, reward function loss: -0.0470\n",
      "125948: reward: 500.00, mean_100: 500.00, episodes: 605, reward function loss: -0.0470\n",
      "126448: reward: 500.00, mean_100: 500.00, episodes: 606, reward function loss: -0.0470\n",
      "126948: reward: 500.00, mean_100: 500.00, episodes: 607, reward function loss: -0.0470\n",
      "127448: reward: 500.00, mean_100: 500.00, episodes: 608, reward function loss: -0.0470\n",
      "127948: reward: 500.00, mean_100: 500.00, episodes: 609, reward function loss: -0.0470\n",
      "128448: reward: 500.00, mean_100: 500.00, episodes: 610, reward function loss: -0.0470\n",
      "128948: reward: 500.00, mean_100: 500.00, episodes: 611, reward function loss: -0.0470\n",
      "129448: reward: 500.00, mean_100: 500.00, episodes: 612, reward function loss: -0.0478\n",
      "129948: reward: 500.00, mean_100: 500.00, episodes: 613, reward function loss: -0.0478\n",
      "130448: reward: 500.00, mean_100: 500.00, episodes: 614, reward function loss: -0.0478\n",
      "130948: reward: 500.00, mean_100: 500.00, episodes: 615, reward function loss: -0.0478\n",
      "131448: reward: 500.00, mean_100: 500.00, episodes: 616, reward function loss: -0.0479\n",
      "131948: reward: 500.00, mean_100: 500.00, episodes: 617, reward function loss: -0.0479\n",
      "132448: reward: 500.00, mean_100: 500.00, episodes: 618, reward function loss: -0.0479\n",
      "132948: reward: 500.00, mean_100: 500.00, episodes: 619, reward function loss: -0.0479\n",
      "133448: reward: 500.00, mean_100: 500.00, episodes: 620, reward function loss: -0.0476\n",
      "133948: reward: 500.00, mean_100: 500.00, episodes: 621, reward function loss: -0.0476\n",
      "134448: reward: 500.00, mean_100: 500.00, episodes: 622, reward function loss: -0.0476\n",
      "134948: reward: 500.00, mean_100: 500.00, episodes: 623, reward function loss: -0.0476\n",
      "135448: reward: 500.00, mean_100: 500.00, episodes: 624, reward function loss: -0.0479\n",
      "135948: reward: 500.00, mean_100: 500.00, episodes: 625, reward function loss: -0.0479\n",
      "136448: reward: 500.00, mean_100: 500.00, episodes: 626, reward function loss: -0.0479\n",
      "136948: reward: 500.00, mean_100: 500.00, episodes: 627, reward function loss: -0.0479\n",
      "137448: reward: 500.00, mean_100: 500.00, episodes: 628, reward function loss: -0.0475\n",
      "137948: reward: 500.00, mean_100: 500.00, episodes: 629, reward function loss: -0.0475\n",
      "138448: reward: 500.00, mean_100: 500.00, episodes: 630, reward function loss: -0.0475\n",
      "138672: reward: 224.00, mean_100: 497.24, episodes: 631, reward function loss: -0.0475\n",
      "139172: reward: 500.00, mean_100: 497.24, episodes: 632, reward function loss: -0.0416\n",
      "139672: reward: 500.00, mean_100: 497.24, episodes: 633, reward function loss: -0.0416\n",
      "140172: reward: 500.00, mean_100: 497.24, episodes: 634, reward function loss: -0.0416\n",
      "140672: reward: 500.00, mean_100: 497.24, episodes: 635, reward function loss: -0.0416\n",
      "141172: reward: 500.00, mean_100: 497.24, episodes: 636, reward function loss: -0.0472\n",
      "141672: reward: 500.00, mean_100: 497.24, episodes: 637, reward function loss: -0.0472\n",
      "141849: reward: 177.00, mean_100: 494.01, episodes: 638, reward function loss: -0.0472\n",
      "142349: reward: 500.00, mean_100: 494.01, episodes: 639, reward function loss: -0.0472\n",
      "142849: reward: 500.00, mean_100: 494.01, episodes: 640, reward function loss: -0.0401\n",
      "143349: reward: 500.00, mean_100: 494.01, episodes: 641, reward function loss: -0.0401\n",
      "143849: reward: 500.00, mean_100: 494.01, episodes: 642, reward function loss: -0.0401\n",
      "144349: reward: 500.00, mean_100: 494.01, episodes: 643, reward function loss: -0.0401\n",
      "144849: reward: 500.00, mean_100: 494.01, episodes: 644, reward function loss: -0.0478\n",
      "145349: reward: 500.00, mean_100: 494.01, episodes: 645, reward function loss: -0.0478\n",
      "145849: reward: 500.00, mean_100: 494.01, episodes: 646, reward function loss: -0.0478\n",
      "146349: reward: 500.00, mean_100: 494.01, episodes: 647, reward function loss: -0.0478\n",
      "146849: reward: 500.00, mean_100: 494.01, episodes: 648, reward function loss: -0.0478\n",
      "147349: reward: 500.00, mean_100: 494.01, episodes: 649, reward function loss: -0.0478\n",
      "147849: reward: 500.00, mean_100: 494.01, episodes: 650, reward function loss: -0.0478\n",
      "148349: reward: 500.00, mean_100: 494.01, episodes: 651, reward function loss: -0.0478\n",
      "148849: reward: 500.00, mean_100: 494.01, episodes: 652, reward function loss: -0.0478\n",
      "149349: reward: 500.00, mean_100: 494.01, episodes: 653, reward function loss: -0.0478\n",
      "149849: reward: 500.00, mean_100: 494.01, episodes: 654, reward function loss: -0.0478\n",
      "150349: reward: 500.00, mean_100: 494.01, episodes: 655, reward function loss: -0.0478\n",
      "150849: reward: 500.00, mean_100: 494.01, episodes: 656, reward function loss: -0.0479\n",
      "151349: reward: 500.00, mean_100: 494.01, episodes: 657, reward function loss: -0.0479\n",
      "151849: reward: 500.00, mean_100: 494.01, episodes: 658, reward function loss: -0.0479\n",
      "152349: reward: 500.00, mean_100: 494.01, episodes: 659, reward function loss: -0.0479\n",
      "152849: reward: 500.00, mean_100: 494.01, episodes: 660, reward function loss: -0.0479\n",
      "153349: reward: 500.00, mean_100: 494.01, episodes: 661, reward function loss: -0.0479\n",
      "153849: reward: 500.00, mean_100: 494.01, episodes: 662, reward function loss: -0.0479\n",
      "154349: reward: 500.00, mean_100: 494.01, episodes: 663, reward function loss: -0.0479\n",
      "154849: reward: 500.00, mean_100: 494.01, episodes: 664, reward function loss: -0.0477\n",
      "155005: reward: 156.00, mean_100: 490.57, episodes: 665, reward function loss: -0.0477\n",
      "155505: reward: 500.00, mean_100: 490.57, episodes: 666, reward function loss: -0.0477\n",
      "156005: reward: 500.00, mean_100: 490.57, episodes: 667, reward function loss: -0.0477\n",
      "156505: reward: 500.00, mean_100: 490.57, episodes: 668, reward function loss: -0.0396\n",
      "156647: reward: 142.00, mean_100: 486.99, episodes: 669, reward function loss: -0.0396\n",
      "157147: reward: 500.00, mean_100: 486.99, episodes: 670, reward function loss: -0.0396\n",
      "157647: reward: 500.00, mean_100: 486.99, episodes: 671, reward function loss: -0.0396\n",
      "158147: reward: 500.00, mean_100: 486.99, episodes: 672, reward function loss: -0.0395\n",
      "158647: reward: 500.00, mean_100: 486.99, episodes: 673, reward function loss: -0.0395\n",
      "159147: reward: 500.00, mean_100: 486.99, episodes: 674, reward function loss: -0.0395\n",
      "159647: reward: 500.00, mean_100: 486.99, episodes: 675, reward function loss: -0.0395\n",
      "160147: reward: 500.00, mean_100: 486.99, episodes: 676, reward function loss: -0.0474\n",
      "160647: reward: 500.00, mean_100: 486.99, episodes: 677, reward function loss: -0.0474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161147: reward: 500.00, mean_100: 486.99, episodes: 678, reward function loss: -0.0474\n",
      "161647: reward: 500.00, mean_100: 486.99, episodes: 679, reward function loss: -0.0474\n",
      "162147: reward: 500.00, mean_100: 486.99, episodes: 680, reward function loss: -0.0476\n",
      "162647: reward: 500.00, mean_100: 486.99, episodes: 681, reward function loss: -0.0476\n",
      "163147: reward: 500.00, mean_100: 486.99, episodes: 682, reward function loss: -0.0476\n",
      "163647: reward: 500.00, mean_100: 486.99, episodes: 683, reward function loss: -0.0476\n",
      "164147: reward: 500.00, mean_100: 486.99, episodes: 684, reward function loss: -0.0477\n",
      "164647: reward: 500.00, mean_100: 486.99, episodes: 685, reward function loss: -0.0477\n",
      "165147: reward: 500.00, mean_100: 486.99, episodes: 686, reward function loss: -0.0477\n",
      "165647: reward: 500.00, mean_100: 486.99, episodes: 687, reward function loss: -0.0477\n",
      "166147: reward: 500.00, mean_100: 486.99, episodes: 688, reward function loss: -0.0476\n",
      "166647: reward: 500.00, mean_100: 486.99, episodes: 689, reward function loss: -0.0476\n",
      "167147: reward: 500.00, mean_100: 486.99, episodes: 690, reward function loss: -0.0476\n",
      "167647: reward: 500.00, mean_100: 486.99, episodes: 691, reward function loss: -0.0476\n",
      "168147: reward: 500.00, mean_100: 486.99, episodes: 692, reward function loss: -0.0477\n",
      "168647: reward: 500.00, mean_100: 486.99, episodes: 693, reward function loss: -0.0477\n",
      "169147: reward: 500.00, mean_100: 486.99, episodes: 694, reward function loss: -0.0477\n",
      "169647: reward: 500.00, mean_100: 486.99, episodes: 695, reward function loss: -0.0477\n",
      "170145: reward: 498.00, mean_100: 486.97, episodes: 696, reward function loss: -0.0475\n",
      "170645: reward: 500.00, mean_100: 486.97, episodes: 697, reward function loss: -0.0475\n",
      "171145: reward: 500.00, mean_100: 486.97, episodes: 698, reward function loss: -0.0475\n",
      "171645: reward: 500.00, mean_100: 486.97, episodes: 699, reward function loss: -0.0475\n",
      "172145: reward: 500.00, mean_100: 486.97, episodes: 700, reward function loss: -0.0479\n",
      "172645: reward: 500.00, mean_100: 486.97, episodes: 701, reward function loss: -0.0479\n",
      "173145: reward: 500.00, mean_100: 486.97, episodes: 702, reward function loss: -0.0479\n",
      "173645: reward: 500.00, mean_100: 486.97, episodes: 703, reward function loss: -0.0479\n",
      "173661: reward:  16.00, mean_100: 482.13, episodes: 704, reward function loss: -0.0362\n",
      "174161: reward: 500.00, mean_100: 482.13, episodes: 705, reward function loss: -0.0362\n",
      "174661: reward: 500.00, mean_100: 482.13, episodes: 706, reward function loss: -0.0362\n",
      "175161: reward: 500.00, mean_100: 482.13, episodes: 707, reward function loss: -0.0362\n",
      "175661: reward: 500.00, mean_100: 482.13, episodes: 708, reward function loss: -0.0476\n",
      "176161: reward: 500.00, mean_100: 482.13, episodes: 709, reward function loss: -0.0476\n",
      "176661: reward: 500.00, mean_100: 482.13, episodes: 710, reward function loss: -0.0476\n",
      "176679: reward:  18.00, mean_100: 477.31, episodes: 711, reward function loss: -0.0476\n",
      "177179: reward: 500.00, mean_100: 477.31, episodes: 712, reward function loss: -0.0366\n",
      "177679: reward: 500.00, mean_100: 477.31, episodes: 713, reward function loss: -0.0366\n",
      "178179: reward: 500.00, mean_100: 477.31, episodes: 714, reward function loss: -0.0366\n",
      "178679: reward: 500.00, mean_100: 477.31, episodes: 715, reward function loss: -0.0366\n",
      "179179: reward: 500.00, mean_100: 477.31, episodes: 716, reward function loss: -0.0477\n",
      "179679: reward: 500.00, mean_100: 477.31, episodes: 717, reward function loss: -0.0477\n",
      "180179: reward: 500.00, mean_100: 477.31, episodes: 718, reward function loss: -0.0477\n",
      "180679: reward: 500.00, mean_100: 477.31, episodes: 719, reward function loss: -0.0477\n",
      "180767: reward:  88.00, mean_100: 473.19, episodes: 720, reward function loss: -0.0383\n",
      "181267: reward: 500.00, mean_100: 473.19, episodes: 721, reward function loss: -0.0383\n",
      "181767: reward: 500.00, mean_100: 473.19, episodes: 722, reward function loss: -0.0383\n",
      "182267: reward: 500.00, mean_100: 473.19, episodes: 723, reward function loss: -0.0383\n",
      "182767: reward: 500.00, mean_100: 473.19, episodes: 724, reward function loss: -0.0478\n",
      "183267: reward: 500.00, mean_100: 473.19, episodes: 725, reward function loss: -0.0478\n",
      "183767: reward: 500.00, mean_100: 473.19, episodes: 726, reward function loss: -0.0478\n",
      "184267: reward: 500.00, mean_100: 473.19, episodes: 727, reward function loss: -0.0478\n",
      "184767: reward: 500.00, mean_100: 473.19, episodes: 728, reward function loss: -0.0474\n",
      "185267: reward: 500.00, mean_100: 473.19, episodes: 729, reward function loss: -0.0474\n",
      "185767: reward: 500.00, mean_100: 473.19, episodes: 730, reward function loss: -0.0474\n",
      "186267: reward: 500.00, mean_100: 475.95, episodes: 731, reward function loss: -0.0474\n",
      "186767: reward: 500.00, mean_100: 475.95, episodes: 732, reward function loss: -0.0478\n",
      "187172: reward: 405.00, mean_100: 475.00, episodes: 733, reward function loss: -0.0478\n",
      "187597: reward: 425.00, mean_100: 474.25, episodes: 734, reward function loss: -0.0478\n",
      "188097: reward: 500.00, mean_100: 474.25, episodes: 735, reward function loss: -0.0478\n",
      "188117: reward:  20.00, mean_100: 469.45, episodes: 736, reward function loss: -0.0291\n",
      "188617: reward: 500.00, mean_100: 469.45, episodes: 737, reward function loss: -0.0291\n",
      "189117: reward: 500.00, mean_100: 472.68, episodes: 738, reward function loss: -0.0291\n",
      "189617: reward: 500.00, mean_100: 472.68, episodes: 739, reward function loss: -0.0291\n",
      "190117: reward: 500.00, mean_100: 472.68, episodes: 740, reward function loss: -0.0478\n",
      "190617: reward: 500.00, mean_100: 472.68, episodes: 741, reward function loss: -0.0478\n",
      "191117: reward: 500.00, mean_100: 472.68, episodes: 742, reward function loss: -0.0478\n",
      "191617: reward: 500.00, mean_100: 472.68, episodes: 743, reward function loss: -0.0478\n",
      "192117: reward: 500.00, mean_100: 472.68, episodes: 744, reward function loss: -0.0472\n",
      "192617: reward: 500.00, mean_100: 472.68, episodes: 745, reward function loss: -0.0472\n",
      "192724: reward: 107.00, mean_100: 468.75, episodes: 746, reward function loss: -0.0472\n",
      "193224: reward: 500.00, mean_100: 468.75, episodes: 747, reward function loss: -0.0472\n",
      "193724: reward: 500.00, mean_100: 468.75, episodes: 748, reward function loss: -0.0384\n",
      "194224: reward: 500.00, mean_100: 468.75, episodes: 749, reward function loss: -0.0384\n",
      "194724: reward: 500.00, mean_100: 468.75, episodes: 750, reward function loss: -0.0384\n",
      "195224: reward: 500.00, mean_100: 468.75, episodes: 751, reward function loss: -0.0384\n",
      "195724: reward: 500.00, mean_100: 468.75, episodes: 752, reward function loss: -0.0479\n",
      "196224: reward: 500.00, mean_100: 468.75, episodes: 753, reward function loss: -0.0479\n",
      "196724: reward: 500.00, mean_100: 468.75, episodes: 754, reward function loss: -0.0479\n",
      "197224: reward: 500.00, mean_100: 468.75, episodes: 755, reward function loss: -0.0479\n",
      "197724: reward: 500.00, mean_100: 468.75, episodes: 756, reward function loss: -0.0477\n",
      "198224: reward: 500.00, mean_100: 468.75, episodes: 757, reward function loss: -0.0477\n",
      "198724: reward: 500.00, mean_100: 468.75, episodes: 758, reward function loss: -0.0477\n",
      "199224: reward: 500.00, mean_100: 468.75, episodes: 759, reward function loss: -0.0477\n",
      "199724: reward: 500.00, mean_100: 468.75, episodes: 760, reward function loss: -0.0478\n",
      "200224: reward: 500.00, mean_100: 468.75, episodes: 761, reward function loss: -0.0478\n",
      "200724: reward: 500.00, mean_100: 468.75, episodes: 762, reward function loss: -0.0478\n",
      "201224: reward: 500.00, mean_100: 468.75, episodes: 763, reward function loss: -0.0478\n",
      "201724: reward: 500.00, mean_100: 468.75, episodes: 764, reward function loss: -0.0476\n",
      "202224: reward: 500.00, mean_100: 472.19, episodes: 765, reward function loss: -0.0476\n",
      "202724: reward: 500.00, mean_100: 472.19, episodes: 766, reward function loss: -0.0476\n",
      "203224: reward: 500.00, mean_100: 472.19, episodes: 767, reward function loss: -0.0476\n",
      "203724: reward: 500.00, mean_100: 472.19, episodes: 768, reward function loss: -0.0476\n",
      "204224: reward: 500.00, mean_100: 475.77, episodes: 769, reward function loss: -0.0476\n",
      "204724: reward: 500.00, mean_100: 475.77, episodes: 770, reward function loss: -0.0476\n",
      "205224: reward: 500.00, mean_100: 475.77, episodes: 771, reward function loss: -0.0476\n",
      "205724: reward: 500.00, mean_100: 475.77, episodes: 772, reward function loss: -0.0477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206224: reward: 500.00, mean_100: 475.77, episodes: 773, reward function loss: -0.0477\n",
      "206724: reward: 500.00, mean_100: 475.77, episodes: 774, reward function loss: -0.0477\n",
      "207113: reward: 389.00, mean_100: 474.66, episodes: 775, reward function loss: -0.0477\n",
      "207613: reward: 500.00, mean_100: 474.66, episodes: 776, reward function loss: -0.0449\n",
      "208113: reward: 500.00, mean_100: 474.66, episodes: 777, reward function loss: -0.0449\n",
      "208613: reward: 500.00, mean_100: 474.66, episodes: 778, reward function loss: -0.0449\n",
      "209113: reward: 500.00, mean_100: 474.66, episodes: 779, reward function loss: -0.0449\n",
      "209304: reward: 191.00, mean_100: 471.57, episodes: 780, reward function loss: -0.0408\n",
      "209804: reward: 500.00, mean_100: 471.57, episodes: 781, reward function loss: -0.0408\n",
      "210304: reward: 500.00, mean_100: 471.57, episodes: 782, reward function loss: -0.0408\n",
      "210804: reward: 500.00, mean_100: 471.57, episodes: 783, reward function loss: -0.0408\n",
      "211304: reward: 500.00, mean_100: 471.57, episodes: 784, reward function loss: -0.0479\n",
      "211804: reward: 500.00, mean_100: 471.57, episodes: 785, reward function loss: -0.0479\n",
      "212304: reward: 500.00, mean_100: 471.57, episodes: 786, reward function loss: -0.0479\n",
      "212804: reward: 500.00, mean_100: 471.57, episodes: 787, reward function loss: -0.0479\n",
      "213304: reward: 500.00, mean_100: 471.57, episodes: 788, reward function loss: -0.0474\n",
      "213804: reward: 500.00, mean_100: 471.57, episodes: 789, reward function loss: -0.0474\n",
      "214304: reward: 500.00, mean_100: 471.57, episodes: 790, reward function loss: -0.0474\n",
      "214804: reward: 500.00, mean_100: 471.57, episodes: 791, reward function loss: -0.0474\n",
      "215304: reward: 500.00, mean_100: 471.57, episodes: 792, reward function loss: -0.0476\n",
      "215804: reward: 500.00, mean_100: 471.57, episodes: 793, reward function loss: -0.0476\n",
      "216304: reward: 500.00, mean_100: 471.57, episodes: 794, reward function loss: -0.0476\n",
      "216804: reward: 500.00, mean_100: 471.57, episodes: 795, reward function loss: -0.0476\n",
      "217304: reward: 500.00, mean_100: 471.59, episodes: 796, reward function loss: -0.0475\n",
      "217804: reward: 500.00, mean_100: 471.59, episodes: 797, reward function loss: -0.0475\n",
      "218304: reward: 500.00, mean_100: 471.59, episodes: 798, reward function loss: -0.0475\n",
      "218804: reward: 500.00, mean_100: 471.59, episodes: 799, reward function loss: -0.0475\n",
      "219304: reward: 500.00, mean_100: 471.59, episodes: 800, reward function loss: -0.0478\n",
      "219804: reward: 500.00, mean_100: 471.59, episodes: 801, reward function loss: -0.0478\n",
      "220304: reward: 500.00, mean_100: 471.59, episodes: 802, reward function loss: -0.0478\n",
      "220804: reward: 500.00, mean_100: 471.59, episodes: 803, reward function loss: -0.0478\n",
      "221304: reward: 500.00, mean_100: 476.43, episodes: 804, reward function loss: -0.0476\n",
      "221804: reward: 500.00, mean_100: 476.43, episodes: 805, reward function loss: -0.0476\n",
      "222304: reward: 500.00, mean_100: 476.43, episodes: 806, reward function loss: -0.0476\n",
      "222804: reward: 500.00, mean_100: 476.43, episodes: 807, reward function loss: -0.0476\n",
      "223304: reward: 500.00, mean_100: 476.43, episodes: 808, reward function loss: -0.0478\n",
      "223804: reward: 500.00, mean_100: 476.43, episodes: 809, reward function loss: -0.0478\n",
      "224304: reward: 500.00, mean_100: 476.43, episodes: 810, reward function loss: -0.0478\n",
      "224804: reward: 500.00, mean_100: 481.25, episodes: 811, reward function loss: -0.0478\n",
      "225304: reward: 500.00, mean_100: 481.25, episodes: 812, reward function loss: -0.0476\n",
      "225804: reward: 500.00, mean_100: 481.25, episodes: 813, reward function loss: -0.0476\n",
      "226304: reward: 500.00, mean_100: 481.25, episodes: 814, reward function loss: -0.0476\n",
      "226804: reward: 500.00, mean_100: 481.25, episodes: 815, reward function loss: -0.0476\n",
      "227304: reward: 500.00, mean_100: 481.25, episodes: 816, reward function loss: -0.0477\n",
      "227804: reward: 500.00, mean_100: 481.25, episodes: 817, reward function loss: -0.0477\n",
      "228304: reward: 500.00, mean_100: 481.25, episodes: 818, reward function loss: -0.0477\n",
      "228804: reward: 500.00, mean_100: 481.25, episodes: 819, reward function loss: -0.0477\n",
      "229304: reward: 500.00, mean_100: 485.37, episodes: 820, reward function loss: -0.0477\n",
      "229804: reward: 500.00, mean_100: 485.37, episodes: 821, reward function loss: -0.0477\n",
      "230304: reward: 500.00, mean_100: 485.37, episodes: 822, reward function loss: -0.0477\n",
      "230804: reward: 500.00, mean_100: 485.37, episodes: 823, reward function loss: -0.0477\n",
      "231304: reward: 500.00, mean_100: 485.37, episodes: 824, reward function loss: -0.0477\n",
      "231804: reward: 500.00, mean_100: 485.37, episodes: 825, reward function loss: -0.0477\n",
      "232304: reward: 500.00, mean_100: 485.37, episodes: 826, reward function loss: -0.0477\n",
      "232804: reward: 500.00, mean_100: 485.37, episodes: 827, reward function loss: -0.0477\n",
      "233304: reward: 500.00, mean_100: 485.37, episodes: 828, reward function loss: -0.0477\n",
      "233804: reward: 500.00, mean_100: 485.37, episodes: 829, reward function loss: -0.0477\n",
      "234304: reward: 500.00, mean_100: 485.37, episodes: 830, reward function loss: -0.0477\n",
      "234804: reward: 500.00, mean_100: 485.37, episodes: 831, reward function loss: -0.0477\n",
      "235304: reward: 500.00, mean_100: 485.37, episodes: 832, reward function loss: -0.0474\n",
      "235804: reward: 500.00, mean_100: 486.32, episodes: 833, reward function loss: -0.0474\n",
      "236304: reward: 500.00, mean_100: 487.07, episodes: 834, reward function loss: -0.0474\n",
      "236804: reward: 500.00, mean_100: 487.07, episodes: 835, reward function loss: -0.0474\n",
      "237304: reward: 500.00, mean_100: 491.87, episodes: 836, reward function loss: -0.0478\n",
      "237804: reward: 500.00, mean_100: 491.87, episodes: 837, reward function loss: -0.0478\n",
      "238304: reward: 500.00, mean_100: 491.87, episodes: 838, reward function loss: -0.0478\n",
      "238804: reward: 500.00, mean_100: 491.87, episodes: 839, reward function loss: -0.0478\n",
      "239304: reward: 500.00, mean_100: 491.87, episodes: 840, reward function loss: -0.0475\n",
      "239804: reward: 500.00, mean_100: 491.87, episodes: 841, reward function loss: -0.0475\n",
      "240304: reward: 500.00, mean_100: 491.87, episodes: 842, reward function loss: -0.0475\n",
      "240804: reward: 500.00, mean_100: 491.87, episodes: 843, reward function loss: -0.0475\n",
      "241304: reward: 500.00, mean_100: 491.87, episodes: 844, reward function loss: -0.0478\n",
      "241804: reward: 500.00, mean_100: 491.87, episodes: 845, reward function loss: -0.0478\n",
      "242304: reward: 500.00, mean_100: 495.80, episodes: 846, reward function loss: -0.0478\n",
      "242804: reward: 500.00, mean_100: 495.80, episodes: 847, reward function loss: -0.0478\n",
      "243304: reward: 500.00, mean_100: 495.80, episodes: 848, reward function loss: -0.0473\n",
      "243804: reward: 500.00, mean_100: 495.80, episodes: 849, reward function loss: -0.0473\n",
      "244304: reward: 500.00, mean_100: 495.80, episodes: 850, reward function loss: -0.0473\n",
      "244804: reward: 500.00, mean_100: 495.80, episodes: 851, reward function loss: -0.0473\n",
      "245304: reward: 500.00, mean_100: 495.80, episodes: 852, reward function loss: -0.0471\n",
      "245804: reward: 500.00, mean_100: 495.80, episodes: 853, reward function loss: -0.0471\n",
      "246304: reward: 500.00, mean_100: 495.80, episodes: 854, reward function loss: -0.0471\n",
      "246804: reward: 500.00, mean_100: 495.80, episodes: 855, reward function loss: -0.0471\n",
      "247304: reward: 500.00, mean_100: 495.80, episodes: 856, reward function loss: -0.0477\n",
      "247804: reward: 500.00, mean_100: 495.80, episodes: 857, reward function loss: -0.0477\n",
      "248304: reward: 500.00, mean_100: 495.80, episodes: 858, reward function loss: -0.0477\n",
      "248804: reward: 500.00, mean_100: 495.80, episodes: 859, reward function loss: -0.0477\n",
      "249304: reward: 500.00, mean_100: 495.80, episodes: 860, reward function loss: -0.0476\n",
      "249804: reward: 500.00, mean_100: 495.80, episodes: 861, reward function loss: -0.0476\n",
      "250304: reward: 500.00, mean_100: 495.80, episodes: 862, reward function loss: -0.0476\n",
      "250804: reward: 500.00, mean_100: 495.80, episodes: 863, reward function loss: -0.0476\n",
      "251304: reward: 500.00, mean_100: 495.80, episodes: 864, reward function loss: -0.0477\n",
      "251804: reward: 500.00, mean_100: 495.80, episodes: 865, reward function loss: -0.0477\n",
      "252304: reward: 500.00, mean_100: 495.80, episodes: 866, reward function loss: -0.0477\n",
      "252804: reward: 500.00, mean_100: 495.80, episodes: 867, reward function loss: -0.0477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253304: reward: 500.00, mean_100: 495.80, episodes: 868, reward function loss: -0.0473\n",
      "253804: reward: 500.00, mean_100: 495.80, episodes: 869, reward function loss: -0.0473\n",
      "254304: reward: 500.00, mean_100: 495.80, episodes: 870, reward function loss: -0.0473\n",
      "254804: reward: 500.00, mean_100: 495.80, episodes: 871, reward function loss: -0.0473\n",
      "255304: reward: 500.00, mean_100: 495.80, episodes: 872, reward function loss: -0.0477\n",
      "255804: reward: 500.00, mean_100: 495.80, episodes: 873, reward function loss: -0.0477\n",
      "255873: reward:  69.00, mean_100: 491.49, episodes: 874, reward function loss: -0.0477\n",
      "256373: reward: 500.00, mean_100: 492.60, episodes: 875, reward function loss: -0.0477\n",
      "256873: reward: 500.00, mean_100: 492.60, episodes: 876, reward function loss: -0.0377\n",
      "257373: reward: 500.00, mean_100: 492.60, episodes: 877, reward function loss: -0.0377\n",
      "257873: reward: 500.00, mean_100: 492.60, episodes: 878, reward function loss: -0.0377\n",
      "258373: reward: 500.00, mean_100: 492.60, episodes: 879, reward function loss: -0.0377\n",
      "258873: reward: 500.00, mean_100: 495.69, episodes: 880, reward function loss: -0.0477\n",
      "259373: reward: 500.00, mean_100: 495.69, episodes: 881, reward function loss: -0.0477\n",
      "259873: reward: 500.00, mean_100: 495.69, episodes: 882, reward function loss: -0.0477\n",
      "260373: reward: 500.00, mean_100: 495.69, episodes: 883, reward function loss: -0.0477\n",
      "260873: reward: 500.00, mean_100: 495.69, episodes: 884, reward function loss: -0.0470\n",
      "261373: reward: 500.00, mean_100: 495.69, episodes: 885, reward function loss: -0.0470\n",
      "261873: reward: 500.00, mean_100: 495.69, episodes: 886, reward function loss: -0.0470\n",
      "262373: reward: 500.00, mean_100: 495.69, episodes: 887, reward function loss: -0.0470\n",
      "262873: reward: 500.00, mean_100: 495.69, episodes: 888, reward function loss: -0.0470\n",
      "263373: reward: 500.00, mean_100: 495.69, episodes: 889, reward function loss: -0.0470\n",
      "263873: reward: 500.00, mean_100: 495.69, episodes: 890, reward function loss: -0.0470\n",
      "264373: reward: 500.00, mean_100: 495.69, episodes: 891, reward function loss: -0.0470\n",
      "264873: reward: 500.00, mean_100: 495.69, episodes: 892, reward function loss: -0.0474\n",
      "265373: reward: 500.00, mean_100: 495.69, episodes: 893, reward function loss: -0.0474\n",
      "265873: reward: 500.00, mean_100: 495.69, episodes: 894, reward function loss: -0.0474\n",
      "266373: reward: 500.00, mean_100: 495.69, episodes: 895, reward function loss: -0.0474\n",
      "266873: reward: 500.00, mean_100: 495.69, episodes: 896, reward function loss: -0.0478\n",
      "267373: reward: 500.00, mean_100: 495.69, episodes: 897, reward function loss: -0.0478\n",
      "267873: reward: 500.00, mean_100: 495.69, episodes: 898, reward function loss: -0.0478\n",
      "268373: reward: 500.00, mean_100: 495.69, episodes: 899, reward function loss: -0.0478\n",
      "268873: reward: 500.00, mean_100: 495.69, episodes: 900, reward function loss: -0.0477\n",
      "269373: reward: 500.00, mean_100: 495.69, episodes: 901, reward function loss: -0.0477\n",
      "269873: reward: 500.00, mean_100: 495.69, episodes: 902, reward function loss: -0.0477\n",
      "270373: reward: 500.00, mean_100: 495.69, episodes: 903, reward function loss: -0.0477\n",
      "270873: reward: 500.00, mean_100: 495.69, episodes: 904, reward function loss: -0.0477\n",
      "271373: reward: 500.00, mean_100: 495.69, episodes: 905, reward function loss: -0.0477\n",
      "271873: reward: 500.00, mean_100: 495.69, episodes: 906, reward function loss: -0.0477\n",
      "272373: reward: 500.00, mean_100: 495.69, episodes: 907, reward function loss: -0.0477\n",
      "272734: reward: 361.00, mean_100: 494.30, episodes: 908, reward function loss: -0.0442\n",
      "273234: reward: 500.00, mean_100: 494.30, episodes: 909, reward function loss: -0.0442\n",
      "273734: reward: 500.00, mean_100: 494.30, episodes: 910, reward function loss: -0.0442\n",
      "274234: reward: 500.00, mean_100: 494.30, episodes: 911, reward function loss: -0.0442\n",
      "274734: reward: 500.00, mean_100: 494.30, episodes: 912, reward function loss: -0.0475\n",
      "275234: reward: 500.00, mean_100: 494.30, episodes: 913, reward function loss: -0.0475\n",
      "275734: reward: 500.00, mean_100: 494.30, episodes: 914, reward function loss: -0.0475\n",
      "276234: reward: 500.00, mean_100: 494.30, episodes: 915, reward function loss: -0.0475\n",
      "276734: reward: 500.00, mean_100: 494.30, episodes: 916, reward function loss: -0.0418\n",
      "277234: reward: 500.00, mean_100: 494.30, episodes: 917, reward function loss: -0.0418\n",
      "277734: reward: 500.00, mean_100: 494.30, episodes: 918, reward function loss: -0.0418\n",
      "278234: reward: 500.00, mean_100: 494.30, episodes: 919, reward function loss: -0.0418\n",
      "278734: reward: 500.00, mean_100: 494.30, episodes: 920, reward function loss: -0.0467\n",
      "279234: reward: 500.00, mean_100: 494.30, episodes: 921, reward function loss: -0.0467\n",
      "279734: reward: 500.00, mean_100: 494.30, episodes: 922, reward function loss: -0.0467\n",
      "280234: reward: 500.00, mean_100: 494.30, episodes: 923, reward function loss: -0.0467\n",
      "280734: reward: 500.00, mean_100: 494.30, episodes: 924, reward function loss: -0.0457\n",
      "281234: reward: 500.00, mean_100: 494.30, episodes: 925, reward function loss: -0.0457\n",
      "281734: reward: 500.00, mean_100: 494.30, episodes: 926, reward function loss: -0.0457\n",
      "282234: reward: 500.00, mean_100: 494.30, episodes: 927, reward function loss: -0.0457\n",
      "282734: reward: 500.00, mean_100: 494.30, episodes: 928, reward function loss: -0.0471\n",
      "283234: reward: 500.00, mean_100: 494.30, episodes: 929, reward function loss: -0.0471\n",
      "283734: reward: 500.00, mean_100: 494.30, episodes: 930, reward function loss: -0.0471\n",
      "284234: reward: 500.00, mean_100: 494.30, episodes: 931, reward function loss: -0.0471\n",
      "284734: reward: 500.00, mean_100: 494.30, episodes: 932, reward function loss: -0.0472\n",
      "285234: reward: 500.00, mean_100: 494.30, episodes: 933, reward function loss: -0.0472\n",
      "285734: reward: 500.00, mean_100: 494.30, episodes: 934, reward function loss: -0.0472\n",
      "286234: reward: 500.00, mean_100: 494.30, episodes: 935, reward function loss: -0.0472\n",
      "286734: reward: 500.00, mean_100: 494.30, episodes: 936, reward function loss: -0.0478\n",
      "287234: reward: 500.00, mean_100: 494.30, episodes: 937, reward function loss: -0.0478\n",
      "287734: reward: 500.00, mean_100: 494.30, episodes: 938, reward function loss: -0.0478\n",
      "288234: reward: 500.00, mean_100: 494.30, episodes: 939, reward function loss: -0.0478\n",
      "288734: reward: 500.00, mean_100: 494.30, episodes: 940, reward function loss: -0.0473\n",
      "289234: reward: 500.00, mean_100: 494.30, episodes: 941, reward function loss: -0.0473\n",
      "289734: reward: 500.00, mean_100: 494.30, episodes: 942, reward function loss: -0.0473\n",
      "290234: reward: 500.00, mean_100: 494.30, episodes: 943, reward function loss: -0.0473\n",
      "290734: reward: 500.00, mean_100: 494.30, episodes: 944, reward function loss: -0.0473\n",
      "291234: reward: 500.00, mean_100: 494.30, episodes: 945, reward function loss: -0.0473\n",
      "291734: reward: 500.00, mean_100: 494.30, episodes: 946, reward function loss: -0.0473\n",
      "292234: reward: 500.00, mean_100: 494.30, episodes: 947, reward function loss: -0.0473\n",
      "292734: reward: 500.00, mean_100: 494.30, episodes: 948, reward function loss: -0.0479\n",
      "293234: reward: 500.00, mean_100: 494.30, episodes: 949, reward function loss: -0.0479\n",
      "293734: reward: 500.00, mean_100: 494.30, episodes: 950, reward function loss: -0.0479\n",
      "294234: reward: 500.00, mean_100: 494.30, episodes: 951, reward function loss: -0.0479\n",
      "294734: reward: 500.00, mean_100: 494.30, episodes: 952, reward function loss: -0.0478\n",
      "295234: reward: 500.00, mean_100: 494.30, episodes: 953, reward function loss: -0.0478\n",
      "295734: reward: 500.00, mean_100: 494.30, episodes: 954, reward function loss: -0.0478\n",
      "296234: reward: 500.00, mean_100: 494.30, episodes: 955, reward function loss: -0.0478\n",
      "296734: reward: 500.00, mean_100: 494.30, episodes: 956, reward function loss: -0.0476\n",
      "297234: reward: 500.00, mean_100: 494.30, episodes: 957, reward function loss: -0.0476\n",
      "297734: reward: 500.00, mean_100: 494.30, episodes: 958, reward function loss: -0.0476\n",
      "298234: reward: 500.00, mean_100: 494.30, episodes: 959, reward function loss: -0.0476\n",
      "298734: reward: 500.00, mean_100: 494.30, episodes: 960, reward function loss: -0.0470\n",
      "299234: reward: 500.00, mean_100: 494.30, episodes: 961, reward function loss: -0.0470\n",
      "299734: reward: 500.00, mean_100: 494.30, episodes: 962, reward function loss: -0.0470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300234: reward: 500.00, mean_100: 494.30, episodes: 963, reward function loss: -0.0470\n",
      "300734: reward: 500.00, mean_100: 494.30, episodes: 964, reward function loss: -0.0474\n",
      "301234: reward: 500.00, mean_100: 494.30, episodes: 965, reward function loss: -0.0474\n",
      "301672: reward: 438.00, mean_100: 493.68, episodes: 966, reward function loss: -0.0474\n",
      "302172: reward: 500.00, mean_100: 493.68, episodes: 967, reward function loss: -0.0474\n",
      "302672: reward: 500.00, mean_100: 493.68, episodes: 968, reward function loss: -0.0460\n",
      "303172: reward: 500.00, mean_100: 493.68, episodes: 969, reward function loss: -0.0460\n",
      "303672: reward: 500.00, mean_100: 493.68, episodes: 970, reward function loss: -0.0460\n",
      "304172: reward: 500.00, mean_100: 493.68, episodes: 971, reward function loss: -0.0460\n",
      "304672: reward: 500.00, mean_100: 493.68, episodes: 972, reward function loss: -0.0476\n",
      "305172: reward: 500.00, mean_100: 493.68, episodes: 973, reward function loss: -0.0476\n",
      "305672: reward: 500.00, mean_100: 497.99, episodes: 974, reward function loss: -0.0476\n",
      "306172: reward: 500.00, mean_100: 497.99, episodes: 975, reward function loss: -0.0476\n",
      "306672: reward: 500.00, mean_100: 497.99, episodes: 976, reward function loss: -0.0470\n",
      "307172: reward: 500.00, mean_100: 497.99, episodes: 977, reward function loss: -0.0470\n",
      "307672: reward: 500.00, mean_100: 497.99, episodes: 978, reward function loss: -0.0470\n",
      "308172: reward: 500.00, mean_100: 497.99, episodes: 979, reward function loss: -0.0470\n",
      "308672: reward: 500.00, mean_100: 497.99, episodes: 980, reward function loss: -0.0477\n",
      "309172: reward: 500.00, mean_100: 497.99, episodes: 981, reward function loss: -0.0477\n",
      "309672: reward: 500.00, mean_100: 497.99, episodes: 982, reward function loss: -0.0477\n",
      "310172: reward: 500.00, mean_100: 497.99, episodes: 983, reward function loss: -0.0477\n",
      "310672: reward: 500.00, mean_100: 497.99, episodes: 984, reward function loss: -0.0471\n",
      "311172: reward: 500.00, mean_100: 497.99, episodes: 985, reward function loss: -0.0471\n",
      "311672: reward: 500.00, mean_100: 497.99, episodes: 986, reward function loss: -0.0471\n",
      "312172: reward: 500.00, mean_100: 497.99, episodes: 987, reward function loss: -0.0471\n",
      "312672: reward: 500.00, mean_100: 497.99, episodes: 988, reward function loss: -0.0479\n",
      "313172: reward: 500.00, mean_100: 497.99, episodes: 989, reward function loss: -0.0479\n",
      "313672: reward: 500.00, mean_100: 497.99, episodes: 990, reward function loss: -0.0479\n",
      "314172: reward: 500.00, mean_100: 497.99, episodes: 991, reward function loss: -0.0479\n",
      "314672: reward: 500.00, mean_100: 497.99, episodes: 992, reward function loss: -0.0475\n",
      "315172: reward: 500.00, mean_100: 497.99, episodes: 993, reward function loss: -0.0475\n",
      "315672: reward: 500.00, mean_100: 497.99, episodes: 994, reward function loss: -0.0475\n",
      "316172: reward: 500.00, mean_100: 497.99, episodes: 995, reward function loss: -0.0475\n",
      "316672: reward: 500.00, mean_100: 497.99, episodes: 996, reward function loss: -0.0478\n",
      "317172: reward: 500.00, mean_100: 497.99, episodes: 997, reward function loss: -0.0478\n",
      "317672: reward: 500.00, mean_100: 497.99, episodes: 998, reward function loss: -0.0478\n",
      "318172: reward: 500.00, mean_100: 497.99, episodes: 999, reward function loss: -0.0478\n",
      "318672: reward: 500.00, mean_100: 497.99, episodes: 1000, reward function loss: -0.0471\n",
      "319172: reward: 500.00, mean_100: 497.99, episodes: 1001, reward function loss: -0.0471\n",
      "319672: reward: 500.00, mean_100: 497.99, episodes: 1002, reward function loss: -0.0471\n",
      "320172: reward: 500.00, mean_100: 497.99, episodes: 1003, reward function loss: -0.0471\n",
      "320672: reward: 500.00, mean_100: 497.99, episodes: 1004, reward function loss: -0.0469\n",
      "321172: reward: 500.00, mean_100: 497.99, episodes: 1005, reward function loss: -0.0469\n",
      "321672: reward: 500.00, mean_100: 497.99, episodes: 1006, reward function loss: -0.0469\n",
      "322172: reward: 500.00, mean_100: 497.99, episodes: 1007, reward function loss: -0.0469\n",
      "322672: reward: 500.00, mean_100: 499.38, episodes: 1008, reward function loss: -0.0475\n",
      "323172: reward: 500.00, mean_100: 499.38, episodes: 1009, reward function loss: -0.0475\n",
      "323672: reward: 500.00, mean_100: 499.38, episodes: 1010, reward function loss: -0.0475\n",
      "324172: reward: 500.00, mean_100: 499.38, episodes: 1011, reward function loss: -0.0475\n",
      "324672: reward: 500.00, mean_100: 499.38, episodes: 1012, reward function loss: -0.0466\n",
      "325172: reward: 500.00, mean_100: 499.38, episodes: 1013, reward function loss: -0.0466\n",
      "325672: reward: 500.00, mean_100: 499.38, episodes: 1014, reward function loss: -0.0466\n",
      "326172: reward: 500.00, mean_100: 499.38, episodes: 1015, reward function loss: -0.0466\n",
      "326672: reward: 500.00, mean_100: 499.38, episodes: 1016, reward function loss: -0.0468\n",
      "327172: reward: 500.00, mean_100: 499.38, episodes: 1017, reward function loss: -0.0468\n",
      "327672: reward: 500.00, mean_100: 499.38, episodes: 1018, reward function loss: -0.0468\n",
      "328172: reward: 500.00, mean_100: 499.38, episodes: 1019, reward function loss: -0.0468\n",
      "328672: reward: 500.00, mean_100: 499.38, episodes: 1020, reward function loss: -0.0478\n",
      "329172: reward: 500.00, mean_100: 499.38, episodes: 1021, reward function loss: -0.0478\n",
      "329672: reward: 500.00, mean_100: 499.38, episodes: 1022, reward function loss: -0.0478\n",
      "330172: reward: 500.00, mean_100: 499.38, episodes: 1023, reward function loss: -0.0478\n",
      "330672: reward: 500.00, mean_100: 499.38, episodes: 1024, reward function loss: -0.0471\n",
      "331172: reward: 500.00, mean_100: 499.38, episodes: 1025, reward function loss: -0.0471\n",
      "331672: reward: 500.00, mean_100: 499.38, episodes: 1026, reward function loss: -0.0471\n",
      "332172: reward: 500.00, mean_100: 499.38, episodes: 1027, reward function loss: -0.0471\n",
      "332672: reward: 500.00, mean_100: 499.38, episodes: 1028, reward function loss: -0.0474\n",
      "333172: reward: 500.00, mean_100: 499.38, episodes: 1029, reward function loss: -0.0474\n",
      "333672: reward: 500.00, mean_100: 499.38, episodes: 1030, reward function loss: -0.0474\n",
      "334172: reward: 500.00, mean_100: 499.38, episodes: 1031, reward function loss: -0.0474\n",
      "334672: reward: 500.00, mean_100: 499.38, episodes: 1032, reward function loss: -0.0477\n",
      "335172: reward: 500.00, mean_100: 499.38, episodes: 1033, reward function loss: -0.0477\n",
      "335672: reward: 500.00, mean_100: 499.38, episodes: 1034, reward function loss: -0.0477\n",
      "336172: reward: 500.00, mean_100: 499.38, episodes: 1035, reward function loss: -0.0477\n",
      "336672: reward: 500.00, mean_100: 499.38, episodes: 1036, reward function loss: -0.0479\n",
      "337172: reward: 500.00, mean_100: 499.38, episodes: 1037, reward function loss: -0.0479\n",
      "337672: reward: 500.00, mean_100: 499.38, episodes: 1038, reward function loss: -0.0479\n",
      "338172: reward: 500.00, mean_100: 499.38, episodes: 1039, reward function loss: -0.0479\n",
      "338672: reward: 500.00, mean_100: 499.38, episodes: 1040, reward function loss: -0.0458\n",
      "339172: reward: 500.00, mean_100: 499.38, episodes: 1041, reward function loss: -0.0458\n",
      "339672: reward: 500.00, mean_100: 499.38, episodes: 1042, reward function loss: -0.0458\n",
      "340084: reward: 412.00, mean_100: 498.50, episodes: 1043, reward function loss: -0.0458\n",
      "340584: reward: 500.00, mean_100: 498.50, episodes: 1044, reward function loss: -0.0453\n",
      "341084: reward: 500.00, mean_100: 498.50, episodes: 1045, reward function loss: -0.0453\n",
      "341584: reward: 500.00, mean_100: 498.50, episodes: 1046, reward function loss: -0.0453\n",
      "342084: reward: 500.00, mean_100: 498.50, episodes: 1047, reward function loss: -0.0453\n",
      "342584: reward: 500.00, mean_100: 498.50, episodes: 1048, reward function loss: -0.0478\n",
      "343084: reward: 500.00, mean_100: 498.50, episodes: 1049, reward function loss: -0.0478\n",
      "343584: reward: 500.00, mean_100: 498.50, episodes: 1050, reward function loss: -0.0478\n",
      "344084: reward: 500.00, mean_100: 498.50, episodes: 1051, reward function loss: -0.0478\n",
      "344584: reward: 500.00, mean_100: 498.50, episodes: 1052, reward function loss: -0.0447\n",
      "345084: reward: 500.00, mean_100: 498.50, episodes: 1053, reward function loss: -0.0447\n",
      "345584: reward: 500.00, mean_100: 498.50, episodes: 1054, reward function loss: -0.0447\n",
      "346084: reward: 500.00, mean_100: 498.50, episodes: 1055, reward function loss: -0.0447\n",
      "346584: reward: 500.00, mean_100: 498.50, episodes: 1056, reward function loss: -0.0465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347084: reward: 500.00, mean_100: 498.50, episodes: 1057, reward function loss: -0.0465\n",
      "347584: reward: 500.00, mean_100: 498.50, episodes: 1058, reward function loss: -0.0465\n",
      "348084: reward: 500.00, mean_100: 498.50, episodes: 1059, reward function loss: -0.0465\n",
      "348584: reward: 500.00, mean_100: 498.50, episodes: 1060, reward function loss: -0.0476\n",
      "349084: reward: 500.00, mean_100: 498.50, episodes: 1061, reward function loss: -0.0476\n",
      "349584: reward: 500.00, mean_100: 498.50, episodes: 1062, reward function loss: -0.0476\n",
      "350084: reward: 500.00, mean_100: 498.50, episodes: 1063, reward function loss: -0.0476\n",
      "350584: reward: 500.00, mean_100: 498.50, episodes: 1064, reward function loss: -0.0474\n",
      "351084: reward: 500.00, mean_100: 498.50, episodes: 1065, reward function loss: -0.0474\n",
      "351584: reward: 500.00, mean_100: 499.12, episodes: 1066, reward function loss: -0.0474\n",
      "352084: reward: 500.00, mean_100: 499.12, episodes: 1067, reward function loss: -0.0474\n",
      "352584: reward: 500.00, mean_100: 499.12, episodes: 1068, reward function loss: -0.0474\n",
      "353084: reward: 500.00, mean_100: 499.12, episodes: 1069, reward function loss: -0.0474\n",
      "353584: reward: 500.00, mean_100: 499.12, episodes: 1070, reward function loss: -0.0474\n",
      "354084: reward: 500.00, mean_100: 499.12, episodes: 1071, reward function loss: -0.0474\n",
      "354584: reward: 500.00, mean_100: 499.12, episodes: 1072, reward function loss: -0.0478\n",
      "355084: reward: 500.00, mean_100: 499.12, episodes: 1073, reward function loss: -0.0478\n",
      "355584: reward: 500.00, mean_100: 499.12, episodes: 1074, reward function loss: -0.0478\n",
      "356084: reward: 500.00, mean_100: 499.12, episodes: 1075, reward function loss: -0.0478\n",
      "356584: reward: 500.00, mean_100: 499.12, episodes: 1076, reward function loss: -0.0466\n",
      "357084: reward: 500.00, mean_100: 499.12, episodes: 1077, reward function loss: -0.0466\n",
      "357584: reward: 500.00, mean_100: 499.12, episodes: 1078, reward function loss: -0.0466\n",
      "358084: reward: 500.00, mean_100: 499.12, episodes: 1079, reward function loss: -0.0466\n",
      "358584: reward: 500.00, mean_100: 499.12, episodes: 1080, reward function loss: -0.0458\n",
      "359084: reward: 500.00, mean_100: 499.12, episodes: 1081, reward function loss: -0.0458\n",
      "359584: reward: 500.00, mean_100: 499.12, episodes: 1082, reward function loss: -0.0458\n",
      "360084: reward: 500.00, mean_100: 499.12, episodes: 1083, reward function loss: -0.0458\n",
      "360584: reward: 500.00, mean_100: 499.12, episodes: 1084, reward function loss: -0.0477\n",
      "361084: reward: 500.00, mean_100: 499.12, episodes: 1085, reward function loss: -0.0477\n",
      "361584: reward: 500.00, mean_100: 499.12, episodes: 1086, reward function loss: -0.0477\n",
      "362084: reward: 500.00, mean_100: 499.12, episodes: 1087, reward function loss: -0.0477\n",
      "362584: reward: 500.00, mean_100: 499.12, episodes: 1088, reward function loss: -0.0477\n",
      "363084: reward: 500.00, mean_100: 499.12, episodes: 1089, reward function loss: -0.0477\n",
      "363584: reward: 500.00, mean_100: 499.12, episodes: 1090, reward function loss: -0.0477\n",
      "364084: reward: 500.00, mean_100: 499.12, episodes: 1091, reward function loss: -0.0477\n",
      "364584: reward: 500.00, mean_100: 499.12, episodes: 1092, reward function loss: -0.0421\n",
      "365084: reward: 500.00, mean_100: 499.12, episodes: 1093, reward function loss: -0.0421\n",
      "365584: reward: 500.00, mean_100: 499.12, episodes: 1094, reward function loss: -0.0421\n",
      "366084: reward: 500.00, mean_100: 499.12, episodes: 1095, reward function loss: -0.0421\n",
      "366584: reward: 500.00, mean_100: 499.12, episodes: 1096, reward function loss: -0.0473\n",
      "367084: reward: 500.00, mean_100: 499.12, episodes: 1097, reward function loss: -0.0473\n",
      "367584: reward: 500.00, mean_100: 499.12, episodes: 1098, reward function loss: -0.0473\n",
      "368084: reward: 500.00, mean_100: 499.12, episodes: 1099, reward function loss: -0.0473\n",
      "368584: reward: 500.00, mean_100: 499.12, episodes: 1100, reward function loss: -0.0477\n",
      "369084: reward: 500.00, mean_100: 499.12, episodes: 1101, reward function loss: -0.0477\n",
      "369584: reward: 500.00, mean_100: 499.12, episodes: 1102, reward function loss: -0.0477\n",
      "370084: reward: 500.00, mean_100: 499.12, episodes: 1103, reward function loss: -0.0477\n",
      "370584: reward: 500.00, mean_100: 499.12, episodes: 1104, reward function loss: -0.0477\n",
      "371084: reward: 500.00, mean_100: 499.12, episodes: 1105, reward function loss: -0.0477\n",
      "371584: reward: 500.00, mean_100: 499.12, episodes: 1106, reward function loss: -0.0477\n",
      "372084: reward: 500.00, mean_100: 499.12, episodes: 1107, reward function loss: -0.0477\n",
      "372584: reward: 500.00, mean_100: 499.12, episodes: 1108, reward function loss: -0.0474\n",
      "373084: reward: 500.00, mean_100: 499.12, episodes: 1109, reward function loss: -0.0474\n",
      "373584: reward: 500.00, mean_100: 499.12, episodes: 1110, reward function loss: -0.0474\n",
      "374084: reward: 500.00, mean_100: 499.12, episodes: 1111, reward function loss: -0.0474\n",
      "374584: reward: 500.00, mean_100: 499.12, episodes: 1112, reward function loss: -0.0446\n",
      "375084: reward: 500.00, mean_100: 499.12, episodes: 1113, reward function loss: -0.0446\n",
      "375584: reward: 500.00, mean_100: 499.12, episodes: 1114, reward function loss: -0.0446\n",
      "375902: reward: 318.00, mean_100: 497.30, episodes: 1115, reward function loss: -0.0446\n",
      "376402: reward: 500.00, mean_100: 497.30, episodes: 1116, reward function loss: -0.0426\n",
      "376902: reward: 500.00, mean_100: 497.30, episodes: 1117, reward function loss: -0.0426\n",
      "377402: reward: 500.00, mean_100: 497.30, episodes: 1118, reward function loss: -0.0426\n",
      "377902: reward: 500.00, mean_100: 497.30, episodes: 1119, reward function loss: -0.0426\n",
      "378402: reward: 500.00, mean_100: 497.30, episodes: 1120, reward function loss: -0.0433\n",
      "378902: reward: 500.00, mean_100: 497.30, episodes: 1121, reward function loss: -0.0433\n",
      "379402: reward: 500.00, mean_100: 497.30, episodes: 1122, reward function loss: -0.0433\n",
      "379902: reward: 500.00, mean_100: 497.30, episodes: 1123, reward function loss: -0.0433\n",
      "380402: reward: 500.00, mean_100: 497.30, episodes: 1124, reward function loss: -0.0465\n",
      "380902: reward: 500.00, mean_100: 497.30, episodes: 1125, reward function loss: -0.0465\n",
      "381402: reward: 500.00, mean_100: 497.30, episodes: 1126, reward function loss: -0.0465\n",
      "381902: reward: 500.00, mean_100: 497.30, episodes: 1127, reward function loss: -0.0465\n",
      "382402: reward: 500.00, mean_100: 497.30, episodes: 1128, reward function loss: -0.0383\n",
      "382902: reward: 500.00, mean_100: 497.30, episodes: 1129, reward function loss: -0.0383\n",
      "383402: reward: 500.00, mean_100: 497.30, episodes: 1130, reward function loss: -0.0383\n",
      "383902: reward: 500.00, mean_100: 497.30, episodes: 1131, reward function loss: -0.0383\n",
      "384402: reward: 500.00, mean_100: 497.30, episodes: 1132, reward function loss: -0.0417\n",
      "384902: reward: 500.00, mean_100: 497.30, episodes: 1133, reward function loss: -0.0417\n",
      "385402: reward: 500.00, mean_100: 497.30, episodes: 1134, reward function loss: -0.0417\n",
      "385902: reward: 500.00, mean_100: 497.30, episodes: 1135, reward function loss: -0.0417\n",
      "386402: reward: 500.00, mean_100: 497.30, episodes: 1136, reward function loss: -0.0291\n",
      "386902: reward: 500.00, mean_100: 497.30, episodes: 1137, reward function loss: -0.0291\n",
      "387402: reward: 500.00, mean_100: 497.30, episodes: 1138, reward function loss: -0.0291\n",
      "387902: reward: 500.00, mean_100: 497.30, episodes: 1139, reward function loss: -0.0291\n",
      "388402: reward: 500.00, mean_100: 497.30, episodes: 1140, reward function loss: -0.0190\n",
      "388902: reward: 500.00, mean_100: 497.30, episodes: 1141, reward function loss: -0.0190\n",
      "389402: reward: 500.00, mean_100: 497.30, episodes: 1142, reward function loss: -0.0190\n",
      "389902: reward: 500.00, mean_100: 498.18, episodes: 1143, reward function loss: -0.0190\n",
      "390402: reward: 500.00, mean_100: 498.18, episodes: 1144, reward function loss: -0.0058\n",
      "390902: reward: 500.00, mean_100: 498.18, episodes: 1145, reward function loss: -0.0058\n",
      "391402: reward: 500.00, mean_100: 498.18, episodes: 1146, reward function loss: -0.0058\n",
      "391902: reward: 500.00, mean_100: 498.18, episodes: 1147, reward function loss: -0.0058\n",
      "392402: reward: 500.00, mean_100: 498.18, episodes: 1148, reward function loss: -0.0001\n",
      "392902: reward: 500.00, mean_100: 498.18, episodes: 1149, reward function loss: -0.0001\n",
      "393402: reward: 500.00, mean_100: 498.18, episodes: 1150, reward function loss: -0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393902: reward: 500.00, mean_100: 498.18, episodes: 1151, reward function loss: -0.0001\n",
      "394402: reward: 500.00, mean_100: 498.18, episodes: 1152, reward function loss: -0.0014\n",
      "394902: reward: 500.00, mean_100: 498.18, episodes: 1153, reward function loss: -0.0014\n",
      "395402: reward: 500.00, mean_100: 498.18, episodes: 1154, reward function loss: -0.0014\n",
      "395902: reward: 500.00, mean_100: 498.18, episodes: 1155, reward function loss: -0.0014\n",
      "396402: reward: 500.00, mean_100: 498.18, episodes: 1156, reward function loss: -0.0015\n",
      "396902: reward: 500.00, mean_100: 498.18, episodes: 1157, reward function loss: -0.0015\n",
      "397402: reward: 500.00, mean_100: 498.18, episodes: 1158, reward function loss: -0.0015\n",
      "397902: reward: 500.00, mean_100: 498.18, episodes: 1159, reward function loss: -0.0015\n",
      "398402: reward: 500.00, mean_100: 498.18, episodes: 1160, reward function loss: -0.0046\n",
      "398902: reward: 500.00, mean_100: 498.18, episodes: 1161, reward function loss: -0.0046\n",
      "399402: reward: 500.00, mean_100: 498.18, episodes: 1162, reward function loss: -0.0046\n",
      "399902: reward: 500.00, mean_100: 498.18, episodes: 1163, reward function loss: -0.0046\n",
      "400402: reward: 500.00, mean_100: 498.18, episodes: 1164, reward function loss: -0.0187\n",
      "400902: reward: 500.00, mean_100: 498.18, episodes: 1165, reward function loss: -0.0187\n",
      "401402: reward: 500.00, mean_100: 498.18, episodes: 1166, reward function loss: -0.0187\n",
      "401902: reward: 500.00, mean_100: 498.18, episodes: 1167, reward function loss: -0.0187\n",
      "402402: reward: 500.00, mean_100: 498.18, episodes: 1168, reward function loss: -0.0335\n",
      "402902: reward: 500.00, mean_100: 498.18, episodes: 1169, reward function loss: -0.0335\n",
      "403402: reward: 500.00, mean_100: 498.18, episodes: 1170, reward function loss: -0.0335\n",
      "403902: reward: 500.00, mean_100: 498.18, episodes: 1171, reward function loss: -0.0335\n",
      "404402: reward: 500.00, mean_100: 498.18, episodes: 1172, reward function loss: -0.0202\n",
      "404902: reward: 500.00, mean_100: 498.18, episodes: 1173, reward function loss: -0.0202\n",
      "405402: reward: 500.00, mean_100: 498.18, episodes: 1174, reward function loss: -0.0202\n",
      "405902: reward: 500.00, mean_100: 498.18, episodes: 1175, reward function loss: -0.0202\n",
      "406402: reward: 500.00, mean_100: 498.18, episodes: 1176, reward function loss: -0.0339\n",
      "406902: reward: 500.00, mean_100: 498.18, episodes: 1177, reward function loss: -0.0339\n",
      "407402: reward: 500.00, mean_100: 498.18, episodes: 1178, reward function loss: -0.0339\n",
      "407902: reward: 500.00, mean_100: 498.18, episodes: 1179, reward function loss: -0.0339\n",
      "408402: reward: 500.00, mean_100: 498.18, episodes: 1180, reward function loss: -0.0370\n",
      "408902: reward: 500.00, mean_100: 498.18, episodes: 1181, reward function loss: -0.0370\n",
      "408915: reward:  13.00, mean_100: 493.31, episodes: 1182, reward function loss: -0.0370\n",
      "408962: reward:  47.00, mean_100: 488.78, episodes: 1183, reward function loss: -0.0370\n",
      "409462: reward: 500.00, mean_100: 488.78, episodes: 1184, reward function loss: -0.0187\n",
      "409477: reward:  15.00, mean_100: 483.93, episodes: 1185, reward function loss: -0.0187\n",
      "409977: reward: 500.00, mean_100: 483.93, episodes: 1186, reward function loss: -0.0187\n",
      "410477: reward: 500.00, mean_100: 483.93, episodes: 1187, reward function loss: -0.0187\n",
      "410977: reward: 500.00, mean_100: 483.93, episodes: 1188, reward function loss: -0.0292\n",
      "411477: reward: 500.00, mean_100: 483.93, episodes: 1189, reward function loss: -0.0292\n",
      "411500: reward:  23.00, mean_100: 479.16, episodes: 1190, reward function loss: -0.0292\n",
      "412000: reward: 500.00, mean_100: 479.16, episodes: 1191, reward function loss: -0.0292\n",
      "412019: reward:  19.00, mean_100: 474.35, episodes: 1192, reward function loss: -0.0200\n",
      "412519: reward: 500.00, mean_100: 474.35, episodes: 1193, reward function loss: -0.0200\n",
      "413019: reward: 500.00, mean_100: 474.35, episodes: 1194, reward function loss: -0.0200\n",
      "413519: reward: 500.00, mean_100: 474.35, episodes: 1195, reward function loss: -0.0200\n",
      "414019: reward: 500.00, mean_100: 474.35, episodes: 1196, reward function loss: -0.0381\n",
      "414519: reward: 500.00, mean_100: 474.35, episodes: 1197, reward function loss: -0.0381\n",
      "415019: reward: 500.00, mean_100: 474.35, episodes: 1198, reward function loss: -0.0381\n",
      "415519: reward: 500.00, mean_100: 474.35, episodes: 1199, reward function loss: -0.0381\n",
      "416019: reward: 500.00, mean_100: 474.35, episodes: 1200, reward function loss: -0.0391\n",
      "416034: reward:  15.00, mean_100: 469.50, episodes: 1201, reward function loss: -0.0391\n",
      "416054: reward:  20.00, mean_100: 464.70, episodes: 1202, reward function loss: -0.0391\n",
      "416554: reward: 500.00, mean_100: 464.70, episodes: 1203, reward function loss: -0.0391\n",
      "417054: reward: 500.00, mean_100: 464.70, episodes: 1204, reward function loss: -0.0206\n",
      "417554: reward: 500.00, mean_100: 464.70, episodes: 1205, reward function loss: -0.0206\n",
      "417695: reward: 141.00, mean_100: 461.11, episodes: 1206, reward function loss: -0.0206\n",
      "417714: reward:  19.00, mean_100: 456.30, episodes: 1207, reward function loss: -0.0206\n",
      "418214: reward: 500.00, mean_100: 456.30, episodes: 1208, reward function loss: -0.0194\n",
      "418714: reward: 500.00, mean_100: 456.30, episodes: 1209, reward function loss: -0.0194\n",
      "419214: reward: 500.00, mean_100: 456.30, episodes: 1210, reward function loss: -0.0194\n",
      "419261: reward:  47.00, mean_100: 451.77, episodes: 1211, reward function loss: -0.0194\n",
      "419761: reward: 500.00, mean_100: 451.77, episodes: 1212, reward function loss: -0.0283\n",
      "420261: reward: 500.00, mean_100: 451.77, episodes: 1213, reward function loss: -0.0283\n",
      "420761: reward: 500.00, mean_100: 451.77, episodes: 1214, reward function loss: -0.0283\n",
      "421261: reward: 500.00, mean_100: 453.59, episodes: 1215, reward function loss: -0.0283\n",
      "421761: reward: 500.00, mean_100: 453.59, episodes: 1216, reward function loss: -0.0378\n",
      "422261: reward: 500.00, mean_100: 453.59, episodes: 1217, reward function loss: -0.0378\n",
      "422761: reward: 500.00, mean_100: 453.59, episodes: 1218, reward function loss: -0.0378\n",
      "422777: reward:  16.00, mean_100: 448.75, episodes: 1219, reward function loss: -0.0378\n",
      "423277: reward: 500.00, mean_100: 448.75, episodes: 1220, reward function loss: -0.0271\n",
      "423777: reward: 500.00, mean_100: 448.75, episodes: 1221, reward function loss: -0.0271\n",
      "424277: reward: 500.00, mean_100: 448.75, episodes: 1222, reward function loss: -0.0271\n",
      "424777: reward: 500.00, mean_100: 448.75, episodes: 1223, reward function loss: -0.0271\n",
      "425277: reward: 500.00, mean_100: 448.75, episodes: 1224, reward function loss: -0.0375\n",
      "425291: reward:  14.00, mean_100: 443.89, episodes: 1225, reward function loss: -0.0375\n",
      "425791: reward: 500.00, mean_100: 443.89, episodes: 1226, reward function loss: -0.0375\n",
      "426291: reward: 500.00, mean_100: 443.89, episodes: 1227, reward function loss: -0.0375\n",
      "426303: reward:  12.00, mean_100: 439.01, episodes: 1228, reward function loss: -0.0147\n",
      "426803: reward: 500.00, mean_100: 439.01, episodes: 1229, reward function loss: -0.0147\n",
      "427303: reward: 500.00, mean_100: 439.01, episodes: 1230, reward function loss: -0.0147\n",
      "427318: reward:  15.00, mean_100: 434.16, episodes: 1231, reward function loss: -0.0147\n",
      "427818: reward: 500.00, mean_100: 434.16, episodes: 1232, reward function loss: -0.0242\n",
      "428318: reward: 500.00, mean_100: 434.16, episodes: 1233, reward function loss: -0.0242\n",
      "428818: reward: 500.00, mean_100: 434.16, episodes: 1234, reward function loss: -0.0242\n",
      "429318: reward: 500.00, mean_100: 434.16, episodes: 1235, reward function loss: -0.0242\n",
      "429818: reward: 500.00, mean_100: 434.16, episodes: 1236, reward function loss: -0.0325\n",
      "429886: reward:  68.00, mean_100: 429.84, episodes: 1237, reward function loss: -0.0325\n",
      "430386: reward: 500.00, mean_100: 429.84, episodes: 1238, reward function loss: -0.0325\n",
      "430886: reward: 500.00, mean_100: 429.84, episodes: 1239, reward function loss: -0.0325\n",
      "431386: reward: 500.00, mean_100: 429.84, episodes: 1240, reward function loss: -0.0231\n",
      "431453: reward:  67.00, mean_100: 425.51, episodes: 1241, reward function loss: -0.0231\n",
      "431953: reward: 500.00, mean_100: 425.51, episodes: 1242, reward function loss: -0.0231\n",
      "432453: reward: 500.00, mean_100: 425.51, episodes: 1243, reward function loss: -0.0231\n",
      "432492: reward:  39.00, mean_100: 420.90, episodes: 1244, reward function loss: -0.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432992: reward: 500.00, mean_100: 420.90, episodes: 1245, reward function loss: -0.0156\n",
      "433492: reward: 500.00, mean_100: 420.90, episodes: 1246, reward function loss: -0.0156\n",
      "433510: reward:  18.00, mean_100: 416.08, episodes: 1247, reward function loss: -0.0156\n",
      "434010: reward: 500.00, mean_100: 416.08, episodes: 1248, reward function loss: -0.0187\n",
      "434510: reward: 500.00, mean_100: 416.08, episodes: 1249, reward function loss: -0.0187\n",
      "435010: reward: 500.00, mean_100: 416.08, episodes: 1250, reward function loss: -0.0187\n",
      "435510: reward: 500.00, mean_100: 416.08, episodes: 1251, reward function loss: -0.0187\n",
      "436010: reward: 500.00, mean_100: 416.08, episodes: 1252, reward function loss: -0.0244\n",
      "436510: reward: 500.00, mean_100: 416.08, episodes: 1253, reward function loss: -0.0244\n",
      "437010: reward: 500.00, mean_100: 416.08, episodes: 1254, reward function loss: -0.0244\n",
      "437510: reward: 500.00, mean_100: 416.08, episodes: 1255, reward function loss: -0.0244\n",
      "438010: reward: 500.00, mean_100: 416.08, episodes: 1256, reward function loss: -0.0173\n",
      "438510: reward: 500.00, mean_100: 416.08, episodes: 1257, reward function loss: -0.0173\n",
      "439010: reward: 500.00, mean_100: 416.08, episodes: 1258, reward function loss: -0.0173\n",
      "439510: reward: 500.00, mean_100: 416.08, episodes: 1259, reward function loss: -0.0173\n",
      "440010: reward: 500.00, mean_100: 416.08, episodes: 1260, reward function loss: -0.0000\n",
      "440510: reward: 500.00, mean_100: 416.08, episodes: 1261, reward function loss: -0.0000\n",
      "441010: reward: 500.00, mean_100: 416.08, episodes: 1262, reward function loss: -0.0000\n",
      "441329: reward: 319.00, mean_100: 414.27, episodes: 1263, reward function loss: -0.0000\n",
      "441829: reward: 500.00, mean_100: 414.27, episodes: 1264, reward function loss: -0.0000\n",
      "442329: reward: 500.00, mean_100: 414.27, episodes: 1265, reward function loss: -0.0000\n",
      "442829: reward: 500.00, mean_100: 414.27, episodes: 1266, reward function loss: -0.0000\n",
      "443329: reward: 500.00, mean_100: 414.27, episodes: 1267, reward function loss: -0.0000\n",
      "443829: reward: 500.00, mean_100: 414.27, episodes: 1268, reward function loss: -0.0000\n",
      "444329: reward: 500.00, mean_100: 414.27, episodes: 1269, reward function loss: -0.0000\n",
      "444829: reward: 500.00, mean_100: 414.27, episodes: 1270, reward function loss: -0.0000\n",
      "445329: reward: 500.00, mean_100: 414.27, episodes: 1271, reward function loss: -0.0000\n",
      "445829: reward: 500.00, mean_100: 414.27, episodes: 1272, reward function loss: -0.0000\n",
      "446329: reward: 500.00, mean_100: 414.27, episodes: 1273, reward function loss: -0.0000\n",
      "446829: reward: 500.00, mean_100: 414.27, episodes: 1274, reward function loss: -0.0000\n",
      "447329: reward: 500.00, mean_100: 414.27, episodes: 1275, reward function loss: -0.0000\n",
      "447829: reward: 500.00, mean_100: 414.27, episodes: 1276, reward function loss: -0.0000\n",
      "448329: reward: 500.00, mean_100: 414.27, episodes: 1277, reward function loss: -0.0000\n",
      "448829: reward: 500.00, mean_100: 414.27, episodes: 1278, reward function loss: -0.0000\n",
      "449329: reward: 500.00, mean_100: 414.27, episodes: 1279, reward function loss: -0.0000\n",
      "449829: reward: 500.00, mean_100: 414.27, episodes: 1280, reward function loss: -0.0000\n",
      "450329: reward: 500.00, mean_100: 414.27, episodes: 1281, reward function loss: -0.0000\n",
      "450829: reward: 500.00, mean_100: 419.14, episodes: 1282, reward function loss: -0.0000\n",
      "451329: reward: 500.00, mean_100: 423.67, episodes: 1283, reward function loss: -0.0000\n",
      "451829: reward: 500.00, mean_100: 423.67, episodes: 1284, reward function loss: -0.0000\n",
      "452329: reward: 500.00, mean_100: 428.52, episodes: 1285, reward function loss: -0.0000\n",
      "452829: reward: 500.00, mean_100: 428.52, episodes: 1286, reward function loss: -0.0000\n",
      "453329: reward: 500.00, mean_100: 428.52, episodes: 1287, reward function loss: -0.0000\n",
      "453829: reward: 500.00, mean_100: 428.52, episodes: 1288, reward function loss: -0.0000\n",
      "454329: reward: 500.00, mean_100: 428.52, episodes: 1289, reward function loss: -0.0000\n",
      "454829: reward: 500.00, mean_100: 433.29, episodes: 1290, reward function loss: -0.0000\n",
      "455329: reward: 500.00, mean_100: 433.29, episodes: 1291, reward function loss: -0.0000\n",
      "455403: reward:  74.00, mean_100: 433.84, episodes: 1292, reward function loss: -0.0000\n",
      "455853: reward: 450.00, mean_100: 433.34, episodes: 1293, reward function loss: -0.0000\n",
      "456132: reward: 279.00, mean_100: 431.13, episodes: 1294, reward function loss: -0.0000\n",
      "456632: reward: 500.00, mean_100: 431.13, episodes: 1295, reward function loss: -0.0000\n",
      "456683: reward:  51.00, mean_100: 426.64, episodes: 1296, reward function loss: -0.0000\n",
      "456871: reward: 188.00, mean_100: 423.52, episodes: 1297, reward function loss: -0.0000\n",
      "457143: reward: 272.00, mean_100: 421.24, episodes: 1298, reward function loss: -0.0000\n",
      "457192: reward:  49.00, mean_100: 416.73, episodes: 1299, reward function loss: -0.0000\n",
      "457488: reward: 296.00, mean_100: 414.69, episodes: 1300, reward function loss: -0.0000\n",
      "457906: reward: 418.00, mean_100: 418.72, episodes: 1301, reward function loss: -0.0000\n",
      "457956: reward:  50.00, mean_100: 419.02, episodes: 1302, reward function loss: -0.0000\n",
      "458027: reward:  71.00, mean_100: 414.73, episodes: 1303, reward function loss: -0.0000\n",
      "458477: reward: 450.00, mean_100: 414.23, episodes: 1304, reward function loss: -0.0000\n",
      "458523: reward:  46.00, mean_100: 409.69, episodes: 1305, reward function loss: -0.0000\n",
      "458572: reward:  49.00, mean_100: 408.77, episodes: 1306, reward function loss: -0.0000\n",
      "458951: reward: 379.00, mean_100: 412.37, episodes: 1307, reward function loss: -0.0000\n",
      "459062: reward: 111.00, mean_100: 408.48, episodes: 1308, reward function loss: -0.0000\n",
      "459230: reward: 168.00, mean_100: 405.16, episodes: 1309, reward function loss: -0.0000\n",
      "459278: reward:  48.00, mean_100: 400.64, episodes: 1310, reward function loss: -0.0000\n",
      "459778: reward: 500.00, mean_100: 405.17, episodes: 1311, reward function loss: -0.0000\n",
      "460278: reward: 500.00, mean_100: 405.17, episodes: 1312, reward function loss: -0.0000\n",
      "460707: reward: 429.00, mean_100: 404.46, episodes: 1313, reward function loss: -0.0000\n",
      "461207: reward: 500.00, mean_100: 404.46, episodes: 1314, reward function loss: -0.0000\n",
      "461707: reward: 500.00, mean_100: 404.46, episodes: 1315, reward function loss: -0.0000\n",
      "462207: reward: 500.00, mean_100: 404.46, episodes: 1316, reward function loss: -0.0000\n",
      "462707: reward: 500.00, mean_100: 404.46, episodes: 1317, reward function loss: -0.0000\n",
      "463207: reward: 500.00, mean_100: 404.46, episodes: 1318, reward function loss: -0.0000\n",
      "463707: reward: 500.00, mean_100: 409.30, episodes: 1319, reward function loss: -0.0000\n",
      "464207: reward: 500.00, mean_100: 409.30, episodes: 1320, reward function loss: -0.0000\n",
      "464707: reward: 500.00, mean_100: 409.30, episodes: 1321, reward function loss: -0.0000\n",
      "465207: reward: 500.00, mean_100: 409.30, episodes: 1322, reward function loss: -0.0000\n",
      "465707: reward: 500.00, mean_100: 409.30, episodes: 1323, reward function loss: -0.0000\n",
      "466207: reward: 500.00, mean_100: 409.30, episodes: 1324, reward function loss: -0.0000\n",
      "466707: reward: 500.00, mean_100: 414.16, episodes: 1325, reward function loss: -0.0000\n",
      "467207: reward: 500.00, mean_100: 414.16, episodes: 1326, reward function loss: -0.0000\n",
      "467707: reward: 500.00, mean_100: 414.16, episodes: 1327, reward function loss: -0.0000\n",
      "468207: reward: 500.00, mean_100: 419.04, episodes: 1328, reward function loss: -0.0000\n",
      "468416: reward: 209.00, mean_100: 416.13, episodes: 1329, reward function loss: -0.0000\n",
      "468916: reward: 500.00, mean_100: 416.13, episodes: 1330, reward function loss: -0.0000\n",
      "469416: reward: 500.00, mean_100: 420.98, episodes: 1331, reward function loss: -0.0000\n",
      "469916: reward: 500.00, mean_100: 420.98, episodes: 1332, reward function loss: -0.0000\n",
      "470211: reward: 295.00, mean_100: 418.93, episodes: 1333, reward function loss: -0.0000\n",
      "470711: reward: 500.00, mean_100: 418.93, episodes: 1334, reward function loss: -0.0000\n",
      "471137: reward: 426.00, mean_100: 418.19, episodes: 1335, reward function loss: -0.0000\n",
      "471416: reward: 279.00, mean_100: 415.98, episodes: 1336, reward function loss: -0.0001\n",
      "471806: reward: 390.00, mean_100: 419.20, episodes: 1337, reward function loss: -0.0001\n",
      "472306: reward: 500.00, mean_100: 419.20, episodes: 1338, reward function loss: -0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472806: reward: 500.00, mean_100: 419.20, episodes: 1339, reward function loss: -0.0001\n",
      "473306: reward: 500.00, mean_100: 419.20, episodes: 1340, reward function loss: -0.0001\n",
      "473806: reward: 500.00, mean_100: 423.53, episodes: 1341, reward function loss: -0.0001\n",
      "474306: reward: 500.00, mean_100: 423.53, episodes: 1342, reward function loss: -0.0001\n",
      "474776: reward: 470.00, mean_100: 423.23, episodes: 1343, reward function loss: -0.0001\n",
      "475026: reward: 250.00, mean_100: 425.34, episodes: 1344, reward function loss: -0.0003\n",
      "475418: reward: 392.00, mean_100: 424.26, episodes: 1345, reward function loss: -0.0003\n",
      "475918: reward: 500.00, mean_100: 424.26, episodes: 1346, reward function loss: -0.0003\n",
      "476148: reward: 230.00, mean_100: 426.38, episodes: 1347, reward function loss: -0.0003\n",
      "476648: reward: 500.00, mean_100: 426.38, episodes: 1348, reward function loss: -0.0013\n",
      "477077: reward: 429.00, mean_100: 425.67, episodes: 1349, reward function loss: -0.0013\n",
      "477577: reward: 500.00, mean_100: 425.67, episodes: 1350, reward function loss: -0.0013\n",
      "478077: reward: 500.00, mean_100: 425.67, episodes: 1351, reward function loss: -0.0013\n",
      "478498: reward: 421.00, mean_100: 424.88, episodes: 1352, reward function loss: -0.0076\n",
      "478998: reward: 500.00, mean_100: 424.88, episodes: 1353, reward function loss: -0.0076\n",
      "479226: reward: 228.00, mean_100: 422.16, episodes: 1354, reward function loss: -0.0076\n",
      "479562: reward: 336.00, mean_100: 420.52, episodes: 1355, reward function loss: -0.0076\n",
      "479880: reward: 318.00, mean_100: 418.70, episodes: 1356, reward function loss: -0.0147\n",
      "480380: reward: 500.00, mean_100: 418.70, episodes: 1357, reward function loss: -0.0147\n",
      "480637: reward: 257.00, mean_100: 416.27, episodes: 1358, reward function loss: -0.0147\n",
      "480951: reward: 314.00, mean_100: 414.41, episodes: 1359, reward function loss: -0.0147\n",
      "481451: reward: 500.00, mean_100: 414.41, episodes: 1360, reward function loss: -0.0136\n",
      "481751: reward: 300.00, mean_100: 412.41, episodes: 1361, reward function loss: -0.0136\n",
      "482091: reward: 340.00, mean_100: 410.81, episodes: 1362, reward function loss: -0.0136\n",
      "482591: reward: 500.00, mean_100: 412.62, episodes: 1363, reward function loss: -0.0136\n",
      "483091: reward: 500.00, mean_100: 412.62, episodes: 1364, reward function loss: -0.0202\n",
      "483487: reward: 396.00, mean_100: 411.58, episodes: 1365, reward function loss: -0.0202\n",
      "483987: reward: 500.00, mean_100: 411.58, episodes: 1366, reward function loss: -0.0202\n",
      "484311: reward: 324.00, mean_100: 409.82, episodes: 1367, reward function loss: -0.0202\n",
      "484811: reward: 500.00, mean_100: 409.82, episodes: 1368, reward function loss: -0.0160\n",
      "485039: reward: 228.00, mean_100: 407.10, episodes: 1369, reward function loss: -0.0160\n",
      "485539: reward: 500.00, mean_100: 407.10, episodes: 1370, reward function loss: -0.0160\n",
      "485920: reward: 381.00, mean_100: 405.91, episodes: 1371, reward function loss: -0.0160\n",
      "486420: reward: 500.00, mean_100: 405.91, episodes: 1372, reward function loss: -0.0279\n",
      "486892: reward: 472.00, mean_100: 405.63, episodes: 1373, reward function loss: -0.0279\n",
      "487392: reward: 500.00, mean_100: 405.63, episodes: 1374, reward function loss: -0.0279\n",
      "487710: reward: 318.00, mean_100: 403.81, episodes: 1375, reward function loss: -0.0279\n",
      "488025: reward: 315.00, mean_100: 401.96, episodes: 1376, reward function loss: -0.0269\n",
      "488431: reward: 406.00, mean_100: 401.02, episodes: 1377, reward function loss: -0.0269\n",
      "488531: reward: 100.00, mean_100: 397.02, episodes: 1378, reward function loss: -0.0269\n",
      "488636: reward: 105.00, mean_100: 393.07, episodes: 1379, reward function loss: -0.0269\n",
      "488911: reward: 275.00, mean_100: 390.82, episodes: 1380, reward function loss: -0.0130\n",
      "489158: reward: 247.00, mean_100: 388.29, episodes: 1381, reward function loss: -0.0130\n",
      "489658: reward: 500.00, mean_100: 388.29, episodes: 1382, reward function loss: -0.0130\n",
      "489923: reward: 265.00, mean_100: 385.94, episodes: 1383, reward function loss: -0.0130\n",
      "490330: reward: 407.00, mean_100: 385.01, episodes: 1384, reward function loss: -0.0245\n",
      "490503: reward: 173.00, mean_100: 381.74, episodes: 1385, reward function loss: -0.0245\n",
      "490760: reward: 257.00, mean_100: 379.31, episodes: 1386, reward function loss: -0.0245\n",
      "491260: reward: 500.00, mean_100: 379.31, episodes: 1387, reward function loss: -0.0245\n",
      "491760: reward: 500.00, mean_100: 379.31, episodes: 1388, reward function loss: -0.0184\n",
      "491857: reward:  97.00, mean_100: 375.28, episodes: 1389, reward function loss: -0.0184\n",
      "492357: reward: 500.00, mean_100: 375.28, episodes: 1390, reward function loss: -0.0184\n",
      "492600: reward: 243.00, mean_100: 372.71, episodes: 1391, reward function loss: -0.0184\n",
      "493039: reward: 439.00, mean_100: 376.36, episodes: 1392, reward function loss: -0.0154\n",
      "493539: reward: 500.00, mean_100: 376.86, episodes: 1393, reward function loss: -0.0154\n",
      "493951: reward: 412.00, mean_100: 378.19, episodes: 1394, reward function loss: -0.0154\n",
      "494184: reward: 233.00, mean_100: 375.52, episodes: 1395, reward function loss: -0.0154\n",
      "494404: reward: 220.00, mean_100: 377.21, episodes: 1396, reward function loss: -0.0211\n",
      "494548: reward: 144.00, mean_100: 376.77, episodes: 1397, reward function loss: -0.0211\n",
      "494728: reward: 180.00, mean_100: 375.85, episodes: 1398, reward function loss: -0.0211\n",
      "494995: reward: 267.00, mean_100: 378.03, episodes: 1399, reward function loss: -0.0211\n",
      "495495: reward: 500.00, mean_100: 380.07, episodes: 1400, reward function loss: -0.0103\n",
      "495761: reward: 266.00, mean_100: 378.55, episodes: 1401, reward function loss: -0.0103\n",
      "496031: reward: 270.00, mean_100: 380.75, episodes: 1402, reward function loss: -0.0103\n",
      "496237: reward: 206.00, mean_100: 382.10, episodes: 1403, reward function loss: -0.0103\n",
      "496442: reward: 205.00, mean_100: 379.65, episodes: 1404, reward function loss: -0.0108\n",
      "496544: reward: 102.00, mean_100: 380.21, episodes: 1405, reward function loss: -0.0108\n",
      "496764: reward: 220.00, mean_100: 381.92, episodes: 1406, reward function loss: -0.0108\n",
      "496834: reward:  70.00, mean_100: 378.83, episodes: 1407, reward function loss: -0.0108\n",
      "497334: reward: 500.00, mean_100: 382.72, episodes: 1408, reward function loss: 0.0000\n",
      "497621: reward: 287.00, mean_100: 383.91, episodes: 1409, reward function loss: 0.0000\n",
      "497877: reward: 256.00, mean_100: 385.99, episodes: 1410, reward function loss: 0.0000\n",
      "498240: reward: 363.00, mean_100: 384.62, episodes: 1411, reward function loss: 0.0000\n",
      "498527: reward: 287.00, mean_100: 382.49, episodes: 1412, reward function loss: 0.0000\n",
      "498626: reward:  99.00, mean_100: 379.19, episodes: 1413, reward function loss: 0.0000\n",
      "499109: reward: 483.00, mean_100: 379.02, episodes: 1414, reward function loss: 0.0000\n",
      "499354: reward: 245.00, mean_100: 376.47, episodes: 1415, reward function loss: 0.0000\n",
      "499629: reward: 275.00, mean_100: 374.22, episodes: 1416, reward function loss: 0.0000\n",
      "500129: reward: 500.00, mean_100: 374.22, episodes: 1417, reward function loss: 0.0000\n",
      "500534: reward: 405.00, mean_100: 373.27, episodes: 1418, reward function loss: 0.0000\n",
      "500948: reward: 414.00, mean_100: 372.41, episodes: 1419, reward function loss: 0.0000\n",
      "501154: reward: 206.00, mean_100: 369.47, episodes: 1420, reward function loss: 0.0000\n",
      "501331: reward: 177.00, mean_100: 366.24, episodes: 1421, reward function loss: 0.0000\n",
      "501454: reward: 123.00, mean_100: 362.47, episodes: 1422, reward function loss: 0.0000\n",
      "501954: reward: 500.00, mean_100: 362.47, episodes: 1423, reward function loss: 0.0000\n",
      "502454: reward: 500.00, mean_100: 362.47, episodes: 1424, reward function loss: 0.0000\n",
      "502534: reward:  80.00, mean_100: 358.27, episodes: 1425, reward function loss: 0.0000\n",
      "502842: reward: 308.00, mean_100: 356.35, episodes: 1426, reward function loss: 0.0000\n",
      "503184: reward: 342.00, mean_100: 354.77, episodes: 1427, reward function loss: 0.0000\n",
      "503523: reward: 339.00, mean_100: 353.16, episodes: 1428, reward function loss: 0.0000\n",
      "504023: reward: 500.00, mean_100: 356.07, episodes: 1429, reward function loss: 0.0000\n",
      "504523: reward: 500.00, mean_100: 356.07, episodes: 1430, reward function loss: 0.0000\n",
      "505023: reward: 500.00, mean_100: 356.07, episodes: 1431, reward function loss: 0.0000\n",
      "505523: reward: 500.00, mean_100: 356.07, episodes: 1432, reward function loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506023: reward: 500.00, mean_100: 358.12, episodes: 1433, reward function loss: 0.0000\n",
      "506156: reward: 133.00, mean_100: 354.45, episodes: 1434, reward function loss: 0.0000\n",
      "506656: reward: 500.00, mean_100: 355.19, episodes: 1435, reward function loss: 0.0000\n",
      "507156: reward: 500.00, mean_100: 357.40, episodes: 1436, reward function loss: 0.0000\n",
      "507656: reward: 500.00, mean_100: 358.50, episodes: 1437, reward function loss: 0.0000\n",
      "508156: reward: 500.00, mean_100: 358.50, episodes: 1438, reward function loss: 0.0000\n",
      "508656: reward: 500.00, mean_100: 358.50, episodes: 1439, reward function loss: 0.0000\n",
      "509156: reward: 500.00, mean_100: 358.50, episodes: 1440, reward function loss: 0.0000\n",
      "509408: reward: 252.00, mean_100: 356.02, episodes: 1441, reward function loss: 0.0000\n",
      "509908: reward: 500.00, mean_100: 356.02, episodes: 1442, reward function loss: 0.0000\n",
      "510408: reward: 500.00, mean_100: 356.32, episodes: 1443, reward function loss: 0.0000\n",
      "510908: reward: 500.00, mean_100: 358.82, episodes: 1444, reward function loss: 0.0000\n",
      "511408: reward: 500.00, mean_100: 359.90, episodes: 1445, reward function loss: 0.0000\n",
      "511908: reward: 500.00, mean_100: 359.90, episodes: 1446, reward function loss: 0.0000\n",
      "512408: reward: 500.00, mean_100: 362.60, episodes: 1447, reward function loss: 0.0000\n",
      "512908: reward: 500.00, mean_100: 362.60, episodes: 1448, reward function loss: 0.0000\n",
      "513408: reward: 500.00, mean_100: 363.31, episodes: 1449, reward function loss: 0.0000\n",
      "513908: reward: 500.00, mean_100: 363.31, episodes: 1450, reward function loss: 0.0000\n",
      "514408: reward: 500.00, mean_100: 363.31, episodes: 1451, reward function loss: 0.0000\n",
      "514908: reward: 500.00, mean_100: 364.10, episodes: 1452, reward function loss: 0.0000\n",
      "515408: reward: 500.00, mean_100: 364.10, episodes: 1453, reward function loss: 0.0000\n",
      "515908: reward: 500.00, mean_100: 366.82, episodes: 1454, reward function loss: 0.0000\n",
      "516408: reward: 500.00, mean_100: 368.46, episodes: 1455, reward function loss: 0.0000\n",
      "516908: reward: 500.00, mean_100: 370.28, episodes: 1456, reward function loss: 0.0000\n",
      "517408: reward: 500.00, mean_100: 370.28, episodes: 1457, reward function loss: 0.0000\n",
      "517908: reward: 500.00, mean_100: 372.71, episodes: 1458, reward function loss: 0.0000\n",
      "518408: reward: 500.00, mean_100: 374.57, episodes: 1459, reward function loss: 0.0000\n",
      "518908: reward: 500.00, mean_100: 374.57, episodes: 1460, reward function loss: 0.0000\n",
      "519408: reward: 500.00, mean_100: 376.57, episodes: 1461, reward function loss: 0.0000\n",
      "519908: reward: 500.00, mean_100: 378.17, episodes: 1462, reward function loss: 0.0000\n",
      "520408: reward: 500.00, mean_100: 378.17, episodes: 1463, reward function loss: 0.0000\n",
      "520908: reward: 500.00, mean_100: 378.17, episodes: 1464, reward function loss: 0.0000\n",
      "521408: reward: 500.00, mean_100: 379.21, episodes: 1465, reward function loss: 0.0000\n",
      "521908: reward: 500.00, mean_100: 379.21, episodes: 1466, reward function loss: 0.0000\n",
      "522408: reward: 500.00, mean_100: 380.97, episodes: 1467, reward function loss: 0.0000\n",
      "522908: reward: 500.00, mean_100: 380.97, episodes: 1468, reward function loss: 0.0000\n",
      "523408: reward: 500.00, mean_100: 383.69, episodes: 1469, reward function loss: 0.0000\n",
      "523908: reward: 500.00, mean_100: 383.69, episodes: 1470, reward function loss: 0.0000\n",
      "524408: reward: 500.00, mean_100: 384.88, episodes: 1471, reward function loss: 0.0000\n",
      "524908: reward: 500.00, mean_100: 384.88, episodes: 1472, reward function loss: 0.0000\n",
      "525408: reward: 500.00, mean_100: 385.16, episodes: 1473, reward function loss: 0.0000\n",
      "525908: reward: 500.00, mean_100: 385.16, episodes: 1474, reward function loss: 0.0000\n",
      "526408: reward: 500.00, mean_100: 386.98, episodes: 1475, reward function loss: 0.0000\n",
      "526908: reward: 500.00, mean_100: 388.83, episodes: 1476, reward function loss: 0.0000\n",
      "527408: reward: 500.00, mean_100: 389.77, episodes: 1477, reward function loss: 0.0000\n",
      "527908: reward: 500.00, mean_100: 393.77, episodes: 1478, reward function loss: 0.0000\n",
      "528408: reward: 500.00, mean_100: 397.72, episodes: 1479, reward function loss: 0.0000\n",
      "528908: reward: 500.00, mean_100: 399.97, episodes: 1480, reward function loss: 0.0000\n",
      "529408: reward: 500.00, mean_100: 402.50, episodes: 1481, reward function loss: 0.0000\n",
      "529908: reward: 500.00, mean_100: 402.50, episodes: 1482, reward function loss: 0.0000\n",
      "530408: reward: 500.00, mean_100: 404.85, episodes: 1483, reward function loss: 0.0000\n",
      "530908: reward: 500.00, mean_100: 405.78, episodes: 1484, reward function loss: 0.0000\n",
      "531408: reward: 500.00, mean_100: 409.05, episodes: 1485, reward function loss: 0.0000\n",
      "531908: reward: 500.00, mean_100: 411.48, episodes: 1486, reward function loss: 0.0000\n",
      "532408: reward: 500.00, mean_100: 411.48, episodes: 1487, reward function loss: 0.0000\n",
      "532908: reward: 500.00, mean_100: 411.48, episodes: 1488, reward function loss: 0.0000\n",
      "533155: reward: 247.00, mean_100: 412.98, episodes: 1489, reward function loss: 0.0000\n",
      "533655: reward: 500.00, mean_100: 412.98, episodes: 1490, reward function loss: 0.0000\n",
      "534155: reward: 500.00, mean_100: 415.55, episodes: 1491, reward function loss: 0.0000\n",
      "534655: reward: 500.00, mean_100: 416.16, episodes: 1492, reward function loss: 0.0000\n",
      "535155: reward: 500.00, mean_100: 416.16, episodes: 1493, reward function loss: 0.0000\n",
      "535655: reward: 500.00, mean_100: 417.04, episodes: 1494, reward function loss: 0.0000\n",
      "536155: reward: 500.00, mean_100: 419.71, episodes: 1495, reward function loss: 0.0000\n",
      "536655: reward: 500.00, mean_100: 422.51, episodes: 1496, reward function loss: 0.0000\n",
      "537155: reward: 500.00, mean_100: 426.07, episodes: 1497, reward function loss: 0.0000\n",
      "537655: reward: 500.00, mean_100: 429.27, episodes: 1498, reward function loss: 0.0000\n",
      "538155: reward: 500.00, mean_100: 431.60, episodes: 1499, reward function loss: 0.0000\n",
      "538655: reward: 500.00, mean_100: 431.60, episodes: 1500, reward function loss: 0.0000\n",
      "539155: reward: 500.00, mean_100: 433.94, episodes: 1501, reward function loss: 0.0000\n",
      "539655: reward: 500.00, mean_100: 436.24, episodes: 1502, reward function loss: 0.0000\n",
      "540155: reward: 500.00, mean_100: 439.18, episodes: 1503, reward function loss: 0.0000\n",
      "540655: reward: 500.00, mean_100: 442.13, episodes: 1504, reward function loss: 0.0000\n",
      "541155: reward: 500.00, mean_100: 446.11, episodes: 1505, reward function loss: 0.0000\n",
      "541655: reward: 500.00, mean_100: 448.91, episodes: 1506, reward function loss: 0.0000\n",
      "542155: reward: 500.00, mean_100: 453.21, episodes: 1507, reward function loss: 0.0000\n",
      "542655: reward: 500.00, mean_100: 453.21, episodes: 1508, reward function loss: 0.0000\n",
      "543155: reward: 500.00, mean_100: 455.34, episodes: 1509, reward function loss: 0.0000\n",
      "543655: reward: 500.00, mean_100: 457.78, episodes: 1510, reward function loss: 0.0000\n",
      "544155: reward: 500.00, mean_100: 459.15, episodes: 1511, reward function loss: 0.0000\n",
      "544655: reward: 500.00, mean_100: 461.28, episodes: 1512, reward function loss: 0.0000\n",
      "545155: reward: 500.00, mean_100: 465.29, episodes: 1513, reward function loss: 0.0000\n",
      "545655: reward: 500.00, mean_100: 465.46, episodes: 1514, reward function loss: 0.0000\n",
      "546155: reward: 500.00, mean_100: 468.01, episodes: 1515, reward function loss: 0.0000\n",
      "546655: reward: 500.00, mean_100: 470.26, episodes: 1516, reward function loss: 0.0000\n",
      "547155: reward: 500.00, mean_100: 470.26, episodes: 1517, reward function loss: 0.0000\n",
      "547655: reward: 500.00, mean_100: 471.21, episodes: 1518, reward function loss: 0.0000\n",
      "548155: reward: 500.00, mean_100: 472.07, episodes: 1519, reward function loss: 0.0000\n",
      "548655: reward: 500.00, mean_100: 475.01, episodes: 1520, reward function loss: 0.0000\n",
      "549155: reward: 500.00, mean_100: 478.24, episodes: 1521, reward function loss: 0.0000\n",
      "549655: reward: 500.00, mean_100: 482.01, episodes: 1522, reward function loss: 0.0000\n",
      "550155: reward: 500.00, mean_100: 482.01, episodes: 1523, reward function loss: 0.0000\n",
      "550655: reward: 500.00, mean_100: 482.01, episodes: 1524, reward function loss: 0.0000\n",
      "551155: reward: 500.00, mean_100: 486.21, episodes: 1525, reward function loss: 0.0000\n",
      "551655: reward: 500.00, mean_100: 488.13, episodes: 1526, reward function loss: 0.0000\n",
      "552155: reward: 500.00, mean_100: 489.71, episodes: 1527, reward function loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552655: reward: 500.00, mean_100: 491.32, episodes: 1528, reward function loss: 0.0000\n",
      "553155: reward: 500.00, mean_100: 491.32, episodes: 1529, reward function loss: 0.0000\n",
      "553655: reward: 500.00, mean_100: 491.32, episodes: 1530, reward function loss: 0.0000\n",
      "554155: reward: 500.00, mean_100: 491.32, episodes: 1531, reward function loss: 0.0000\n",
      "554655: reward: 500.00, mean_100: 491.32, episodes: 1532, reward function loss: 0.0000\n",
      "555155: reward: 500.00, mean_100: 491.32, episodes: 1533, reward function loss: 0.0000\n",
      "555655: reward: 500.00, mean_100: 494.99, episodes: 1534, reward function loss: 0.0000\n",
      "556155: reward: 500.00, mean_100: 494.99, episodes: 1535, reward function loss: 0.0000\n",
      "556655: reward: 500.00, mean_100: 494.99, episodes: 1536, reward function loss: 0.0000\n",
      "557155: reward: 500.00, mean_100: 494.99, episodes: 1537, reward function loss: 0.0000\n",
      "557655: reward: 500.00, mean_100: 494.99, episodes: 1538, reward function loss: 0.0000\n",
      "558155: reward: 500.00, mean_100: 494.99, episodes: 1539, reward function loss: 0.0000\n",
      "558655: reward: 500.00, mean_100: 494.99, episodes: 1540, reward function loss: 0.0000\n",
      "559155: reward: 500.00, mean_100: 497.47, episodes: 1541, reward function loss: 0.0000\n",
      "559655: reward: 500.00, mean_100: 497.47, episodes: 1542, reward function loss: 0.0000\n",
      "560155: reward: 500.00, mean_100: 497.47, episodes: 1543, reward function loss: 0.0000\n",
      "560655: reward: 500.00, mean_100: 497.47, episodes: 1544, reward function loss: 0.0000\n",
      "561155: reward: 500.00, mean_100: 497.47, episodes: 1545, reward function loss: 0.0000\n",
      "561655: reward: 500.00, mean_100: 497.47, episodes: 1546, reward function loss: 0.0000\n",
      "562155: reward: 500.00, mean_100: 497.47, episodes: 1547, reward function loss: 0.0000\n",
      "562655: reward: 500.00, mean_100: 497.47, episodes: 1548, reward function loss: 0.0000\n",
      "563155: reward: 500.00, mean_100: 497.47, episodes: 1549, reward function loss: 0.0000\n",
      "563655: reward: 500.00, mean_100: 497.47, episodes: 1550, reward function loss: 0.0000\n",
      "564155: reward: 500.00, mean_100: 497.47, episodes: 1551, reward function loss: 0.0000\n",
      "564655: reward: 500.00, mean_100: 497.47, episodes: 1552, reward function loss: 0.0000\n",
      "565155: reward: 500.00, mean_100: 497.47, episodes: 1553, reward function loss: 0.0000\n",
      "565655: reward: 500.00, mean_100: 497.47, episodes: 1554, reward function loss: 0.0000\n",
      "566155: reward: 500.00, mean_100: 497.47, episodes: 1555, reward function loss: 0.0000\n",
      "566655: reward: 500.00, mean_100: 497.47, episodes: 1556, reward function loss: 0.0000\n",
      "567155: reward: 500.00, mean_100: 497.47, episodes: 1557, reward function loss: 0.0000\n",
      "567655: reward: 500.00, mean_100: 497.47, episodes: 1558, reward function loss: 0.0000\n",
      "568155: reward: 500.00, mean_100: 497.47, episodes: 1559, reward function loss: 0.0000\n",
      "568655: reward: 500.00, mean_100: 497.47, episodes: 1560, reward function loss: 0.0000\n",
      "569155: reward: 500.00, mean_100: 497.47, episodes: 1561, reward function loss: 0.0000\n",
      "569655: reward: 500.00, mean_100: 497.47, episodes: 1562, reward function loss: 0.0000\n",
      "570155: reward: 500.00, mean_100: 497.47, episodes: 1563, reward function loss: 0.0000\n",
      "570655: reward: 500.00, mean_100: 497.47, episodes: 1564, reward function loss: 0.0000\n",
      "571155: reward: 500.00, mean_100: 497.47, episodes: 1565, reward function loss: 0.0000\n",
      "571655: reward: 500.00, mean_100: 497.47, episodes: 1566, reward function loss: 0.0000\n",
      "572155: reward: 500.00, mean_100: 497.47, episodes: 1567, reward function loss: 0.0000\n",
      "572655: reward: 500.00, mean_100: 497.47, episodes: 1568, reward function loss: 0.0000\n",
      "573155: reward: 500.00, mean_100: 497.47, episodes: 1569, reward function loss: 0.0000\n",
      "573655: reward: 500.00, mean_100: 497.47, episodes: 1570, reward function loss: 0.0000\n",
      "574155: reward: 500.00, mean_100: 497.47, episodes: 1571, reward function loss: 0.0000\n",
      "574655: reward: 500.00, mean_100: 497.47, episodes: 1572, reward function loss: 0.0000\n",
      "575155: reward: 500.00, mean_100: 497.47, episodes: 1573, reward function loss: 0.0000\n",
      "575655: reward: 500.00, mean_100: 497.47, episodes: 1574, reward function loss: 0.0000\n",
      "576155: reward: 500.00, mean_100: 497.47, episodes: 1575, reward function loss: 0.0000\n",
      "576655: reward: 500.00, mean_100: 497.47, episodes: 1576, reward function loss: 0.0000\n",
      "577155: reward: 500.00, mean_100: 497.47, episodes: 1577, reward function loss: 0.0000\n",
      "577655: reward: 500.00, mean_100: 497.47, episodes: 1578, reward function loss: 0.0000\n",
      "578155: reward: 500.00, mean_100: 497.47, episodes: 1579, reward function loss: 0.0000\n",
      "578655: reward: 500.00, mean_100: 497.47, episodes: 1580, reward function loss: 0.0000\n",
      "579155: reward: 500.00, mean_100: 497.47, episodes: 1581, reward function loss: 0.0000\n",
      "579655: reward: 500.00, mean_100: 497.47, episodes: 1582, reward function loss: 0.0000\n",
      "580011: reward: 356.00, mean_100: 496.03, episodes: 1583, reward function loss: 0.0000\n",
      "580511: reward: 500.00, mean_100: 496.03, episodes: 1584, reward function loss: 0.0000\n",
      "580801: reward: 290.00, mean_100: 493.93, episodes: 1585, reward function loss: 0.0000\n",
      "581301: reward: 500.00, mean_100: 493.93, episodes: 1586, reward function loss: 0.0000\n",
      "581801: reward: 500.00, mean_100: 493.93, episodes: 1587, reward function loss: 0.0000\n",
      "582301: reward: 500.00, mean_100: 493.93, episodes: 1588, reward function loss: 0.0000\n",
      "582801: reward: 500.00, mean_100: 496.46, episodes: 1589, reward function loss: 0.0000\n",
      "583301: reward: 500.00, mean_100: 496.46, episodes: 1590, reward function loss: 0.0000\n",
      "583801: reward: 500.00, mean_100: 496.46, episodes: 1591, reward function loss: 0.0000\n",
      "584301: reward: 500.00, mean_100: 496.46, episodes: 1592, reward function loss: 0.0000\n",
      "584599: reward: 298.00, mean_100: 494.44, episodes: 1593, reward function loss: 0.0000\n",
      "585099: reward: 500.00, mean_100: 494.44, episodes: 1594, reward function loss: 0.0000\n",
      "585590: reward: 491.00, mean_100: 494.35, episodes: 1595, reward function loss: 0.0000\n",
      "586090: reward: 500.00, mean_100: 494.35, episodes: 1596, reward function loss: 0.0000\n",
      "586590: reward: 500.00, mean_100: 494.35, episodes: 1597, reward function loss: 0.0000\n",
      "587090: reward: 500.00, mean_100: 494.35, episodes: 1598, reward function loss: 0.0000\n",
      "587590: reward: 500.00, mean_100: 494.35, episodes: 1599, reward function loss: 0.0000\n",
      "588090: reward: 500.00, mean_100: 494.35, episodes: 1600, reward function loss: 0.0000\n",
      "588590: reward: 500.00, mean_100: 494.35, episodes: 1601, reward function loss: 0.0000\n",
      "589090: reward: 500.00, mean_100: 494.35, episodes: 1602, reward function loss: 0.0000\n",
      "589493: reward: 403.00, mean_100: 493.38, episodes: 1603, reward function loss: 0.0000\n",
      "589993: reward: 500.00, mean_100: 493.38, episodes: 1604, reward function loss: 0.0000\n",
      "590493: reward: 500.00, mean_100: 493.38, episodes: 1605, reward function loss: 0.0000\n",
      "590993: reward: 500.00, mean_100: 493.38, episodes: 1606, reward function loss: 0.0000\n",
      "591493: reward: 500.00, mean_100: 493.38, episodes: 1607, reward function loss: 0.0000\n",
      "591993: reward: 500.00, mean_100: 493.38, episodes: 1608, reward function loss: 0.0000\n",
      "592369: reward: 376.00, mean_100: 492.14, episodes: 1609, reward function loss: 0.0000\n",
      "592869: reward: 500.00, mean_100: 492.14, episodes: 1610, reward function loss: 0.0000\n",
      "593369: reward: 500.00, mean_100: 492.14, episodes: 1611, reward function loss: 0.0000\n",
      "593869: reward: 500.00, mean_100: 492.14, episodes: 1612, reward function loss: 0.0000\n",
      "594369: reward: 500.00, mean_100: 492.14, episodes: 1613, reward function loss: 0.0000\n",
      "594603: reward: 234.00, mean_100: 489.48, episodes: 1614, reward function loss: 0.0000\n",
      "594972: reward: 369.00, mean_100: 488.17, episodes: 1615, reward function loss: 0.0000\n",
      "595472: reward: 500.00, mean_100: 488.17, episodes: 1616, reward function loss: 0.0000\n",
      "595972: reward: 500.00, mean_100: 488.17, episodes: 1617, reward function loss: 0.0000\n",
      "596472: reward: 500.00, mean_100: 488.17, episodes: 1618, reward function loss: 0.0000\n",
      "596972: reward: 500.00, mean_100: 488.17, episodes: 1619, reward function loss: 0.0000\n",
      "597472: reward: 500.00, mean_100: 488.17, episodes: 1620, reward function loss: 0.0000\n",
      "597972: reward: 500.00, mean_100: 488.17, episodes: 1621, reward function loss: 0.0000\n",
      "598373: reward: 401.00, mean_100: 487.18, episodes: 1622, reward function loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598873: reward: 500.00, mean_100: 487.18, episodes: 1623, reward function loss: 0.0000\n",
      "599244: reward: 371.00, mean_100: 485.89, episodes: 1624, reward function loss: -0.0000\n",
      "599744: reward: 500.00, mean_100: 485.89, episodes: 1625, reward function loss: -0.0000\n",
      "600244: reward: 500.00, mean_100: 485.89, episodes: 1626, reward function loss: -0.0000\n",
      "600744: reward: 500.00, mean_100: 485.89, episodes: 1627, reward function loss: -0.0000\n",
      "601244: reward: 500.00, mean_100: 485.89, episodes: 1628, reward function loss: 0.0000\n",
      "601681: reward: 437.00, mean_100: 485.26, episodes: 1629, reward function loss: 0.0000\n",
      "602055: reward: 374.00, mean_100: 484.00, episodes: 1630, reward function loss: 0.0000\n",
      "602555: reward: 500.00, mean_100: 484.00, episodes: 1631, reward function loss: 0.0000\n",
      "603055: reward: 500.00, mean_100: 484.00, episodes: 1632, reward function loss: -0.0000\n",
      "603555: reward: 500.00, mean_100: 484.00, episodes: 1633, reward function loss: -0.0000\n",
      "604055: reward: 500.00, mean_100: 484.00, episodes: 1634, reward function loss: -0.0000\n",
      "604555: reward: 500.00, mean_100: 484.00, episodes: 1635, reward function loss: -0.0000\n",
      "605055: reward: 500.00, mean_100: 484.00, episodes: 1636, reward function loss: -0.0000\n",
      "605379: reward: 324.00, mean_100: 482.24, episodes: 1637, reward function loss: -0.0000\n",
      "605879: reward: 500.00, mean_100: 482.24, episodes: 1638, reward function loss: -0.0000\n",
      "606379: reward: 500.00, mean_100: 482.24, episodes: 1639, reward function loss: -0.0000\n",
      "606879: reward: 500.00, mean_100: 482.24, episodes: 1640, reward function loss: -0.0000\n",
      "607379: reward: 500.00, mean_100: 482.24, episodes: 1641, reward function loss: -0.0000\n",
      "607857: reward: 478.00, mean_100: 482.02, episodes: 1642, reward function loss: -0.0000\n",
      "608357: reward: 500.00, mean_100: 482.02, episodes: 1643, reward function loss: -0.0000\n",
      "608851: reward: 494.00, mean_100: 481.96, episodes: 1644, reward function loss: -0.0001\n",
      "609351: reward: 500.00, mean_100: 481.96, episodes: 1645, reward function loss: -0.0001\n",
      "609703: reward: 352.00, mean_100: 480.48, episodes: 1646, reward function loss: -0.0001\n",
      "610203: reward: 500.00, mean_100: 480.48, episodes: 1647, reward function loss: -0.0001\n",
      "610673: reward: 470.00, mean_100: 480.18, episodes: 1648, reward function loss: -0.0008\n",
      "611173: reward: 500.00, mean_100: 480.18, episodes: 1649, reward function loss: -0.0008\n",
      "611673: reward: 500.00, mean_100: 480.18, episodes: 1650, reward function loss: -0.0008\n",
      "612161: reward: 488.00, mean_100: 480.06, episodes: 1651, reward function loss: -0.0008\n",
      "612661: reward: 500.00, mean_100: 480.06, episodes: 1652, reward function loss: -0.0294\n",
      "613161: reward: 500.00, mean_100: 480.06, episodes: 1653, reward function loss: -0.0294\n",
      "613576: reward: 415.00, mean_100: 479.21, episodes: 1654, reward function loss: -0.0294\n",
      "614002: reward: 426.00, mean_100: 478.47, episodes: 1655, reward function loss: -0.0294\n",
      "614502: reward: 500.00, mean_100: 478.47, episodes: 1656, reward function loss: -0.0311\n",
      "614805: reward: 303.00, mean_100: 476.50, episodes: 1657, reward function loss: -0.0311\n",
      "615230: reward: 425.00, mean_100: 475.75, episodes: 1658, reward function loss: -0.0311\n",
      "615730: reward: 500.00, mean_100: 475.75, episodes: 1659, reward function loss: -0.0311\n",
      "616230: reward: 500.00, mean_100: 475.75, episodes: 1660, reward function loss: -0.0394\n",
      "616730: reward: 500.00, mean_100: 475.75, episodes: 1661, reward function loss: -0.0394\n",
      "617206: reward: 476.00, mean_100: 475.51, episodes: 1662, reward function loss: -0.0394\n",
      "617694: reward: 488.00, mean_100: 475.39, episodes: 1663, reward function loss: -0.0394\n",
      "618194: reward: 500.00, mean_100: 475.39, episodes: 1664, reward function loss: -0.0459\n",
      "618565: reward: 371.00, mean_100: 474.10, episodes: 1665, reward function loss: -0.0459\n",
      "618925: reward: 360.00, mean_100: 472.70, episodes: 1666, reward function loss: -0.0459\n",
      "619343: reward: 418.00, mean_100: 471.88, episodes: 1667, reward function loss: -0.0459\n",
      "619827: reward: 484.00, mean_100: 471.72, episodes: 1668, reward function loss: -0.0374\n",
      "620255: reward: 428.00, mean_100: 471.00, episodes: 1669, reward function loss: -0.0374\n",
      "620616: reward: 361.00, mean_100: 469.61, episodes: 1670, reward function loss: -0.0374\n",
      "620985: reward: 369.00, mean_100: 468.30, episodes: 1671, reward function loss: -0.0374\n",
      "621411: reward: 426.00, mean_100: 467.56, episodes: 1672, reward function loss: -0.0376\n",
      "621709: reward: 298.00, mean_100: 465.54, episodes: 1673, reward function loss: -0.0376\n",
      "622209: reward: 500.00, mean_100: 465.54, episodes: 1674, reward function loss: -0.0376\n",
      "622486: reward: 277.00, mean_100: 463.31, episodes: 1675, reward function loss: -0.0376\n",
      "622986: reward: 500.00, mean_100: 463.31, episodes: 1676, reward function loss: -0.0381\n",
      "623477: reward: 491.00, mean_100: 463.22, episodes: 1677, reward function loss: -0.0381\n",
      "623977: reward: 500.00, mean_100: 463.22, episodes: 1678, reward function loss: -0.0381\n",
      "624336: reward: 359.00, mean_100: 461.81, episodes: 1679, reward function loss: -0.0381\n",
      "624836: reward: 500.00, mean_100: 461.81, episodes: 1680, reward function loss: -0.0433\n",
      "625336: reward: 500.00, mean_100: 461.81, episodes: 1681, reward function loss: -0.0433\n",
      "625699: reward: 363.00, mean_100: 460.44, episodes: 1682, reward function loss: -0.0433\n",
      "626127: reward: 428.00, mean_100: 461.16, episodes: 1683, reward function loss: -0.0433\n",
      "626419: reward: 292.00, mean_100: 459.08, episodes: 1684, reward function loss: -0.0379\n",
      "626652: reward: 233.00, mean_100: 458.51, episodes: 1685, reward function loss: -0.0379\n",
      "626998: reward: 346.00, mean_100: 456.97, episodes: 1686, reward function loss: -0.0379\n",
      "627230: reward: 232.00, mean_100: 454.29, episodes: 1687, reward function loss: -0.0379\n",
      "627531: reward: 301.00, mean_100: 452.30, episodes: 1688, reward function loss: -0.0270\n",
      "628031: reward: 500.00, mean_100: 452.30, episodes: 1689, reward function loss: -0.0270\n",
      "628531: reward: 500.00, mean_100: 452.30, episodes: 1690, reward function loss: -0.0270\n",
      "629031: reward: 500.00, mean_100: 452.30, episodes: 1691, reward function loss: -0.0270\n",
      "629519: reward: 488.00, mean_100: 452.18, episodes: 1692, reward function loss: -0.0476\n",
      "629886: reward: 367.00, mean_100: 452.87, episodes: 1693, reward function loss: -0.0476\n",
      "630245: reward: 359.00, mean_100: 451.46, episodes: 1694, reward function loss: -0.0476\n",
      "630745: reward: 500.00, mean_100: 451.55, episodes: 1695, reward function loss: -0.0476\n",
      "631184: reward: 439.00, mean_100: 450.94, episodes: 1696, reward function loss: -0.0402\n",
      "631478: reward: 294.00, mean_100: 448.88, episodes: 1697, reward function loss: -0.0402\n",
      "631835: reward: 357.00, mean_100: 447.45, episodes: 1698, reward function loss: -0.0402\n",
      "632196: reward: 361.00, mean_100: 446.06, episodes: 1699, reward function loss: -0.0402\n",
      "632696: reward: 500.00, mean_100: 446.06, episodes: 1700, reward function loss: -0.0363\n",
      "633193: reward: 497.00, mean_100: 446.03, episodes: 1701, reward function loss: -0.0363\n",
      "633420: reward: 227.00, mean_100: 443.30, episodes: 1702, reward function loss: -0.0363\n",
      "633787: reward: 367.00, mean_100: 442.94, episodes: 1703, reward function loss: -0.0363\n",
      "634281: reward: 494.00, mean_100: 442.88, episodes: 1704, reward function loss: -0.0381\n",
      "634650: reward: 369.00, mean_100: 441.57, episodes: 1705, reward function loss: -0.0381\n",
      "634946: reward: 296.00, mean_100: 439.53, episodes: 1706, reward function loss: -0.0381\n",
      "635316: reward: 370.00, mean_100: 438.23, episodes: 1707, reward function loss: -0.0381\n",
      "635666: reward: 350.00, mean_100: 436.73, episodes: 1708, reward function loss: -0.0330\n",
      "636166: reward: 500.00, mean_100: 437.97, episodes: 1709, reward function loss: -0.0330\n",
      "636666: reward: 500.00, mean_100: 437.97, episodes: 1710, reward function loss: -0.0330\n",
      "637166: reward: 500.00, mean_100: 437.97, episodes: 1711, reward function loss: -0.0330\n",
      "637662: reward: 496.00, mean_100: 437.93, episodes: 1712, reward function loss: -0.0473\n",
      "638035: reward: 373.00, mean_100: 436.66, episodes: 1713, reward function loss: -0.0473\n",
      "638525: reward: 490.00, mean_100: 439.22, episodes: 1714, reward function loss: -0.0473\n",
      "638969: reward: 444.00, mean_100: 439.97, episodes: 1715, reward function loss: -0.0473\n",
      "639317: reward: 348.00, mean_100: 438.45, episodes: 1716, reward function loss: -0.0394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639817: reward: 500.00, mean_100: 438.45, episodes: 1717, reward function loss: -0.0394\n",
      "640196: reward: 379.00, mean_100: 437.24, episodes: 1718, reward function loss: -0.0394\n",
      "640496: reward: 300.00, mean_100: 435.24, episodes: 1719, reward function loss: -0.0394\n",
      "640996: reward: 500.00, mean_100: 435.24, episodes: 1720, reward function loss: -0.0405\n",
      "641293: reward: 297.00, mean_100: 433.21, episodes: 1721, reward function loss: -0.0405\n",
      "641793: reward: 500.00, mean_100: 434.20, episodes: 1722, reward function loss: -0.0405\n",
      "642156: reward: 363.00, mean_100: 432.83, episodes: 1723, reward function loss: -0.0405\n",
      "642584: reward: 428.00, mean_100: 433.40, episodes: 1724, reward function loss: -0.0384\n",
      "643079: reward: 495.00, mean_100: 433.35, episodes: 1725, reward function loss: -0.0384\n",
      "643308: reward: 229.00, mean_100: 430.64, episodes: 1726, reward function loss: -0.0384\n",
      "643808: reward: 500.00, mean_100: 430.64, episodes: 1727, reward function loss: -0.0384\n",
      "644301: reward: 493.00, mean_100: 430.57, episodes: 1728, reward function loss: -0.0409\n",
      "644801: reward: 500.00, mean_100: 431.20, episodes: 1729, reward function loss: -0.0409\n",
      "645251: reward: 450.00, mean_100: 431.96, episodes: 1730, reward function loss: -0.0409\n",
      "645741: reward: 490.00, mean_100: 431.86, episodes: 1731, reward function loss: -0.0409\n",
      "646172: reward: 431.00, mean_100: 431.17, episodes: 1732, reward function loss: -0.0444\n",
      "646540: reward: 368.00, mean_100: 429.85, episodes: 1733, reward function loss: -0.0444\n",
      "646782: reward: 242.00, mean_100: 427.27, episodes: 1734, reward function loss: -0.0444\n",
      "647078: reward: 296.00, mean_100: 425.23, episodes: 1735, reward function loss: -0.0444\n",
      "647578: reward: 500.00, mean_100: 425.23, episodes: 1736, reward function loss: -0.0340\n",
      "648078: reward: 500.00, mean_100: 426.99, episodes: 1737, reward function loss: -0.0340\n",
      "648290: reward: 212.00, mean_100: 424.11, episodes: 1738, reward function loss: -0.0340\n",
      "648790: reward: 500.00, mean_100: 424.11, episodes: 1739, reward function loss: -0.0340\n",
      "649091: reward: 301.00, mean_100: 422.12, episodes: 1740, reward function loss: -0.0362\n",
      "649316: reward: 225.00, mean_100: 419.37, episodes: 1741, reward function loss: -0.0362\n",
      "649626: reward: 310.00, mean_100: 417.69, episodes: 1742, reward function loss: -0.0362\n",
      "650126: reward: 500.00, mean_100: 417.69, episodes: 1743, reward function loss: -0.0362\n",
      "650626: reward: 500.00, mean_100: 417.75, episodes: 1744, reward function loss: -0.0369\n",
      "650795: reward: 169.00, mean_100: 414.44, episodes: 1745, reward function loss: -0.0369\n",
      "651096: reward: 301.00, mean_100: 413.93, episodes: 1746, reward function loss: -0.0369\n",
      "651323: reward: 227.00, mean_100: 411.20, episodes: 1747, reward function loss: -0.0369\n",
      "651617: reward: 294.00, mean_100: 409.44, episodes: 1748, reward function loss: -0.0243\n",
      "651915: reward: 298.00, mean_100: 407.42, episodes: 1749, reward function loss: -0.0243\n",
      "652353: reward: 438.00, mean_100: 406.80, episodes: 1750, reward function loss: -0.0243\n",
      "652719: reward: 366.00, mean_100: 405.58, episodes: 1751, reward function loss: -0.0243\n",
      "653099: reward: 380.00, mean_100: 404.38, episodes: 1752, reward function loss: -0.0356\n",
      "653463: reward: 364.00, mean_100: 403.02, episodes: 1753, reward function loss: -0.0356\n",
      "653841: reward: 378.00, mean_100: 402.65, episodes: 1754, reward function loss: -0.0356\n",
      "654278: reward: 437.00, mean_100: 402.76, episodes: 1755, reward function loss: -0.0356\n",
      "654573: reward: 295.00, mean_100: 400.71, episodes: 1756, reward function loss: -0.0350\n",
      "654949: reward: 376.00, mean_100: 401.44, episodes: 1757, reward function loss: -0.0350\n",
      "655449: reward: 500.00, mean_100: 402.19, episodes: 1758, reward function loss: -0.0350\n",
      "655754: reward: 305.00, mean_100: 400.24, episodes: 1759, reward function loss: -0.0350\n",
      "656061: reward: 307.00, mean_100: 398.31, episodes: 1760, reward function loss: -0.0361\n",
      "656302: reward: 241.00, mean_100: 395.72, episodes: 1761, reward function loss: -0.0361\n",
      "656613: reward: 311.00, mean_100: 394.07, episodes: 1762, reward function loss: -0.0361\n",
      "656828: reward: 215.00, mean_100: 391.34, episodes: 1763, reward function loss: -0.0361\n",
      "657197: reward: 369.00, mean_100: 390.03, episodes: 1764, reward function loss: -0.0270\n",
      "657573: reward: 376.00, mean_100: 390.08, episodes: 1765, reward function loss: -0.0270\n",
      "658019: reward: 446.00, mean_100: 390.94, episodes: 1766, reward function loss: -0.0270\n",
      "658453: reward: 434.00, mean_100: 391.10, episodes: 1767, reward function loss: -0.0270\n",
      "658913: reward: 460.00, mean_100: 390.86, episodes: 1768, reward function loss: -0.0411\n",
      "659291: reward: 378.00, mean_100: 390.36, episodes: 1769, reward function loss: -0.0411\n",
      "659649: reward: 358.00, mean_100: 390.33, episodes: 1770, reward function loss: -0.0411\n",
      "660149: reward: 500.00, mean_100: 391.64, episodes: 1771, reward function loss: -0.0411\n",
      "660596: reward: 447.00, mean_100: 391.85, episodes: 1772, reward function loss: -0.0405\n",
      "661096: reward: 500.00, mean_100: 393.87, episodes: 1773, reward function loss: -0.0405\n",
      "661596: reward: 500.00, mean_100: 393.87, episodes: 1774, reward function loss: -0.0405\n",
      "662058: reward: 462.00, mean_100: 395.72, episodes: 1775, reward function loss: -0.0405\n",
      "662364: reward: 306.00, mean_100: 393.78, episodes: 1776, reward function loss: -0.0424\n",
      "662586: reward: 222.00, mean_100: 391.09, episodes: 1777, reward function loss: -0.0424\n",
      "662949: reward: 363.00, mean_100: 389.72, episodes: 1778, reward function loss: -0.0424\n",
      "663321: reward: 372.00, mean_100: 389.85, episodes: 1779, reward function loss: -0.0424\n",
      "663749: reward: 428.00, mean_100: 389.13, episodes: 1780, reward function loss: -0.0336\n",
      "664132: reward: 383.00, mean_100: 387.96, episodes: 1781, reward function loss: -0.0336\n",
      "664632: reward: 500.00, mean_100: 389.33, episodes: 1782, reward function loss: -0.0336\n",
      "665061: reward: 429.00, mean_100: 389.34, episodes: 1783, reward function loss: -0.0336\n",
      "665511: reward: 450.00, mean_100: 390.92, episodes: 1784, reward function loss: -0.0424\n",
      "665975: reward: 464.00, mean_100: 393.23, episodes: 1785, reward function loss: -0.0424\n",
      "666345: reward: 370.00, mean_100: 393.47, episodes: 1786, reward function loss: -0.0424\n",
      "666845: reward: 500.00, mean_100: 396.15, episodes: 1787, reward function loss: -0.0424\n",
      "667291: reward: 446.00, mean_100: 397.60, episodes: 1788, reward function loss: -0.0428\n",
      "667728: reward: 437.00, mean_100: 396.97, episodes: 1789, reward function loss: -0.0428\n",
      "668166: reward: 438.00, mean_100: 396.35, episodes: 1790, reward function loss: -0.0428\n",
      "668534: reward: 368.00, mean_100: 395.03, episodes: 1791, reward function loss: -0.0428\n",
      "668975: reward: 441.00, mean_100: 394.56, episodes: 1792, reward function loss: -0.0403\n",
      "669287: reward: 312.00, mean_100: 394.01, episodes: 1793, reward function loss: -0.0403\n",
      "669591: reward: 304.00, mean_100: 393.46, episodes: 1794, reward function loss: -0.0403\n",
      "669899: reward: 308.00, mean_100: 391.54, episodes: 1795, reward function loss: -0.0403\n",
      "670399: reward: 500.00, mean_100: 392.15, episodes: 1796, reward function loss: -0.0341\n",
      "670760: reward: 361.00, mean_100: 392.82, episodes: 1797, reward function loss: -0.0341\n",
      "671260: reward: 500.00, mean_100: 394.25, episodes: 1798, reward function loss: -0.0341\n",
      "671549: reward: 289.00, mean_100: 393.53, episodes: 1799, reward function loss: -0.0341\n",
      "671861: reward: 312.00, mean_100: 391.65, episodes: 1800, reward function loss: -0.0352\n",
      "672361: reward: 500.00, mean_100: 391.68, episodes: 1801, reward function loss: -0.0352\n",
      "672861: reward: 500.00, mean_100: 394.41, episodes: 1802, reward function loss: -0.0352\n",
      "673215: reward: 354.00, mean_100: 394.28, episodes: 1803, reward function loss: -0.0352\n",
      "673715: reward: 500.00, mean_100: 394.34, episodes: 1804, reward function loss: -0.0446\n",
      "674092: reward: 377.00, mean_100: 394.42, episodes: 1805, reward function loss: -0.0446\n",
      "674333: reward: 241.00, mean_100: 393.87, episodes: 1806, reward function loss: -0.0446\n",
      "674694: reward: 361.00, mean_100: 393.78, episodes: 1807, reward function loss: -0.0446\n",
      "675000: reward: 306.00, mean_100: 393.34, episodes: 1808, reward function loss: -0.0298\n",
      "675306: reward: 306.00, mean_100: 391.40, episodes: 1809, reward function loss: -0.0298\n",
      "675769: reward: 463.00, mean_100: 391.03, episodes: 1810, reward function loss: -0.0298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676143: reward: 374.00, mean_100: 389.77, episodes: 1811, reward function loss: -0.0298\n",
      "676529: reward: 386.00, mean_100: 388.67, episodes: 1812, reward function loss: -0.0360\n",
      "676823: reward: 294.00, mean_100: 387.88, episodes: 1813, reward function loss: -0.0360\n",
      "677323: reward: 500.00, mean_100: 387.98, episodes: 1814, reward function loss: -0.0360\n",
      "677819: reward: 496.00, mean_100: 388.50, episodes: 1815, reward function loss: -0.0360\n",
      "678134: reward: 315.00, mean_100: 388.17, episodes: 1816, reward function loss: -0.0387\n",
      "678508: reward: 374.00, mean_100: 386.91, episodes: 1817, reward function loss: -0.0387\n",
      "679008: reward: 500.00, mean_100: 388.12, episodes: 1818, reward function loss: -0.0387\n",
      "679502: reward: 494.00, mean_100: 390.06, episodes: 1819, reward function loss: -0.0387\n",
      "679809: reward: 307.00, mean_100: 388.13, episodes: 1820, reward function loss: -0.0400\n",
      "680129: reward: 320.00, mean_100: 388.36, episodes: 1821, reward function loss: -0.0400\n",
      "680499: reward: 370.00, mean_100: 387.06, episodes: 1822, reward function loss: -0.0400\n",
      "680864: reward: 365.00, mean_100: 387.08, episodes: 1823, reward function loss: -0.0400\n",
      "681364: reward: 500.00, mean_100: 387.80, episodes: 1824, reward function loss: -0.0371\n",
      "681864: reward: 500.00, mean_100: 387.85, episodes: 1825, reward function loss: -0.0371\n",
      "682364: reward: 500.00, mean_100: 390.56, episodes: 1826, reward function loss: -0.0371\n",
      "682864: reward: 500.00, mean_100: 390.56, episodes: 1827, reward function loss: -0.0371\n",
      "683156: reward: 292.00, mean_100: 388.55, episodes: 1828, reward function loss: -0.0431\n",
      "683586: reward: 430.00, mean_100: 387.85, episodes: 1829, reward function loss: -0.0431\n",
      "684086: reward: 500.00, mean_100: 388.35, episodes: 1830, reward function loss: -0.0431\n",
      "684457: reward: 371.00, mean_100: 387.16, episodes: 1831, reward function loss: -0.0431\n",
      "684832: reward: 375.00, mean_100: 386.60, episodes: 1832, reward function loss: -0.0403\n",
      "685332: reward: 500.00, mean_100: 387.92, episodes: 1833, reward function loss: -0.0403\n",
      "685564: reward: 232.00, mean_100: 387.82, episodes: 1834, reward function loss: -0.0403\n",
      "685920: reward: 356.00, mean_100: 388.42, episodes: 1835, reward function loss: -0.0403\n",
      "686420: reward: 500.00, mean_100: 388.42, episodes: 1836, reward function loss: -0.0378\n",
      "686804: reward: 384.00, mean_100: 387.26, episodes: 1837, reward function loss: -0.0378\n",
      "687037: reward: 233.00, mean_100: 387.47, episodes: 1838, reward function loss: -0.0378\n",
      "687537: reward: 500.00, mean_100: 387.47, episodes: 1839, reward function loss: -0.0378\n",
      "687834: reward: 297.00, mean_100: 387.43, episodes: 1840, reward function loss: -0.0343\n",
      "688196: reward: 362.00, mean_100: 388.80, episodes: 1841, reward function loss: -0.0343\n",
      "688439: reward: 243.00, mean_100: 388.13, episodes: 1842, reward function loss: -0.0343\n",
      "688693: reward: 254.00, mean_100: 385.67, episodes: 1843, reward function loss: -0.0343\n",
      "689193: reward: 500.00, mean_100: 385.67, episodes: 1844, reward function loss: -0.0327\n",
      "689426: reward: 233.00, mean_100: 386.31, episodes: 1845, reward function loss: -0.0327\n",
      "689802: reward: 376.00, mean_100: 387.06, episodes: 1846, reward function loss: -0.0327\n",
      "690168: reward: 366.00, mean_100: 388.45, episodes: 1847, reward function loss: -0.0327\n",
      "690605: reward: 437.00, mean_100: 389.88, episodes: 1848, reward function loss: -0.0342\n",
      "690974: reward: 369.00, mean_100: 390.59, episodes: 1849, reward function loss: -0.0342\n",
      "691351: reward: 377.00, mean_100: 389.98, episodes: 1850, reward function loss: -0.0342\n",
      "691782: reward: 431.00, mean_100: 390.63, episodes: 1851, reward function loss: -0.0342\n",
      "692282: reward: 500.00, mean_100: 391.83, episodes: 1852, reward function loss: -0.0404\n",
      "692513: reward: 231.00, mean_100: 390.50, episodes: 1853, reward function loss: -0.0404\n",
      "692961: reward: 448.00, mean_100: 391.20, episodes: 1854, reward function loss: -0.0404\n",
      "693461: reward: 500.00, mean_100: 391.83, episodes: 1855, reward function loss: -0.0404\n",
      "693961: reward: 500.00, mean_100: 393.88, episodes: 1856, reward function loss: -0.0402\n",
      "694331: reward: 370.00, mean_100: 393.82, episodes: 1857, reward function loss: -0.0402\n",
      "694769: reward: 438.00, mean_100: 393.20, episodes: 1858, reward function loss: -0.0402\n",
      "695269: reward: 500.00, mean_100: 395.15, episodes: 1859, reward function loss: -0.0402\n",
      "695511: reward: 242.00, mean_100: 394.50, episodes: 1860, reward function loss: -0.0374\n",
      "696011: reward: 500.00, mean_100: 397.09, episodes: 1861, reward function loss: -0.0374\n",
      "696174: reward: 163.00, mean_100: 395.61, episodes: 1862, reward function loss: -0.0374\n",
      "696490: reward: 316.00, mean_100: 396.62, episodes: 1863, reward function loss: -0.0374\n",
      "696848: reward: 358.00, mean_100: 396.51, episodes: 1864, reward function loss: -0.0321\n",
      "697154: reward: 306.00, mean_100: 395.81, episodes: 1865, reward function loss: -0.0321\n",
      "697466: reward: 312.00, mean_100: 394.47, episodes: 1866, reward function loss: -0.0321\n",
      "697775: reward: 309.00, mean_100: 393.22, episodes: 1867, reward function loss: -0.0321\n",
      "698237: reward: 462.00, mean_100: 393.24, episodes: 1868, reward function loss: -0.0334\n",
      "698525: reward: 288.00, mean_100: 392.34, episodes: 1869, reward function loss: -0.0334\n",
      "698853: reward: 328.00, mean_100: 392.04, episodes: 1870, reward function loss: -0.0334\n",
      "699298: reward: 445.00, mean_100: 391.49, episodes: 1871, reward function loss: -0.0334\n",
      "699730: reward: 432.00, mean_100: 391.34, episodes: 1872, reward function loss: -0.0360\n",
      "700168: reward: 438.00, mean_100: 390.72, episodes: 1873, reward function loss: -0.0360\n",
      "700668: reward: 500.00, mean_100: 390.72, episodes: 1874, reward function loss: -0.0360\n",
      "700960: reward: 292.00, mean_100: 389.02, episodes: 1875, reward function loss: -0.0360\n",
      "701460: reward: 500.00, mean_100: 390.96, episodes: 1876, reward function loss: -0.0416\n",
      "701764: reward: 304.00, mean_100: 391.78, episodes: 1877, reward function loss: -0.0416\n",
      "702264: reward: 500.00, mean_100: 393.15, episodes: 1878, reward function loss: -0.0416\n",
      "702764: reward: 500.00, mean_100: 394.43, episodes: 1879, reward function loss: -0.0416\n",
      "703128: reward: 364.00, mean_100: 393.79, episodes: 1880, reward function loss: -0.0402\n",
      "703443: reward: 315.00, mean_100: 393.11, episodes: 1881, reward function loss: -0.0402\n",
      "703814: reward: 371.00, mean_100: 391.82, episodes: 1882, reward function loss: -0.0402\n",
      "704122: reward: 308.00, mean_100: 390.61, episodes: 1883, reward function loss: -0.0402\n",
      "704433: reward: 311.00, mean_100: 389.22, episodes: 1884, reward function loss: -0.0318\n",
      "704933: reward: 500.00, mean_100: 389.58, episodes: 1885, reward function loss: -0.0318\n",
      "705167: reward: 234.00, mean_100: 388.22, episodes: 1886, reward function loss: -0.0318\n",
      "705408: reward: 241.00, mean_100: 385.63, episodes: 1887, reward function loss: -0.0318\n",
      "705782: reward: 374.00, mean_100: 384.91, episodes: 1888, reward function loss: -0.0313\n",
      "706150: reward: 368.00, mean_100: 384.22, episodes: 1889, reward function loss: -0.0313\n",
      "706466: reward: 316.00, mean_100: 383.00, episodes: 1890, reward function loss: -0.0313\n",
      "706966: reward: 500.00, mean_100: 384.32, episodes: 1891, reward function loss: -0.0313\n",
      "707421: reward: 455.00, mean_100: 384.46, episodes: 1892, reward function loss: -0.0393\n",
      "707858: reward: 437.00, mean_100: 385.71, episodes: 1893, reward function loss: -0.0393\n",
      "708216: reward: 358.00, mean_100: 386.25, episodes: 1894, reward function loss: -0.0393\n",
      "708516: reward: 300.00, mean_100: 386.17, episodes: 1895, reward function loss: -0.0393\n",
      "708951: reward: 435.00, mean_100: 385.52, episodes: 1896, reward function loss: -0.0369\n",
      "709269: reward: 318.00, mean_100: 385.09, episodes: 1897, reward function loss: -0.0369\n",
      "709649: reward: 380.00, mean_100: 383.89, episodes: 1898, reward function loss: -0.0369\n",
      "710149: reward: 500.00, mean_100: 386.00, episodes: 1899, reward function loss: -0.0369\n",
      "710649: reward: 500.00, mean_100: 387.88, episodes: 1900, reward function loss: -0.0405\n",
      "711091: reward: 442.00, mean_100: 387.30, episodes: 1901, reward function loss: -0.0405\n",
      "711398: reward: 307.00, mean_100: 385.37, episodes: 1902, reward function loss: -0.0405\n",
      "711770: reward: 372.00, mean_100: 385.55, episodes: 1903, reward function loss: -0.0405\n",
      "712068: reward: 298.00, mean_100: 383.53, episodes: 1904, reward function loss: -0.0339\n",
      "712379: reward: 311.00, mean_100: 382.87, episodes: 1905, reward function loss: -0.0339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712879: reward: 500.00, mean_100: 385.46, episodes: 1906, reward function loss: -0.0339\n",
      "713184: reward: 305.00, mean_100: 384.90, episodes: 1907, reward function loss: -0.0339\n",
      "713509: reward: 325.00, mean_100: 385.09, episodes: 1908, reward function loss: -0.0347\n",
      "714009: reward: 500.00, mean_100: 387.03, episodes: 1909, reward function loss: -0.0347\n",
      "714309: reward: 300.00, mean_100: 385.40, episodes: 1910, reward function loss: -0.0347\n",
      "714750: reward: 441.00, mean_100: 386.07, episodes: 1911, reward function loss: -0.0347\n",
      "715214: reward: 464.00, mean_100: 386.85, episodes: 1912, reward function loss: -0.0411\n",
      "715648: reward: 434.00, mean_100: 388.25, episodes: 1913, reward function loss: -0.0411\n",
      "716033: reward: 385.00, mean_100: 387.10, episodes: 1914, reward function loss: -0.0411\n",
      "716342: reward: 309.00, mean_100: 385.23, episodes: 1915, reward function loss: -0.0411\n",
      "716800: reward: 458.00, mean_100: 386.66, episodes: 1916, reward function loss: -0.0383\n",
      "717110: reward: 310.00, mean_100: 386.02, episodes: 1917, reward function loss: -0.0383\n",
      "717559: reward: 449.00, mean_100: 385.51, episodes: 1918, reward function loss: -0.0383\n",
      "717794: reward: 235.00, mean_100: 382.92, episodes: 1919, reward function loss: -0.0383\n",
      "718294: reward: 500.00, mean_100: 384.85, episodes: 1920, reward function loss: -0.0361\n",
      "718671: reward: 377.00, mean_100: 385.42, episodes: 1921, reward function loss: -0.0361\n",
      "718907: reward: 236.00, mean_100: 384.08, episodes: 1922, reward function loss: -0.0361\n",
      "719205: reward: 298.00, mean_100: 383.41, episodes: 1923, reward function loss: -0.0361\n",
      "719582: reward: 377.00, mean_100: 382.18, episodes: 1924, reward function loss: -0.0301\n",
      "719956: reward: 374.00, mean_100: 380.92, episodes: 1925, reward function loss: -0.0301\n",
      "720274: reward: 318.00, mean_100: 379.10, episodes: 1926, reward function loss: -0.0301\n",
      "720649: reward: 375.00, mean_100: 377.85, episodes: 1927, reward function loss: -0.0301\n",
      "720889: reward: 240.00, mean_100: 377.33, episodes: 1928, reward function loss: -0.0314\n",
      "721389: reward: 500.00, mean_100: 378.03, episodes: 1929, reward function loss: -0.0314\n",
      "721743: reward: 354.00, mean_100: 376.57, episodes: 1930, reward function loss: -0.0314\n",
      "722120: reward: 377.00, mean_100: 376.63, episodes: 1931, reward function loss: -0.0314\n",
      "722508: reward: 388.00, mean_100: 376.76, episodes: 1932, reward function loss: -0.0387\n",
      "722803: reward: 295.00, mean_100: 374.71, episodes: 1933, reward function loss: -0.0387\n",
      "723303: reward: 500.00, mean_100: 377.39, episodes: 1934, reward function loss: -0.0387\n",
      "723541: reward: 238.00, mean_100: 376.21, episodes: 1935, reward function loss: -0.0387\n",
      "724041: reward: 500.00, mean_100: 376.21, episodes: 1936, reward function loss: -0.0370\n",
      "724410: reward: 369.00, mean_100: 376.06, episodes: 1937, reward function loss: -0.0370\n",
      "724910: reward: 500.00, mean_100: 378.73, episodes: 1938, reward function loss: -0.0370\n",
      "725271: reward: 361.00, mean_100: 377.34, episodes: 1939, reward function loss: -0.0370\n",
      "725766: reward: 495.00, mean_100: 379.32, episodes: 1940, reward function loss: -0.0415\n",
      "726216: reward: 450.00, mean_100: 380.20, episodes: 1941, reward function loss: -0.0415\n",
      "726716: reward: 500.00, mean_100: 382.77, episodes: 1942, reward function loss: -0.0415\n",
      "726940: reward: 224.00, mean_100: 382.47, episodes: 1943, reward function loss: -0.0415\n",
      "727270: reward: 330.00, mean_100: 380.77, episodes: 1944, reward function loss: -0.0362\n",
      "727642: reward: 372.00, mean_100: 382.16, episodes: 1945, reward function loss: -0.0362\n",
      "727880: reward: 238.00, mean_100: 380.78, episodes: 1946, reward function loss: -0.0362\n",
      "728258: reward: 378.00, mean_100: 380.90, episodes: 1947, reward function loss: -0.0362\n",
      "728686: reward: 428.00, mean_100: 380.81, episodes: 1948, reward function loss: -0.0340\n",
      "729071: reward: 385.00, mean_100: 380.97, episodes: 1949, reward function loss: -0.0340\n",
      "729517: reward: 446.00, mean_100: 381.66, episodes: 1950, reward function loss: -0.0340\n",
      "729893: reward: 376.00, mean_100: 381.11, episodes: 1951, reward function loss: -0.0340\n",
      "730126: reward: 233.00, mean_100: 378.44, episodes: 1952, reward function loss: -0.0347\n",
      "730365: reward: 239.00, mean_100: 378.52, episodes: 1953, reward function loss: -0.0347\n",
      "730823: reward: 458.00, mean_100: 378.62, episodes: 1954, reward function loss: -0.0347\n",
      "731197: reward: 374.00, mean_100: 377.36, episodes: 1955, reward function loss: -0.0347\n",
      "731697: reward: 500.00, mean_100: 377.36, episodes: 1956, reward function loss: -0.0380\n",
      "732197: reward: 500.00, mean_100: 378.66, episodes: 1957, reward function loss: -0.0380\n",
      "732506: reward: 309.00, mean_100: 377.37, episodes: 1958, reward function loss: -0.0380\n",
      "732862: reward: 356.00, mean_100: 375.93, episodes: 1959, reward function loss: -0.0380\n",
      "733362: reward: 500.00, mean_100: 378.51, episodes: 1960, reward function loss: -0.0398\n",
      "733862: reward: 500.00, mean_100: 378.51, episodes: 1961, reward function loss: -0.0398\n",
      "734362: reward: 500.00, mean_100: 381.88, episodes: 1962, reward function loss: -0.0398\n",
      "734808: reward: 446.00, mean_100: 383.18, episodes: 1963, reward function loss: -0.0398\n",
      "735241: reward: 433.00, mean_100: 383.93, episodes: 1964, reward function loss: -0.0449\n",
      "735487: reward: 246.00, mean_100: 383.33, episodes: 1965, reward function loss: -0.0449\n",
      "735803: reward: 316.00, mean_100: 383.37, episodes: 1966, reward function loss: -0.0449\n",
      "736303: reward: 500.00, mean_100: 385.28, episodes: 1967, reward function loss: -0.0449\n",
      "736656: reward: 353.00, mean_100: 384.19, episodes: 1968, reward function loss: -0.0343\n",
      "736950: reward: 294.00, mean_100: 384.25, episodes: 1969, reward function loss: -0.0343\n",
      "737303: reward: 353.00, mean_100: 384.50, episodes: 1970, reward function loss: -0.0343\n",
      "737659: reward: 356.00, mean_100: 383.61, episodes: 1971, reward function loss: -0.0343\n",
      "737888: reward: 229.00, mean_100: 381.58, episodes: 1972, reward function loss: -0.0296\n",
      "738388: reward: 500.00, mean_100: 382.20, episodes: 1973, reward function loss: -0.0296\n",
      "738702: reward: 314.00, mean_100: 380.34, episodes: 1974, reward function loss: -0.0296\n",
      "739086: reward: 384.00, mean_100: 381.26, episodes: 1975, reward function loss: -0.0296\n",
      "739542: reward: 456.00, mean_100: 380.82, episodes: 1976, reward function loss: -0.0400\n",
      "739914: reward: 372.00, mean_100: 381.50, episodes: 1977, reward function loss: -0.0400\n",
      "740138: reward: 224.00, mean_100: 378.74, episodes: 1978, reward function loss: -0.0400\n",
      "740450: reward: 312.00, mean_100: 376.86, episodes: 1979, reward function loss: -0.0400\n",
      "740759: reward: 309.00, mean_100: 376.31, episodes: 1980, reward function loss: -0.0289\n",
      "741259: reward: 500.00, mean_100: 378.16, episodes: 1981, reward function loss: -0.0289\n",
      "741759: reward: 500.00, mean_100: 379.45, episodes: 1982, reward function loss: -0.0289\n",
      "742149: reward: 390.00, mean_100: 380.27, episodes: 1983, reward function loss: -0.0289\n",
      "742524: reward: 375.00, mean_100: 380.91, episodes: 1984, reward function loss: -0.0422\n",
      "742834: reward: 310.00, mean_100: 379.01, episodes: 1985, reward function loss: -0.0422\n",
      "743334: reward: 500.00, mean_100: 381.67, episodes: 1986, reward function loss: -0.0422\n",
      "743781: reward: 447.00, mean_100: 383.73, episodes: 1987, reward function loss: -0.0422\n",
      "744017: reward: 236.00, mean_100: 382.35, episodes: 1988, reward function loss: -0.0357\n",
      "744382: reward: 365.00, mean_100: 382.32, episodes: 1989, reward function loss: -0.0357\n",
      "744773: reward: 391.00, mean_100: 383.07, episodes: 1990, reward function loss: -0.0357\n",
      "745017: reward: 244.00, mean_100: 380.51, episodes: 1991, reward function loss: -0.0357\n",
      "745477: reward: 460.00, mean_100: 380.56, episodes: 1992, reward function loss: -0.0352\n",
      "745794: reward: 317.00, mean_100: 379.36, episodes: 1993, reward function loss: -0.0352\n",
      "746294: reward: 500.00, mean_100: 380.78, episodes: 1994, reward function loss: -0.0352\n",
      "746794: reward: 500.00, mean_100: 382.78, episodes: 1995, reward function loss: -0.0352\n",
      "747037: reward: 243.00, mean_100: 380.86, episodes: 1996, reward function loss: -0.0363\n",
      "747537: reward: 500.00, mean_100: 382.68, episodes: 1997, reward function loss: -0.0363\n",
      "747851: reward: 314.00, mean_100: 382.02, episodes: 1998, reward function loss: -0.0363\n",
      "748154: reward: 303.00, mean_100: 380.05, episodes: 1999, reward function loss: -0.0363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748469: reward: 315.00, mean_100: 378.20, episodes: 2000, reward function loss: -0.0345\n",
      "748969: reward: 500.00, mean_100: 378.78, episodes: 2001, reward function loss: -0.0345\n",
      "749359: reward: 390.00, mean_100: 379.61, episodes: 2002, reward function loss: -0.0345\n",
      "749679: reward: 320.00, mean_100: 379.09, episodes: 2003, reward function loss: -0.0345\n",
      "749999: reward: 320.00, mean_100: 379.31, episodes: 2004, reward function loss: -0.0360\n",
      "750439: reward: 440.00, mean_100: 380.60, episodes: 2005, reward function loss: -0.0360\n",
      "750827: reward: 388.00, mean_100: 379.48, episodes: 2006, reward function loss: -0.0360\n",
      "751283: reward: 456.00, mean_100: 380.99, episodes: 2007, reward function loss: -0.0360\n",
      "751783: reward: 500.00, mean_100: 382.74, episodes: 2008, reward function loss: -0.0424\n",
      "752235: reward: 452.00, mean_100: 382.26, episodes: 2009, reward function loss: -0.0424\n",
      "752695: reward: 460.00, mean_100: 383.86, episodes: 2010, reward function loss: -0.0424\n",
      "753195: reward: 500.00, mean_100: 384.45, episodes: 2011, reward function loss: -0.0424\n",
      "753637: reward: 442.00, mean_100: 384.23, episodes: 2012, reward function loss: -0.0445\n",
      "753950: reward: 313.00, mean_100: 383.02, episodes: 2013, reward function loss: -0.0445\n",
      "754321: reward: 371.00, mean_100: 382.88, episodes: 2014, reward function loss: -0.0445\n",
      "754546: reward: 225.00, mean_100: 382.04, episodes: 2015, reward function loss: -0.0445\n",
      "755046: reward: 500.00, mean_100: 382.46, episodes: 2016, reward function loss: -0.0336\n",
      "755546: reward: 500.00, mean_100: 384.36, episodes: 2017, reward function loss: -0.0336\n",
      "755916: reward: 370.00, mean_100: 383.57, episodes: 2018, reward function loss: -0.0336\n",
      "756147: reward: 231.00, mean_100: 383.53, episodes: 2019, reward function loss: -0.0336\n",
      "756461: reward: 314.00, mean_100: 381.67, episodes: 2020, reward function loss: -0.0338\n",
      "756904: reward: 443.00, mean_100: 382.33, episodes: 2021, reward function loss: -0.0338\n",
      "757150: reward: 246.00, mean_100: 382.43, episodes: 2022, reward function loss: -0.0338\n",
      "757389: reward: 239.00, mean_100: 381.84, episodes: 2023, reward function loss: -0.0338\n",
      "757753: reward: 364.00, mean_100: 381.71, episodes: 2024, reward function loss: -0.0312\n",
      "758000: reward: 247.00, mean_100: 380.44, episodes: 2025, reward function loss: -0.0312\n",
      "758358: reward: 358.00, mean_100: 380.84, episodes: 2026, reward function loss: -0.0312\n",
      "758798: reward: 440.00, mean_100: 381.49, episodes: 2027, reward function loss: -0.0312\n",
      "759298: reward: 500.00, mean_100: 384.09, episodes: 2028, reward function loss: -0.0370\n",
      "759664: reward: 366.00, mean_100: 382.75, episodes: 2029, reward function loss: -0.0370\n",
      "760034: reward: 370.00, mean_100: 382.91, episodes: 2030, reward function loss: -0.0370\n",
      "760276: reward: 242.00, mean_100: 381.56, episodes: 2031, reward function loss: -0.0370\n",
      "760593: reward: 317.00, mean_100: 380.85, episodes: 2032, reward function loss: -0.0315\n",
      "761060: reward: 467.00, mean_100: 382.57, episodes: 2033, reward function loss: -0.0315\n",
      "761560: reward: 500.00, mean_100: 382.57, episodes: 2034, reward function loss: -0.0315\n",
      "761874: reward: 314.00, mean_100: 383.33, episodes: 2035, reward function loss: -0.0315\n",
      "762190: reward: 316.00, mean_100: 381.49, episodes: 2036, reward function loss: -0.0374\n",
      "762690: reward: 500.00, mean_100: 382.80, episodes: 2037, reward function loss: -0.0374\n",
      "763190: reward: 500.00, mean_100: 382.80, episodes: 2038, reward function loss: -0.0374\n",
      "763560: reward: 370.00, mean_100: 382.89, episodes: 2039, reward function loss: -0.0374\n",
      "764060: reward: 500.00, mean_100: 382.94, episodes: 2040, reward function loss: -0.0450\n",
      "764441: reward: 381.00, mean_100: 382.25, episodes: 2041, reward function loss: -0.0450\n",
      "764810: reward: 369.00, mean_100: 380.94, episodes: 2042, reward function loss: -0.0450\n",
      "765243: reward: 433.00, mean_100: 383.03, episodes: 2043, reward function loss: -0.0450\n",
      "765643: reward: 400.00, mean_100: 383.73, episodes: 2044, reward function loss: -0.0382\n",
      "766143: reward: 500.00, mean_100: 385.01, episodes: 2045, reward function loss: -0.0382\n",
      "766526: reward: 383.00, mean_100: 386.46, episodes: 2046, reward function loss: -0.0382\n",
      "766966: reward: 440.00, mean_100: 387.08, episodes: 2047, reward function loss: -0.0382\n",
      "767278: reward: 312.00, mean_100: 385.92, episodes: 2048, reward function loss: -0.0395\n",
      "767650: reward: 372.00, mean_100: 385.79, episodes: 2049, reward function loss: -0.0395\n",
      "768033: reward: 383.00, mean_100: 385.16, episodes: 2050, reward function loss: -0.0395\n",
      "768404: reward: 371.00, mean_100: 385.11, episodes: 2051, reward function loss: -0.0395\n",
      "768904: reward: 500.00, mean_100: 387.78, episodes: 2052, reward function loss: -0.0392\n",
      "769355: reward: 451.00, mean_100: 389.90, episodes: 2053, reward function loss: -0.0392\n",
      "769737: reward: 382.00, mean_100: 389.14, episodes: 2054, reward function loss: -0.0392\n",
      "770189: reward: 452.00, mean_100: 389.92, episodes: 2055, reward function loss: -0.0392\n",
      "770486: reward: 297.00, mean_100: 387.89, episodes: 2056, reward function loss: -0.0381\n",
      "770850: reward: 364.00, mean_100: 386.53, episodes: 2057, reward function loss: -0.0381\n",
      "771235: reward: 385.00, mean_100: 387.29, episodes: 2058, reward function loss: -0.0381\n",
      "771622: reward: 387.00, mean_100: 387.60, episodes: 2059, reward function loss: -0.0381\n",
      "772122: reward: 500.00, mean_100: 387.60, episodes: 2060, reward function loss: -0.0396\n",
      "772435: reward: 313.00, mean_100: 385.73, episodes: 2061, reward function loss: -0.0396\n",
      "772806: reward: 371.00, mean_100: 384.44, episodes: 2062, reward function loss: -0.0396\n",
      "773306: reward: 500.00, mean_100: 384.98, episodes: 2063, reward function loss: -0.0396\n",
      "773685: reward: 379.00, mean_100: 384.44, episodes: 2064, reward function loss: -0.0371\n",
      "774146: reward: 461.00, mean_100: 386.59, episodes: 2065, reward function loss: -0.0371\n",
      "774646: reward: 500.00, mean_100: 388.43, episodes: 2066, reward function loss: -0.0371\n",
      "774961: reward: 315.00, mean_100: 386.58, episodes: 2067, reward function loss: -0.0371\n",
      "775283: reward: 322.00, mean_100: 386.27, episodes: 2068, reward function loss: -0.0386\n",
      "775603: reward: 320.00, mean_100: 386.53, episodes: 2069, reward function loss: -0.0386\n",
      "776099: reward: 496.00, mean_100: 387.96, episodes: 2070, reward function loss: -0.0386\n",
      "776599: reward: 500.00, mean_100: 389.40, episodes: 2071, reward function loss: -0.0386\n",
      "776974: reward: 375.00, mean_100: 390.86, episodes: 2072, reward function loss: -0.0407\n",
      "777284: reward: 310.00, mean_100: 388.96, episodes: 2073, reward function loss: -0.0407\n",
      "777780: reward: 496.00, mean_100: 390.78, episodes: 2074, reward function loss: -0.0407\n",
      "778280: reward: 500.00, mean_100: 391.94, episodes: 2075, reward function loss: -0.0407\n",
      "778574: reward: 294.00, mean_100: 390.32, episodes: 2076, reward function loss: -0.0387\n",
      "778949: reward: 375.00, mean_100: 390.35, episodes: 2077, reward function loss: -0.0387\n",
      "779402: reward: 453.00, mean_100: 392.64, episodes: 2078, reward function loss: -0.0387\n",
      "779725: reward: 323.00, mean_100: 392.75, episodes: 2079, reward function loss: -0.0387\n",
      "780225: reward: 500.00, mean_100: 394.66, episodes: 2080, reward function loss: -0.0399\n",
      "780725: reward: 500.00, mean_100: 394.66, episodes: 2081, reward function loss: -0.0399\n",
      "781092: reward: 367.00, mean_100: 393.33, episodes: 2082, reward function loss: -0.0399\n",
      "781592: reward: 500.00, mean_100: 394.43, episodes: 2083, reward function loss: -0.0399\n",
      "782044: reward: 452.00, mean_100: 395.20, episodes: 2084, reward function loss: -0.0431\n",
      "782340: reward: 296.00, mean_100: 395.06, episodes: 2085, reward function loss: -0.0431\n",
      "782724: reward: 384.00, mean_100: 393.90, episodes: 2086, reward function loss: -0.0431\n",
      "783224: reward: 500.00, mean_100: 394.43, episodes: 2087, reward function loss: -0.0431\n",
      "783697: reward: 473.00, mean_100: 396.80, episodes: 2088, reward function loss: -0.0388\n",
      "784009: reward: 312.00, mean_100: 396.27, episodes: 2089, reward function loss: -0.0388\n",
      "784330: reward: 321.00, mean_100: 395.57, episodes: 2090, reward function loss: -0.0388\n",
      "784789: reward: 459.00, mean_100: 397.72, episodes: 2091, reward function loss: -0.0388\n",
      "785029: reward: 240.00, mean_100: 395.52, episodes: 2092, reward function loss: -0.0310\n",
      "785424: reward: 395.00, mean_100: 396.30, episodes: 2093, reward function loss: -0.0310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785871: reward: 447.00, mean_100: 395.77, episodes: 2094, reward function loss: -0.0310\n",
      "786188: reward: 317.00, mean_100: 393.94, episodes: 2095, reward function loss: -0.0310\n",
      "786562: reward: 374.00, mean_100: 395.25, episodes: 2096, reward function loss: -0.0371\n",
      "786950: reward: 388.00, mean_100: 394.13, episodes: 2097, reward function loss: -0.0371\n",
      "787318: reward: 368.00, mean_100: 394.67, episodes: 2098, reward function loss: -0.0371\n",
      "787642: reward: 324.00, mean_100: 394.88, episodes: 2099, reward function loss: -0.0371\n",
      "788142: reward: 500.00, mean_100: 396.73, episodes: 2100, reward function loss: -0.0381\n",
      "788529: reward: 387.00, mean_100: 395.60, episodes: 2101, reward function loss: -0.0381\n",
      "788961: reward: 432.00, mean_100: 396.02, episodes: 2102, reward function loss: -0.0381\n",
      "789410: reward: 449.00, mean_100: 397.31, episodes: 2103, reward function loss: -0.0381\n",
      "789910: reward: 500.00, mean_100: 399.11, episodes: 2104, reward function loss: -0.0418\n",
      "790363: reward: 453.00, mean_100: 399.24, episodes: 2105, reward function loss: -0.0418\n",
      "790751: reward: 388.00, mean_100: 399.24, episodes: 2106, reward function loss: -0.0418\n",
      "791215: reward: 464.00, mean_100: 399.32, episodes: 2107, reward function loss: -0.0418\n",
      "791531: reward: 316.00, mean_100: 397.48, episodes: 2108, reward function loss: -0.0375\n",
      "792031: reward: 500.00, mean_100: 397.96, episodes: 2109, reward function loss: -0.0375\n",
      "792327: reward: 296.00, mean_100: 396.32, episodes: 2110, reward function loss: -0.0375\n",
      "792641: reward: 314.00, mean_100: 394.46, episodes: 2111, reward function loss: -0.0375\n",
      "793022: reward: 381.00, mean_100: 393.85, episodes: 2112, reward function loss: -0.0362\n",
      "793417: reward: 395.00, mean_100: 394.67, episodes: 2113, reward function loss: -0.0362\n",
      "793735: reward: 318.00, mean_100: 394.14, episodes: 2114, reward function loss: -0.0362\n",
      "794054: reward: 319.00, mean_100: 395.08, episodes: 2115, reward function loss: -0.0362\n",
      "794412: reward: 358.00, mean_100: 393.66, episodes: 2116, reward function loss: -0.0338\n",
      "794912: reward: 500.00, mean_100: 393.66, episodes: 2117, reward function loss: -0.0338\n",
      "795235: reward: 323.00, mean_100: 393.19, episodes: 2118, reward function loss: -0.0338\n",
      "795735: reward: 500.00, mean_100: 395.88, episodes: 2119, reward function loss: -0.0338\n",
      "796054: reward: 319.00, mean_100: 395.93, episodes: 2120, reward function loss: -0.0383\n",
      "796430: reward: 376.00, mean_100: 395.26, episodes: 2121, reward function loss: -0.0383\n",
      "796930: reward: 500.00, mean_100: 397.80, episodes: 2122, reward function loss: -0.0383\n",
      "797258: reward: 328.00, mean_100: 398.69, episodes: 2123, reward function loss: -0.0383\n",
      "797708: reward: 450.00, mean_100: 399.55, episodes: 2124, reward function loss: -0.0399\n",
      "798005: reward: 297.00, mean_100: 400.05, episodes: 2125, reward function loss: -0.0399\n",
      "798387: reward: 382.00, mean_100: 400.29, episodes: 2126, reward function loss: -0.0399\n",
      "798887: reward: 500.00, mean_100: 400.89, episodes: 2127, reward function loss: -0.0399\n",
      "799276: reward: 389.00, mean_100: 399.78, episodes: 2128, reward function loss: -0.0370\n",
      "799664: reward: 388.00, mean_100: 400.00, episodes: 2129, reward function loss: -0.0370\n",
      "800164: reward: 500.00, mean_100: 401.30, episodes: 2130, reward function loss: -0.0370\n",
      "800664: reward: 500.00, mean_100: 403.88, episodes: 2131, reward function loss: -0.0370\n",
      "800982: reward: 318.00, mean_100: 403.89, episodes: 2132, reward function loss: -0.0408\n",
      "801482: reward: 500.00, mean_100: 404.22, episodes: 2133, reward function loss: -0.0408\n",
      "801863: reward: 381.00, mean_100: 403.03, episodes: 2134, reward function loss: -0.0408\n",
      "802326: reward: 463.00, mean_100: 404.52, episodes: 2135, reward function loss: -0.0408\n",
      "802790: reward: 464.00, mean_100: 406.00, episodes: 2136, reward function loss: -0.0433\n",
      "803040: reward: 250.00, mean_100: 403.50, episodes: 2137, reward function loss: -0.0433\n",
      "803363: reward: 323.00, mean_100: 401.73, episodes: 2138, reward function loss: -0.0433\n",
      "803756: reward: 393.00, mean_100: 401.96, episodes: 2139, reward function loss: -0.0433\n",
      "804074: reward: 318.00, mean_100: 400.14, episodes: 2140, reward function loss: -0.0300\n",
      "804574: reward: 500.00, mean_100: 401.33, episodes: 2141, reward function loss: -0.0300\n",
      "805014: reward: 440.00, mean_100: 402.04, episodes: 2142, reward function loss: -0.0300\n",
      "805465: reward: 451.00, mean_100: 402.22, episodes: 2143, reward function loss: -0.0300\n",
      "805769: reward: 304.00, mean_100: 401.26, episodes: 2144, reward function loss: -0.0404\n",
      "806169: reward: 400.00, mean_100: 400.26, episodes: 2145, reward function loss: -0.0404\n",
      "806480: reward: 311.00, mean_100: 399.54, episodes: 2146, reward function loss: -0.0404\n",
      "806886: reward: 406.00, mean_100: 399.20, episodes: 2147, reward function loss: -0.0404\n",
      "807272: reward: 386.00, mean_100: 399.94, episodes: 2148, reward function loss: -0.0351\n",
      "807582: reward: 310.00, mean_100: 399.32, episodes: 2149, reward function loss: -0.0351\n",
      "808035: reward: 453.00, mean_100: 400.02, episodes: 2150, reward function loss: -0.0351\n",
      "808408: reward: 373.00, mean_100: 400.04, episodes: 2151, reward function loss: -0.0351\n",
      "808862: reward: 454.00, mean_100: 399.58, episodes: 2152, reward function loss: -0.0382\n",
      "809240: reward: 378.00, mean_100: 398.85, episodes: 2153, reward function loss: -0.0382\n",
      "809740: reward: 500.00, mean_100: 400.03, episodes: 2154, reward function loss: -0.0382\n",
      "809979: reward: 239.00, mean_100: 397.90, episodes: 2155, reward function loss: -0.0382\n",
      "810276: reward: 297.00, mean_100: 397.90, episodes: 2156, reward function loss: -0.0340\n",
      "810591: reward: 315.00, mean_100: 397.41, episodes: 2157, reward function loss: -0.0340\n",
      "811091: reward: 500.00, mean_100: 398.56, episodes: 2158, reward function loss: -0.0340\n",
      "811388: reward: 297.00, mean_100: 397.66, episodes: 2159, reward function loss: -0.0340\n",
      "811854: reward: 466.00, mean_100: 397.32, episodes: 2160, reward function loss: -0.0376\n",
      "812159: reward: 305.00, mean_100: 397.24, episodes: 2161, reward function loss: -0.0376\n",
      "812530: reward: 371.00, mean_100: 397.24, episodes: 2162, reward function loss: -0.0376\n",
      "812853: reward: 323.00, mean_100: 395.47, episodes: 2163, reward function loss: -0.0376\n",
      "813222: reward: 369.00, mean_100: 395.37, episodes: 2164, reward function loss: -0.0331\n",
      "813722: reward: 500.00, mean_100: 395.76, episodes: 2165, reward function loss: -0.0331\n",
      "814222: reward: 500.00, mean_100: 395.76, episodes: 2166, reward function loss: -0.0331\n",
      "814456: reward: 234.00, mean_100: 394.95, episodes: 2167, reward function loss: -0.0331\n",
      "814914: reward: 458.00, mean_100: 396.31, episodes: 2168, reward function loss: -0.0404\n",
      "815414: reward: 500.00, mean_100: 398.11, episodes: 2169, reward function loss: -0.0404\n",
      "815675: reward: 261.00, mean_100: 395.76, episodes: 2170, reward function loss: -0.0404\n",
      "816175: reward: 500.00, mean_100: 395.76, episodes: 2171, reward function loss: -0.0404\n",
      "816675: reward: 500.00, mean_100: 397.01, episodes: 2172, reward function loss: -0.0417\n",
      "817175: reward: 500.00, mean_100: 398.91, episodes: 2173, reward function loss: -0.0417\n",
      "817675: reward: 500.00, mean_100: 398.95, episodes: 2174, reward function loss: -0.0417\n",
      "817975: reward: 300.00, mean_100: 396.95, episodes: 2175, reward function loss: -0.0417\n",
      "818475: reward: 500.00, mean_100: 399.01, episodes: 2176, reward function loss: -0.0431\n",
      "818732: reward: 257.00, mean_100: 397.83, episodes: 2177, reward function loss: -0.0431\n",
      "818972: reward: 240.00, mean_100: 395.70, episodes: 2178, reward function loss: -0.0431\n",
      "819346: reward: 374.00, mean_100: 396.21, episodes: 2179, reward function loss: -0.0431\n",
      "819846: reward: 500.00, mean_100: 396.21, episodes: 2180, reward function loss: -0.0325\n",
      "820346: reward: 500.00, mean_100: 396.21, episodes: 2181, reward function loss: -0.0325\n",
      "820657: reward: 311.00, mean_100: 395.65, episodes: 2182, reward function loss: -0.0325\n",
      "821021: reward: 364.00, mean_100: 394.29, episodes: 2183, reward function loss: -0.0325\n",
      "821521: reward: 500.00, mean_100: 394.77, episodes: 2184, reward function loss: -0.0399\n",
      "821817: reward: 296.00, mean_100: 394.77, episodes: 2185, reward function loss: -0.0399\n",
      "822074: reward: 257.00, mean_100: 393.50, episodes: 2186, reward function loss: -0.0399\n",
      "822329: reward: 255.00, mean_100: 391.05, episodes: 2187, reward function loss: -0.0399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822829: reward: 500.00, mean_100: 391.32, episodes: 2188, reward function loss: -0.0306\n",
      "823329: reward: 500.00, mean_100: 393.20, episodes: 2189, reward function loss: -0.0306\n",
      "823767: reward: 438.00, mean_100: 394.37, episodes: 2190, reward function loss: -0.0306\n",
      "824092: reward: 325.00, mean_100: 393.03, episodes: 2191, reward function loss: -0.0306\n",
      "824477: reward: 385.00, mean_100: 394.48, episodes: 2192, reward function loss: -0.0382\n",
      "824977: reward: 500.00, mean_100: 395.53, episodes: 2193, reward function loss: -0.0382\n",
      "825477: reward: 500.00, mean_100: 396.06, episodes: 2194, reward function loss: -0.0382\n",
      "825977: reward: 500.00, mean_100: 397.89, episodes: 2195, reward function loss: -0.0382\n",
      "826358: reward: 381.00, mean_100: 397.96, episodes: 2196, reward function loss: -0.0438\n",
      "826858: reward: 500.00, mean_100: 399.08, episodes: 2197, reward function loss: -0.0438\n",
      "827220: reward: 362.00, mean_100: 399.02, episodes: 2198, reward function loss: -0.0438\n",
      "827597: reward: 377.00, mean_100: 399.55, episodes: 2199, reward function loss: -0.0438\n",
      "827906: reward: 309.00, mean_100: 397.64, episodes: 2200, reward function loss: -0.0370\n",
      "828406: reward: 500.00, mean_100: 398.77, episodes: 2201, reward function loss: -0.0370\n",
      "828906: reward: 500.00, mean_100: 399.45, episodes: 2202, reward function loss: -0.0370\n",
      "829205: reward: 299.00, mean_100: 397.95, episodes: 2203, reward function loss: -0.0370\n",
      "829705: reward: 500.00, mean_100: 397.95, episodes: 2204, reward function loss: -0.0429\n",
      "830145: reward: 440.00, mean_100: 397.82, episodes: 2205, reward function loss: -0.0429\n",
      "830435: reward: 290.00, mean_100: 396.84, episodes: 2206, reward function loss: -0.0429\n",
      "830818: reward: 383.00, mean_100: 396.03, episodes: 2207, reward function loss: -0.0429\n",
      "831207: reward: 389.00, mean_100: 396.76, episodes: 2208, reward function loss: -0.0364\n",
      "831592: reward: 385.00, mean_100: 395.61, episodes: 2209, reward function loss: -0.0364\n",
      "832092: reward: 500.00, mean_100: 397.65, episodes: 2210, reward function loss: -0.0364\n",
      "832592: reward: 500.00, mean_100: 399.51, episodes: 2211, reward function loss: -0.0364\n",
      "832832: reward: 240.00, mean_100: 398.10, episodes: 2212, reward function loss: -0.0391\n",
      "833290: reward: 458.00, mean_100: 398.73, episodes: 2213, reward function loss: -0.0391\n",
      "833790: reward: 500.00, mean_100: 400.55, episodes: 2214, reward function loss: -0.0391\n",
      "834195: reward: 405.00, mean_100: 401.41, episodes: 2215, reward function loss: -0.0391\n",
      "834525: reward: 330.00, mean_100: 401.13, episodes: 2216, reward function loss: -0.0405\n",
      "835025: reward: 500.00, mean_100: 401.13, episodes: 2217, reward function loss: -0.0405\n",
      "835525: reward: 500.00, mean_100: 402.90, episodes: 2218, reward function loss: -0.0405\n",
      "836025: reward: 500.00, mean_100: 402.90, episodes: 2219, reward function loss: -0.0405\n",
      "836481: reward: 456.00, mean_100: 404.27, episodes: 2220, reward function loss: -0.0452\n",
      "836862: reward: 381.00, mean_100: 404.32, episodes: 2221, reward function loss: -0.0452\n",
      "837232: reward: 370.00, mean_100: 403.02, episodes: 2222, reward function loss: -0.0452\n",
      "837608: reward: 376.00, mean_100: 403.50, episodes: 2223, reward function loss: -0.0452\n",
      "838099: reward: 491.00, mean_100: 403.91, episodes: 2224, reward function loss: -0.0390\n",
      "838407: reward: 308.00, mean_100: 404.02, episodes: 2225, reward function loss: -0.0390\n",
      "838852: reward: 445.00, mean_100: 404.65, episodes: 2226, reward function loss: -0.0390\n",
      "839248: reward: 396.00, mean_100: 403.61, episodes: 2227, reward function loss: -0.0390\n",
      "839748: reward: 500.00, mean_100: 404.72, episodes: 2228, reward function loss: -0.0398\n",
      "840085: reward: 337.00, mean_100: 404.21, episodes: 2229, reward function loss: -0.0398\n",
      "840414: reward: 329.00, mean_100: 402.50, episodes: 2230, reward function loss: -0.0398\n",
      "840807: reward: 393.00, mean_100: 401.43, episodes: 2231, reward function loss: -0.0398\n",
      "841119: reward: 312.00, mean_100: 401.37, episodes: 2232, reward function loss: -0.0320\n",
      "841516: reward: 397.00, mean_100: 400.34, episodes: 2233, reward function loss: -0.0320\n",
      "841827: reward: 311.00, mean_100: 399.64, episodes: 2234, reward function loss: -0.0320\n",
      "842275: reward: 448.00, mean_100: 399.49, episodes: 2235, reward function loss: -0.0320\n",
      "842775: reward: 500.00, mean_100: 399.85, episodes: 2236, reward function loss: -0.0399\n",
      "843097: reward: 322.00, mean_100: 400.57, episodes: 2237, reward function loss: -0.0399\n",
      "843423: reward: 326.00, mean_100: 400.60, episodes: 2238, reward function loss: -0.0399\n",
      "843815: reward: 392.00, mean_100: 400.59, episodes: 2239, reward function loss: -0.0399\n",
      "844197: reward: 382.00, mean_100: 401.23, episodes: 2240, reward function loss: -0.0343\n",
      "844438: reward: 241.00, mean_100: 398.64, episodes: 2241, reward function loss: -0.0343\n",
      "844753: reward: 315.00, mean_100: 397.39, episodes: 2242, reward function loss: -0.0343\n",
      "845066: reward: 313.00, mean_100: 396.01, episodes: 2243, reward function loss: -0.0343\n",
      "845460: reward: 394.00, mean_100: 396.91, episodes: 2244, reward function loss: -0.0303\n",
      "845921: reward: 461.00, mean_100: 397.52, episodes: 2245, reward function loss: -0.0303\n",
      "846246: reward: 325.00, mean_100: 397.66, episodes: 2246, reward function loss: -0.0303\n",
      "846746: reward: 500.00, mean_100: 398.60, episodes: 2247, reward function loss: -0.0303\n",
      "847138: reward: 392.00, mean_100: 398.66, episodes: 2248, reward function loss: -0.0400\n",
      "847499: reward: 361.00, mean_100: 399.17, episodes: 2249, reward function loss: -0.0400\n",
      "847753: reward: 254.00, mean_100: 397.18, episodes: 2250, reward function loss: -0.0400\n",
      "848147: reward: 394.00, mean_100: 397.39, episodes: 2251, reward function loss: -0.0400\n",
      "848473: reward: 326.00, mean_100: 396.11, episodes: 2252, reward function loss: -0.0317\n",
      "848946: reward: 473.00, mean_100: 397.06, episodes: 2253, reward function loss: -0.0317\n",
      "849282: reward: 336.00, mean_100: 395.42, episodes: 2254, reward function loss: -0.0317\n",
      "849782: reward: 500.00, mean_100: 398.03, episodes: 2255, reward function loss: -0.0317\n",
      "850193: reward: 411.00, mean_100: 399.17, episodes: 2256, reward function loss: -0.0407\n",
      "850693: reward: 500.00, mean_100: 401.02, episodes: 2257, reward function loss: -0.0407\n",
      "851025: reward: 332.00, mean_100: 399.34, episodes: 2258, reward function loss: -0.0407\n",
      "851399: reward: 374.00, mean_100: 400.11, episodes: 2259, reward function loss: -0.0407\n",
      "851811: reward: 412.00, mean_100: 399.57, episodes: 2260, reward function loss: -0.0383\n",
      "852311: reward: 500.00, mean_100: 401.52, episodes: 2261, reward function loss: -0.0383\n",
      "852640: reward: 329.00, mean_100: 401.10, episodes: 2262, reward function loss: -0.0383\n",
      "853017: reward: 377.00, mean_100: 401.64, episodes: 2263, reward function loss: -0.0383\n",
      "853517: reward: 500.00, mean_100: 402.95, episodes: 2264, reward function loss: -0.0388\n",
      "853899: reward: 382.00, mean_100: 401.77, episodes: 2265, reward function loss: -0.0388\n",
      "854273: reward: 374.00, mean_100: 400.51, episodes: 2266, reward function loss: -0.0388\n",
      "854681: reward: 408.00, mean_100: 402.25, episodes: 2267, reward function loss: -0.0388\n",
      "855181: reward: 500.00, mean_100: 402.67, episodes: 2268, reward function loss: -0.0392\n",
      "855493: reward: 312.00, mean_100: 400.79, episodes: 2269, reward function loss: -0.0392\n",
      "855876: reward: 383.00, mean_100: 402.01, episodes: 2270, reward function loss: -0.0392\n",
      "856265: reward: 389.00, mean_100: 400.90, episodes: 2271, reward function loss: -0.0392\n",
      "856671: reward: 406.00, mean_100: 399.96, episodes: 2272, reward function loss: -0.0357\n",
      "856931: reward: 260.00, mean_100: 397.56, episodes: 2273, reward function loss: -0.0357\n",
      "857431: reward: 500.00, mean_100: 397.56, episodes: 2274, reward function loss: -0.0357\n",
      "857893: reward: 462.00, mean_100: 399.18, episodes: 2275, reward function loss: -0.0357\n",
      "858235: reward: 342.00, mean_100: 397.60, episodes: 2276, reward function loss: -0.0368\n",
      "858604: reward: 369.00, mean_100: 398.72, episodes: 2277, reward function loss: -0.0368\n",
      "859001: reward: 397.00, mean_100: 400.29, episodes: 2278, reward function loss: -0.0368\n",
      "859381: reward: 380.00, mean_100: 400.35, episodes: 2279, reward function loss: -0.0368\n",
      "859881: reward: 500.00, mean_100: 400.35, episodes: 2280, reward function loss: -0.0386\n",
      "860265: reward: 384.00, mean_100: 399.19, episodes: 2281, reward function loss: -0.0386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860640: reward: 375.00, mean_100: 399.83, episodes: 2282, reward function loss: -0.0386\n",
      "861099: reward: 459.00, mean_100: 400.78, episodes: 2283, reward function loss: -0.0386\n",
      "861430: reward: 331.00, mean_100: 399.09, episodes: 2284, reward function loss: -0.0375\n",
      "861750: reward: 320.00, mean_100: 399.33, episodes: 2285, reward function loss: -0.0375\n",
      "862123: reward: 373.00, mean_100: 400.49, episodes: 2286, reward function loss: -0.0375\n",
      "862614: reward: 491.00, mean_100: 402.85, episodes: 2287, reward function loss: -0.0375\n",
      "863114: reward: 500.00, mean_100: 402.85, episodes: 2288, reward function loss: -0.0403\n",
      "863517: reward: 403.00, mean_100: 401.88, episodes: 2289, reward function loss: -0.0403\n",
      "864017: reward: 500.00, mean_100: 402.50, episodes: 2290, reward function loss: -0.0403\n",
      "864420: reward: 403.00, mean_100: 403.28, episodes: 2291, reward function loss: -0.0403\n",
      "864742: reward: 322.00, mean_100: 402.65, episodes: 2292, reward function loss: -0.0368\n",
      "865086: reward: 344.00, mean_100: 401.09, episodes: 2293, reward function loss: -0.0368\n",
      "865473: reward: 387.00, mean_100: 399.96, episodes: 2294, reward function loss: -0.0368\n",
      "865716: reward: 243.00, mean_100: 397.39, episodes: 2295, reward function loss: -0.0368\n",
      "866087: reward: 371.00, mean_100: 397.29, episodes: 2296, reward function loss: -0.0321\n",
      "866335: reward: 248.00, mean_100: 394.77, episodes: 2297, reward function loss: -0.0321\n",
      "866725: reward: 390.00, mean_100: 395.05, episodes: 2298, reward function loss: -0.0321\n",
      "867065: reward: 340.00, mean_100: 394.68, episodes: 2299, reward function loss: -0.0321\n",
      "867474: reward: 409.00, mean_100: 395.68, episodes: 2300, reward function loss: -0.0321\n",
      "867811: reward: 337.00, mean_100: 394.05, episodes: 2301, reward function loss: -0.0321\n",
      "868144: reward: 333.00, mean_100: 392.38, episodes: 2302, reward function loss: -0.0321\n",
      "868644: reward: 500.00, mean_100: 394.39, episodes: 2303, reward function loss: -0.0321\n",
      "869124: reward: 480.00, mean_100: 394.19, episodes: 2304, reward function loss: -0.0377\n",
      "869624: reward: 500.00, mean_100: 394.79, episodes: 2305, reward function loss: -0.0377\n",
      "870099: reward: 475.00, mean_100: 396.64, episodes: 2306, reward function loss: -0.0377\n",
      "870412: reward: 313.00, mean_100: 395.94, episodes: 2307, reward function loss: -0.0377\n",
      "870739: reward: 327.00, mean_100: 395.32, episodes: 2308, reward function loss: -0.0380\n",
      "871002: reward: 263.00, mean_100: 394.10, episodes: 2309, reward function loss: -0.0380\n",
      "871331: reward: 329.00, mean_100: 392.39, episodes: 2310, reward function loss: -0.0380\n",
      "871716: reward: 385.00, mean_100: 391.24, episodes: 2311, reward function loss: -0.0380\n",
      "872133: reward: 417.00, mean_100: 393.01, episodes: 2312, reward function loss: -0.0331\n",
      "872633: reward: 500.00, mean_100: 393.43, episodes: 2313, reward function loss: -0.0331\n",
      "872881: reward: 248.00, mean_100: 390.91, episodes: 2314, reward function loss: -0.0331\n",
      "873381: reward: 500.00, mean_100: 391.86, episodes: 2315, reward function loss: -0.0331\n",
      "873711: reward: 330.00, mean_100: 391.86, episodes: 2316, reward function loss: -0.0379\n",
      "874099: reward: 388.00, mean_100: 390.74, episodes: 2317, reward function loss: -0.0379\n",
      "874574: reward: 475.00, mean_100: 390.49, episodes: 2318, reward function loss: -0.0379\n",
      "874904: reward: 330.00, mean_100: 388.79, episodes: 2319, reward function loss: -0.0379\n",
      "875404: reward: 500.00, mean_100: 389.23, episodes: 2320, reward function loss: -0.0395\n",
      "875786: reward: 382.00, mean_100: 389.24, episodes: 2321, reward function loss: -0.0395\n",
      "876286: reward: 500.00, mean_100: 390.54, episodes: 2322, reward function loss: -0.0395\n",
      "876672: reward: 386.00, mean_100: 390.64, episodes: 2323, reward function loss: -0.0395\n",
      "877017: reward: 345.00, mean_100: 389.18, episodes: 2324, reward function loss: -0.0371\n",
      "877504: reward: 487.00, mean_100: 390.97, episodes: 2325, reward function loss: -0.0371\n",
      "878004: reward: 500.00, mean_100: 391.52, episodes: 2326, reward function loss: -0.0371\n",
      "878504: reward: 500.00, mean_100: 392.56, episodes: 2327, reward function loss: -0.0371\n",
      "878734: reward: 230.00, mean_100: 389.86, episodes: 2328, reward function loss: -0.0407\n",
      "879081: reward: 347.00, mean_100: 389.96, episodes: 2329, reward function loss: -0.0407\n",
      "879581: reward: 500.00, mean_100: 391.67, episodes: 2330, reward function loss: -0.0407\n",
      "879923: reward: 342.00, mean_100: 391.16, episodes: 2331, reward function loss: -0.0407\n",
      "880327: reward: 404.00, mean_100: 392.08, episodes: 2332, reward function loss: -0.0380\n",
      "880769: reward: 442.00, mean_100: 392.53, episodes: 2333, reward function loss: -0.0380\n",
      "881269: reward: 500.00, mean_100: 394.42, episodes: 2334, reward function loss: -0.0380\n",
      "881611: reward: 342.00, mean_100: 393.36, episodes: 2335, reward function loss: -0.0380\n",
      "881935: reward: 324.00, mean_100: 391.60, episodes: 2336, reward function loss: -0.0378\n",
      "882404: reward: 469.00, mean_100: 393.07, episodes: 2337, reward function loss: -0.0378\n",
      "882808: reward: 404.00, mean_100: 393.85, episodes: 2338, reward function loss: -0.0378\n",
      "883279: reward: 471.00, mean_100: 394.64, episodes: 2339, reward function loss: -0.0378\n",
      "883622: reward: 343.00, mean_100: 394.25, episodes: 2340, reward function loss: -0.0382\n",
      "884122: reward: 500.00, mean_100: 396.84, episodes: 2341, reward function loss: -0.0382\n",
      "884529: reward: 407.00, mean_100: 397.76, episodes: 2342, reward function loss: -0.0382\n",
      "884936: reward: 407.00, mean_100: 398.70, episodes: 2343, reward function loss: -0.0382\n",
      "885436: reward: 500.00, mean_100: 399.76, episodes: 2344, reward function loss: -0.0434\n",
      "885858: reward: 422.00, mean_100: 399.37, episodes: 2345, reward function loss: -0.0434\n",
      "886330: reward: 472.00, mean_100: 400.84, episodes: 2346, reward function loss: -0.0434\n",
      "886655: reward: 325.00, mean_100: 399.09, episodes: 2347, reward function loss: -0.0434\n",
      "887065: reward: 410.00, mean_100: 399.27, episodes: 2348, reward function loss: -0.0368\n",
      "887380: reward: 315.00, mean_100: 398.81, episodes: 2349, reward function loss: -0.0368\n",
      "887779: reward: 399.00, mean_100: 400.26, episodes: 2350, reward function loss: -0.0368\n",
      "888165: reward: 386.00, mean_100: 400.18, episodes: 2351, reward function loss: -0.0368\n",
      "888440: reward: 275.00, mean_100: 399.67, episodes: 2352, reward function loss: -0.0328\n",
      "888940: reward: 500.00, mean_100: 399.94, episodes: 2353, reward function loss: -0.0328\n",
      "889440: reward: 500.00, mean_100: 401.58, episodes: 2354, reward function loss: -0.0328\n",
      "889893: reward: 453.00, mean_100: 401.11, episodes: 2355, reward function loss: -0.0328\n",
      "890393: reward: 500.00, mean_100: 402.00, episodes: 2356, reward function loss: -0.0451\n",
      "890893: reward: 500.00, mean_100: 402.00, episodes: 2357, reward function loss: -0.0451\n",
      "891393: reward: 500.00, mean_100: 403.68, episodes: 2358, reward function loss: -0.0451\n",
      "891737: reward: 344.00, mean_100: 403.38, episodes: 2359, reward function loss: -0.0451\n",
      "892129: reward: 392.00, mean_100: 403.18, episodes: 2360, reward function loss: -0.0410\n",
      "892545: reward: 416.00, mean_100: 402.34, episodes: 2361, reward function loss: -0.0410\n",
      "892860: reward: 315.00, mean_100: 402.20, episodes: 2362, reward function loss: -0.0410\n",
      "893350: reward: 490.00, mean_100: 403.33, episodes: 2363, reward function loss: -0.0410\n",
      "893750: reward: 400.00, mean_100: 402.33, episodes: 2364, reward function loss: -0.0372\n",
      "894146: reward: 396.00, mean_100: 402.47, episodes: 2365, reward function loss: -0.0372\n",
      "894646: reward: 500.00, mean_100: 403.73, episodes: 2366, reward function loss: -0.0372\n",
      "894966: reward: 320.00, mean_100: 402.85, episodes: 2367, reward function loss: -0.0372\n",
      "895304: reward: 338.00, mean_100: 401.23, episodes: 2368, reward function loss: -0.0368\n",
      "895804: reward: 500.00, mean_100: 403.11, episodes: 2369, reward function loss: -0.0368\n",
      "896134: reward: 330.00, mean_100: 402.58, episodes: 2370, reward function loss: -0.0368\n",
      "896593: reward: 459.00, mean_100: 403.28, episodes: 2371, reward function loss: -0.0368\n",
      "897044: reward: 451.00, mean_100: 403.73, episodes: 2372, reward function loss: -0.0420\n",
      "897443: reward: 399.00, mean_100: 405.12, episodes: 2373, reward function loss: -0.0420\n",
      "897840: reward: 397.00, mean_100: 404.09, episodes: 2374, reward function loss: -0.0420\n",
      "898227: reward: 387.00, mean_100: 403.34, episodes: 2375, reward function loss: -0.0420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898727: reward: 500.00, mean_100: 404.92, episodes: 2376, reward function loss: -0.0402\n",
      "898996: reward: 269.00, mean_100: 403.92, episodes: 2377, reward function loss: -0.0402\n",
      "899494: reward: 498.00, mean_100: 404.93, episodes: 2378, reward function loss: -0.0402\n",
      "899914: reward: 420.00, mean_100: 405.33, episodes: 2379, reward function loss: -0.0402\n",
      "900394: reward: 480.00, mean_100: 405.13, episodes: 2380, reward function loss: -0.0371\n",
      "900894: reward: 500.00, mean_100: 406.29, episodes: 2381, reward function loss: -0.0371\n",
      "901291: reward: 397.00, mean_100: 406.51, episodes: 2382, reward function loss: -0.0371\n",
      "901773: reward: 482.00, mean_100: 406.74, episodes: 2383, reward function loss: -0.0371\n",
      "902273: reward: 500.00, mean_100: 408.43, episodes: 2384, reward function loss: -0.0443\n",
      "902773: reward: 500.00, mean_100: 410.23, episodes: 2385, reward function loss: -0.0443\n",
      "903273: reward: 500.00, mean_100: 411.50, episodes: 2386, reward function loss: -0.0443\n",
      "903773: reward: 500.00, mean_100: 411.59, episodes: 2387, reward function loss: -0.0443\n",
      "904220: reward: 447.00, mean_100: 411.06, episodes: 2388, reward function loss: -0.0462\n",
      "904649: reward: 429.00, mean_100: 411.32, episodes: 2389, reward function loss: -0.0462\n",
      "905149: reward: 500.00, mean_100: 411.32, episodes: 2390, reward function loss: -0.0462\n",
      "905584: reward: 435.00, mean_100: 411.64, episodes: 2391, reward function loss: -0.0462\n",
      "906084: reward: 500.00, mean_100: 413.42, episodes: 2392, reward function loss: -0.0444\n",
      "906496: reward: 412.00, mean_100: 414.10, episodes: 2393, reward function loss: -0.0444\n",
      "906868: reward: 372.00, mean_100: 413.95, episodes: 2394, reward function loss: -0.0444\n",
      "907295: reward: 427.00, mean_100: 415.79, episodes: 2395, reward function loss: -0.0444\n",
      "907795: reward: 500.00, mean_100: 417.08, episodes: 2396, reward function loss: -0.0381\n",
      "908213: reward: 418.00, mean_100: 418.78, episodes: 2397, reward function loss: -0.0381\n",
      "908713: reward: 500.00, mean_100: 419.88, episodes: 2398, reward function loss: -0.0381\n",
      "909210: reward: 497.00, mean_100: 421.45, episodes: 2399, reward function loss: -0.0381\n",
      "909710: reward: 500.00, mean_100: 422.36, episodes: 2400, reward function loss: -0.0438\n",
      "910210: reward: 500.00, mean_100: 423.99, episodes: 2401, reward function loss: -0.0438\n",
      "910710: reward: 500.00, mean_100: 425.66, episodes: 2402, reward function loss: -0.0438\n",
      "911210: reward: 500.00, mean_100: 425.66, episodes: 2403, reward function loss: -0.0438\n",
      "911710: reward: 500.00, mean_100: 425.86, episodes: 2404, reward function loss: -0.0453\n",
      "912210: reward: 500.00, mean_100: 425.86, episodes: 2405, reward function loss: -0.0453\n",
      "912710: reward: 500.00, mean_100: 426.11, episodes: 2406, reward function loss: -0.0453\n",
      "913210: reward: 500.00, mean_100: 427.98, episodes: 2407, reward function loss: -0.0453\n",
      "913581: reward: 371.00, mean_100: 428.42, episodes: 2408, reward function loss: -0.0450\n",
      "913997: reward: 416.00, mean_100: 429.95, episodes: 2409, reward function loss: -0.0450\n",
      "914300: reward: 303.00, mean_100: 429.69, episodes: 2410, reward function loss: -0.0450\n",
      "914695: reward: 395.00, mean_100: 429.79, episodes: 2411, reward function loss: -0.0450\n",
      "915195: reward: 500.00, mean_100: 430.62, episodes: 2412, reward function loss: -0.0378\n",
      "915695: reward: 500.00, mean_100: 430.62, episodes: 2413, reward function loss: -0.0378\n",
      "916195: reward: 500.00, mean_100: 433.14, episodes: 2414, reward function loss: -0.0378\n",
      "916617: reward: 422.00, mean_100: 432.36, episodes: 2415, reward function loss: -0.0378\n",
      "917117: reward: 500.00, mean_100: 434.06, episodes: 2416, reward function loss: -0.0453\n",
      "917617: reward: 500.00, mean_100: 435.18, episodes: 2417, reward function loss: -0.0453\n",
      "918050: reward: 433.00, mean_100: 434.76, episodes: 2418, reward function loss: -0.0453\n",
      "918500: reward: 450.00, mean_100: 435.96, episodes: 2419, reward function loss: -0.0453\n",
      "918937: reward: 437.00, mean_100: 435.33, episodes: 2420, reward function loss: -0.0407\n",
      "919336: reward: 399.00, mean_100: 435.50, episodes: 2421, reward function loss: -0.0407\n",
      "919730: reward: 394.00, mean_100: 434.44, episodes: 2422, reward function loss: -0.0407\n",
      "920230: reward: 500.00, mean_100: 435.58, episodes: 2423, reward function loss: -0.0407\n",
      "920730: reward: 500.00, mean_100: 437.13, episodes: 2424, reward function loss: -0.0423\n",
      "921230: reward: 500.00, mean_100: 437.26, episodes: 2425, reward function loss: -0.0423\n",
      "921582: reward: 352.00, mean_100: 435.78, episodes: 2426, reward function loss: -0.0423\n",
      "922067: reward: 485.00, mean_100: 435.63, episodes: 2427, reward function loss: -0.0423\n",
      "922567: reward: 500.00, mean_100: 438.33, episodes: 2428, reward function loss: -0.0399\n",
      "923067: reward: 500.00, mean_100: 439.86, episodes: 2429, reward function loss: -0.0399\n",
      "923567: reward: 500.00, mean_100: 439.86, episodes: 2430, reward function loss: -0.0399\n",
      "923921: reward: 354.00, mean_100: 439.98, episodes: 2431, reward function loss: -0.0399\n",
      "924421: reward: 500.00, mean_100: 440.94, episodes: 2432, reward function loss: -0.0438\n",
      "924797: reward: 376.00, mean_100: 440.28, episodes: 2433, reward function loss: -0.0438\n",
      "925227: reward: 430.00, mean_100: 439.58, episodes: 2434, reward function loss: -0.0438\n",
      "925556: reward: 329.00, mean_100: 439.45, episodes: 2435, reward function loss: -0.0438\n",
      "926045: reward: 489.00, mean_100: 441.10, episodes: 2436, reward function loss: -0.0348\n",
      "926545: reward: 500.00, mean_100: 441.41, episodes: 2437, reward function loss: -0.0348\n",
      "927045: reward: 500.00, mean_100: 442.37, episodes: 2438, reward function loss: -0.0348\n",
      "927545: reward: 500.00, mean_100: 442.66, episodes: 2439, reward function loss: -0.0348\n",
      "928045: reward: 500.00, mean_100: 444.23, episodes: 2440, reward function loss: -0.0439\n",
      "928545: reward: 500.00, mean_100: 444.23, episodes: 2441, reward function loss: -0.0439\n",
      "929045: reward: 500.00, mean_100: 445.16, episodes: 2442, reward function loss: -0.0439\n",
      "929545: reward: 500.00, mean_100: 446.09, episodes: 2443, reward function loss: -0.0439\n",
      "929894: reward: 349.00, mean_100: 444.58, episodes: 2444, reward function loss: -0.0437\n",
      "930288: reward: 394.00, mean_100: 444.30, episodes: 2445, reward function loss: -0.0437\n",
      "930725: reward: 437.00, mean_100: 443.95, episodes: 2446, reward function loss: -0.0437\n",
      "931225: reward: 500.00, mean_100: 445.70, episodes: 2447, reward function loss: -0.0437\n",
      "931725: reward: 500.00, mean_100: 446.60, episodes: 2448, reward function loss: -0.0377\n",
      "932225: reward: 500.00, mean_100: 448.45, episodes: 2449, reward function loss: -0.0377\n",
      "932725: reward: 500.00, mean_100: 449.46, episodes: 2450, reward function loss: -0.0377\n",
      "933096: reward: 371.00, mean_100: 449.31, episodes: 2451, reward function loss: -0.0377\n",
      "933596: reward: 500.00, mean_100: 451.56, episodes: 2452, reward function loss: -0.0423\n",
      "934006: reward: 410.00, mean_100: 450.66, episodes: 2453, reward function loss: -0.0423\n",
      "934465: reward: 459.00, mean_100: 450.25, episodes: 2454, reward function loss: -0.0423\n",
      "934844: reward: 379.00, mean_100: 449.51, episodes: 2455, reward function loss: -0.0423\n",
      "935344: reward: 500.00, mean_100: 449.51, episodes: 2456, reward function loss: -0.0383\n",
      "935844: reward: 500.00, mean_100: 449.51, episodes: 2457, reward function loss: -0.0383\n",
      "936211: reward: 367.00, mean_100: 448.18, episodes: 2458, reward function loss: -0.0383\n",
      "936711: reward: 500.00, mean_100: 449.74, episodes: 2459, reward function loss: -0.0383\n",
      "937127: reward: 416.00, mean_100: 449.98, episodes: 2460, reward function loss: -0.0424\n",
      "937627: reward: 500.00, mean_100: 450.82, episodes: 2461, reward function loss: -0.0424\n",
      "938127: reward: 500.00, mean_100: 452.67, episodes: 2462, reward function loss: -0.0424\n",
      "938575: reward: 448.00, mean_100: 452.25, episodes: 2463, reward function loss: -0.0424\n",
      "938960: reward: 385.00, mean_100: 452.10, episodes: 2464, reward function loss: -0.0418\n",
      "939338: reward: 378.00, mean_100: 451.92, episodes: 2465, reward function loss: -0.0418\n",
      "939838: reward: 500.00, mean_100: 451.92, episodes: 2466, reward function loss: -0.0418\n",
      "940238: reward: 400.00, mean_100: 452.72, episodes: 2467, reward function loss: -0.0418\n",
      "940738: reward: 500.00, mean_100: 454.34, episodes: 2468, reward function loss: -0.0380\n",
      "941238: reward: 500.00, mean_100: 454.34, episodes: 2469, reward function loss: -0.0380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941667: reward: 429.00, mean_100: 455.33, episodes: 2470, reward function loss: -0.0380\n",
      "942167: reward: 500.00, mean_100: 455.74, episodes: 2471, reward function loss: -0.0380\n",
      "942667: reward: 500.00, mean_100: 456.23, episodes: 2472, reward function loss: -0.0387\n",
      "943167: reward: 500.00, mean_100: 457.24, episodes: 2473, reward function loss: -0.0387\n",
      "943667: reward: 500.00, mean_100: 458.27, episodes: 2474, reward function loss: -0.0387\n",
      "944167: reward: 500.00, mean_100: 459.40, episodes: 2475, reward function loss: -0.0387\n",
      "944515: reward: 348.00, mean_100: 457.88, episodes: 2476, reward function loss: -0.0359\n",
      "945015: reward: 500.00, mean_100: 460.19, episodes: 2477, reward function loss: -0.0359\n",
      "945515: reward: 500.00, mean_100: 460.21, episodes: 2478, reward function loss: -0.0359\n",
      "946015: reward: 500.00, mean_100: 461.01, episodes: 2479, reward function loss: -0.0359\n",
      "946481: reward: 466.00, mean_100: 460.87, episodes: 2480, reward function loss: -0.0375\n",
      "946981: reward: 500.00, mean_100: 460.87, episodes: 2481, reward function loss: -0.0375\n",
      "947481: reward: 500.00, mean_100: 461.90, episodes: 2482, reward function loss: -0.0375\n",
      "947981: reward: 500.00, mean_100: 462.08, episodes: 2483, reward function loss: -0.0375\n",
      "948481: reward: 500.00, mean_100: 462.08, episodes: 2484, reward function loss: -0.0416\n",
      "948981: reward: 500.00, mean_100: 462.08, episodes: 2485, reward function loss: -0.0416\n",
      "949481: reward: 500.00, mean_100: 462.08, episodes: 2486, reward function loss: -0.0416\n",
      "949981: reward: 500.00, mean_100: 462.08, episodes: 2487, reward function loss: -0.0416\n",
      "950481: reward: 500.00, mean_100: 462.61, episodes: 2488, reward function loss: -0.0455\n",
      "950981: reward: 500.00, mean_100: 463.32, episodes: 2489, reward function loss: -0.0455\n",
      "951481: reward: 500.00, mean_100: 463.32, episodes: 2490, reward function loss: -0.0455\n",
      "951981: reward: 500.00, mean_100: 463.97, episodes: 2491, reward function loss: -0.0455\n",
      "952481: reward: 500.00, mean_100: 463.97, episodes: 2492, reward function loss: -0.0308\n",
      "952981: reward: 500.00, mean_100: 464.85, episodes: 2493, reward function loss: -0.0308\n",
      "953481: reward: 500.00, mean_100: 466.13, episodes: 2494, reward function loss: -0.0308\n",
      "953981: reward: 500.00, mean_100: 466.86, episodes: 2495, reward function loss: -0.0308\n",
      "954481: reward: 500.00, mean_100: 466.86, episodes: 2496, reward function loss: -0.0315\n",
      "954981: reward: 500.00, mean_100: 467.68, episodes: 2497, reward function loss: -0.0315\n",
      "955481: reward: 500.00, mean_100: 467.68, episodes: 2498, reward function loss: -0.0315\n",
      "955981: reward: 500.00, mean_100: 467.71, episodes: 2499, reward function loss: -0.0315\n",
      "956356: reward: 375.00, mean_100: 466.46, episodes: 2500, reward function loss: -0.0210\n",
      "956856: reward: 500.00, mean_100: 466.46, episodes: 2501, reward function loss: -0.0210\n",
      "957356: reward: 500.00, mean_100: 466.46, episodes: 2502, reward function loss: -0.0210\n",
      "957856: reward: 500.00, mean_100: 466.46, episodes: 2503, reward function loss: -0.0210\n",
      "958329: reward: 473.00, mean_100: 466.19, episodes: 2504, reward function loss: -0.0374\n",
      "958829: reward: 500.00, mean_100: 466.19, episodes: 2505, reward function loss: -0.0374\n",
      "959329: reward: 500.00, mean_100: 466.19, episodes: 2506, reward function loss: -0.0374\n",
      "959829: reward: 500.00, mean_100: 466.19, episodes: 2507, reward function loss: -0.0374\n",
      "960310: reward: 481.00, mean_100: 467.29, episodes: 2508, reward function loss: -0.0387\n",
      "960810: reward: 500.00, mean_100: 468.13, episodes: 2509, reward function loss: -0.0387\n",
      "961310: reward: 500.00, mean_100: 470.10, episodes: 2510, reward function loss: -0.0387\n",
      "961711: reward: 401.00, mean_100: 470.16, episodes: 2511, reward function loss: -0.0387\n",
      "962211: reward: 500.00, mean_100: 470.16, episodes: 2512, reward function loss: -0.0173\n",
      "962711: reward: 500.00, mean_100: 470.16, episodes: 2513, reward function loss: -0.0173\n",
      "963211: reward: 500.00, mean_100: 470.16, episodes: 2514, reward function loss: -0.0173\n",
      "963711: reward: 500.00, mean_100: 470.94, episodes: 2515, reward function loss: -0.0173\n",
      "964120: reward: 409.00, mean_100: 470.03, episodes: 2516, reward function loss: -0.0281\n",
      "964620: reward: 500.00, mean_100: 470.03, episodes: 2517, reward function loss: -0.0281\n",
      "965120: reward: 500.00, mean_100: 470.70, episodes: 2518, reward function loss: -0.0281\n",
      "965494: reward: 374.00, mean_100: 469.94, episodes: 2519, reward function loss: -0.0281\n",
      "965815: reward: 321.00, mean_100: 468.78, episodes: 2520, reward function loss: -0.0040\n",
      "966315: reward: 500.00, mean_100: 469.79, episodes: 2521, reward function loss: -0.0040\n",
      "966757: reward: 442.00, mean_100: 470.27, episodes: 2522, reward function loss: -0.0040\n",
      "967132: reward: 375.00, mean_100: 469.02, episodes: 2523, reward function loss: -0.0040\n",
      "967567: reward: 435.00, mean_100: 468.37, episodes: 2524, reward function loss: -0.0064\n",
      "968050: reward: 483.00, mean_100: 468.20, episodes: 2525, reward function loss: -0.0064\n",
      "968524: reward: 474.00, mean_100: 469.42, episodes: 2526, reward function loss: -0.0064\n",
      "968904: reward: 380.00, mean_100: 468.37, episodes: 2527, reward function loss: -0.0064\n",
      "969281: reward: 377.00, mean_100: 467.14, episodes: 2528, reward function loss: -0.0088\n",
      "969643: reward: 362.00, mean_100: 465.76, episodes: 2529, reward function loss: -0.0088\n",
      "969856: reward: 213.00, mean_100: 462.89, episodes: 2530, reward function loss: -0.0088\n",
      "970157: reward: 301.00, mean_100: 462.36, episodes: 2531, reward function loss: -0.0088\n",
      "970542: reward: 385.00, mean_100: 461.21, episodes: 2532, reward function loss: -0.0079\n",
      "970826: reward: 284.00, mean_100: 460.29, episodes: 2533, reward function loss: -0.0079\n",
      "971226: reward: 400.00, mean_100: 459.99, episodes: 2534, reward function loss: -0.0079\n",
      "971706: reward: 480.00, mean_100: 461.50, episodes: 2535, reward function loss: -0.0079\n",
      "972190: reward: 484.00, mean_100: 461.45, episodes: 2536, reward function loss: -0.0070\n",
      "972400: reward: 210.00, mean_100: 458.55, episodes: 2537, reward function loss: -0.0070\n",
      "972617: reward: 217.00, mean_100: 455.72, episodes: 2538, reward function loss: -0.0070\n",
      "972922: reward: 305.00, mean_100: 453.77, episodes: 2539, reward function loss: -0.0070\n",
      "973236: reward: 314.00, mean_100: 451.91, episodes: 2540, reward function loss: -0.0010\n",
      "973531: reward: 295.00, mean_100: 449.86, episodes: 2541, reward function loss: -0.0010\n",
      "973847: reward: 316.00, mean_100: 448.02, episodes: 2542, reward function loss: -0.0010\n",
      "974242: reward: 395.00, mean_100: 446.97, episodes: 2543, reward function loss: -0.0010\n",
      "974558: reward: 316.00, mean_100: 446.64, episodes: 2544, reward function loss: -0.0033\n",
      "974872: reward: 314.00, mean_100: 445.84, episodes: 2545, reward function loss: -0.0033\n",
      "975200: reward: 328.00, mean_100: 444.75, episodes: 2546, reward function loss: -0.0033\n",
      "975695: reward: 495.00, mean_100: 444.70, episodes: 2547, reward function loss: -0.0033\n",
      "976010: reward: 315.00, mean_100: 442.85, episodes: 2548, reward function loss: -0.0018\n",
      "976510: reward: 500.00, mean_100: 442.85, episodes: 2549, reward function loss: -0.0018\n",
      "976831: reward: 321.00, mean_100: 441.06, episodes: 2550, reward function loss: -0.0018\n",
      "977331: reward: 500.00, mean_100: 442.35, episodes: 2551, reward function loss: -0.0018\n",
      "977831: reward: 500.00, mean_100: 442.35, episodes: 2552, reward function loss: -0.0047\n",
      "978331: reward: 500.00, mean_100: 443.25, episodes: 2553, reward function loss: -0.0047\n",
      "978831: reward: 500.00, mean_100: 443.66, episodes: 2554, reward function loss: -0.0047\n",
      "979331: reward: 500.00, mean_100: 444.87, episodes: 2555, reward function loss: -0.0047\n",
      "979831: reward: 500.00, mean_100: 444.87, episodes: 2556, reward function loss: -0.0083\n",
      "980331: reward: 500.00, mean_100: 444.87, episodes: 2557, reward function loss: -0.0083\n",
      "980831: reward: 500.00, mean_100: 446.20, episodes: 2558, reward function loss: -0.0083\n",
      "981331: reward: 500.00, mean_100: 446.20, episodes: 2559, reward function loss: -0.0083\n",
      "981831: reward: 500.00, mean_100: 447.04, episodes: 2560, reward function loss: -0.0165\n",
      "982331: reward: 500.00, mean_100: 447.04, episodes: 2561, reward function loss: -0.0165\n",
      "982831: reward: 500.00, mean_100: 447.04, episodes: 2562, reward function loss: -0.0165\n",
      "983331: reward: 500.00, mean_100: 447.56, episodes: 2563, reward function loss: -0.0165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983831: reward: 500.00, mean_100: 448.71, episodes: 2564, reward function loss: -0.0345\n",
      "984331: reward: 500.00, mean_100: 449.93, episodes: 2565, reward function loss: -0.0345\n",
      "984831: reward: 500.00, mean_100: 449.93, episodes: 2566, reward function loss: -0.0345\n",
      "985331: reward: 500.00, mean_100: 450.93, episodes: 2567, reward function loss: -0.0345\n",
      "985831: reward: 500.00, mean_100: 450.93, episodes: 2568, reward function loss: -0.0422\n",
      "986331: reward: 500.00, mean_100: 450.93, episodes: 2569, reward function loss: -0.0422\n",
      "986831: reward: 500.00, mean_100: 451.64, episodes: 2570, reward function loss: -0.0422\n",
      "987331: reward: 500.00, mean_100: 451.64, episodes: 2571, reward function loss: -0.0422\n",
      "987831: reward: 500.00, mean_100: 451.64, episodes: 2572, reward function loss: -0.0434\n",
      "988331: reward: 500.00, mean_100: 451.64, episodes: 2573, reward function loss: -0.0434\n",
      "988831: reward: 500.00, mean_100: 451.64, episodes: 2574, reward function loss: -0.0434\n",
      "989331: reward: 500.00, mean_100: 451.64, episodes: 2575, reward function loss: -0.0434\n",
      "989831: reward: 500.00, mean_100: 453.16, episodes: 2576, reward function loss: -0.0427\n",
      "990331: reward: 500.00, mean_100: 453.16, episodes: 2577, reward function loss: -0.0427\n",
      "990831: reward: 500.00, mean_100: 453.16, episodes: 2578, reward function loss: -0.0427\n",
      "991331: reward: 500.00, mean_100: 453.16, episodes: 2579, reward function loss: -0.0427\n",
      "991831: reward: 500.00, mean_100: 453.50, episodes: 2580, reward function loss: -0.0419\n",
      "992331: reward: 500.00, mean_100: 453.50, episodes: 2581, reward function loss: -0.0419\n",
      "992831: reward: 500.00, mean_100: 453.50, episodes: 2582, reward function loss: -0.0419\n",
      "993331: reward: 500.00, mean_100: 453.50, episodes: 2583, reward function loss: -0.0419\n",
      "993831: reward: 500.00, mean_100: 453.50, episodes: 2584, reward function loss: -0.0428\n",
      "994331: reward: 500.00, mean_100: 453.50, episodes: 2585, reward function loss: -0.0428\n",
      "994831: reward: 500.00, mean_100: 453.50, episodes: 2586, reward function loss: -0.0428\n",
      "995331: reward: 500.00, mean_100: 453.50, episodes: 2587, reward function loss: -0.0428\n",
      "995831: reward: 500.00, mean_100: 453.50, episodes: 2588, reward function loss: -0.0433\n",
      "996331: reward: 500.00, mean_100: 453.50, episodes: 2589, reward function loss: -0.0433\n",
      "996831: reward: 500.00, mean_100: 453.50, episodes: 2590, reward function loss: -0.0433\n",
      "996974: reward: 143.00, mean_100: 449.93, episodes: 2591, reward function loss: -0.0433\n",
      "997474: reward: 500.00, mean_100: 449.93, episodes: 2592, reward function loss: -0.0350\n",
      "997974: reward: 500.00, mean_100: 449.93, episodes: 2593, reward function loss: -0.0350\n",
      "998474: reward: 500.00, mean_100: 449.93, episodes: 2594, reward function loss: -0.0350\n",
      "998974: reward: 500.00, mean_100: 449.93, episodes: 2595, reward function loss: -0.0350\n",
      "999474: reward: 500.00, mean_100: 449.93, episodes: 2596, reward function loss: -0.0436\n",
      "999974: reward: 500.00, mean_100: 449.93, episodes: 2597, reward function loss: -0.0436\n",
      "1000474: reward: 500.00, mean_100: 449.93, episodes: 2598, reward function loss: -0.0436\n",
      "1000630: reward: 156.00, mean_100: 446.49, episodes: 2599, reward function loss: -0.0436\n",
      "1001130: reward: 500.00, mean_100: 447.74, episodes: 2600, reward function loss: -0.0348\n",
      "1001630: reward: 500.00, mean_100: 447.74, episodes: 2601, reward function loss: -0.0348\n",
      "1002130: reward: 500.00, mean_100: 447.74, episodes: 2602, reward function loss: -0.0348\n",
      "1002630: reward: 500.00, mean_100: 447.74, episodes: 2603, reward function loss: -0.0348\n",
      "1002782: reward: 152.00, mean_100: 444.53, episodes: 2604, reward function loss: -0.0359\n",
      "1003282: reward: 500.00, mean_100: 444.53, episodes: 2605, reward function loss: -0.0359\n",
      "1003782: reward: 500.00, mean_100: 444.53, episodes: 2606, reward function loss: -0.0359\n",
      "1004282: reward: 500.00, mean_100: 444.53, episodes: 2607, reward function loss: -0.0359\n",
      "1004431: reward: 149.00, mean_100: 441.21, episodes: 2608, reward function loss: -0.0351\n",
      "1004588: reward: 157.00, mean_100: 437.78, episodes: 2609, reward function loss: -0.0351\n",
      "1005088: reward: 500.00, mean_100: 437.78, episodes: 2610, reward function loss: -0.0351\n",
      "1005588: reward: 500.00, mean_100: 438.77, episodes: 2611, reward function loss: -0.0351\n",
      "1006088: reward: 500.00, mean_100: 438.77, episodes: 2612, reward function loss: -0.0365\n",
      "1006588: reward: 500.00, mean_100: 438.77, episodes: 2613, reward function loss: -0.0365\n",
      "1007088: reward: 500.00, mean_100: 438.77, episodes: 2614, reward function loss: -0.0365\n",
      "1007588: reward: 500.00, mean_100: 438.77, episodes: 2615, reward function loss: -0.0365\n",
      "1008088: reward: 500.00, mean_100: 439.68, episodes: 2616, reward function loss: -0.0421\n",
      "1008588: reward: 500.00, mean_100: 439.68, episodes: 2617, reward function loss: -0.0421\n",
      "1008739: reward: 151.00, mean_100: 436.19, episodes: 2618, reward function loss: -0.0421\n",
      "1009239: reward: 500.00, mean_100: 437.45, episodes: 2619, reward function loss: -0.0421\n",
      "1009739: reward: 500.00, mean_100: 439.24, episodes: 2620, reward function loss: -0.0351\n",
      "1010239: reward: 500.00, mean_100: 439.24, episodes: 2621, reward function loss: -0.0351\n",
      "1010739: reward: 500.00, mean_100: 439.82, episodes: 2622, reward function loss: -0.0351\n",
      "1010870: reward: 131.00, mean_100: 437.38, episodes: 2623, reward function loss: -0.0351\n",
      "1011370: reward: 500.00, mean_100: 438.03, episodes: 2624, reward function loss: -0.0357\n",
      "1011870: reward: 500.00, mean_100: 438.20, episodes: 2625, reward function loss: -0.0357\n",
      "1012014: reward: 144.00, mean_100: 434.90, episodes: 2626, reward function loss: -0.0357\n",
      "1012168: reward: 154.00, mean_100: 432.64, episodes: 2627, reward function loss: -0.0357\n",
      "1012668: reward: 500.00, mean_100: 433.87, episodes: 2628, reward function loss: -0.0282\n",
      "1013168: reward: 500.00, mean_100: 435.25, episodes: 2629, reward function loss: -0.0282\n",
      "1013311: reward: 143.00, mean_100: 434.55, episodes: 2630, reward function loss: -0.0282\n",
      "1013811: reward: 500.00, mean_100: 436.54, episodes: 2631, reward function loss: -0.0282\n",
      "1013949: reward: 138.00, mean_100: 434.07, episodes: 2632, reward function loss: -0.0277\n",
      "1014095: reward: 146.00, mean_100: 432.69, episodes: 2633, reward function loss: -0.0277\n",
      "1014254: reward: 159.00, mean_100: 430.28, episodes: 2634, reward function loss: -0.0277\n",
      "1014404: reward: 150.00, mean_100: 426.98, episodes: 2635, reward function loss: -0.0277\n",
      "1014548: reward: 144.00, mean_100: 423.58, episodes: 2636, reward function loss: -0.0111\n",
      "1014700: reward: 152.00, mean_100: 423.00, episodes: 2637, reward function loss: -0.0111\n",
      "1014836: reward: 136.00, mean_100: 422.19, episodes: 2638, reward function loss: -0.0111\n",
      "1015336: reward: 500.00, mean_100: 424.14, episodes: 2639, reward function loss: -0.0111\n",
      "1015483: reward: 147.00, mean_100: 422.47, episodes: 2640, reward function loss: -0.0201\n",
      "1015617: reward: 134.00, mean_100: 420.86, episodes: 2641, reward function loss: -0.0201\n",
      "1015766: reward: 149.00, mean_100: 419.19, episodes: 2642, reward function loss: -0.0201\n",
      "1016266: reward: 500.00, mean_100: 420.24, episodes: 2643, reward function loss: -0.0201\n",
      "1016421: reward: 155.00, mean_100: 418.63, episodes: 2644, reward function loss: -0.0197\n",
      "1016559: reward: 138.00, mean_100: 416.87, episodes: 2645, reward function loss: -0.0197\n",
      "1016698: reward: 139.00, mean_100: 414.98, episodes: 2646, reward function loss: -0.0197\n",
      "1016843: reward: 145.00, mean_100: 411.48, episodes: 2647, reward function loss: -0.0197\n",
      "1017005: reward: 162.00, mean_100: 409.95, episodes: 2648, reward function loss: -0.0111\n",
      "1017146: reward: 141.00, mean_100: 406.36, episodes: 2649, reward function loss: -0.0111\n",
      "1017646: reward: 500.00, mean_100: 408.15, episodes: 2650, reward function loss: -0.0111\n",
      "1017809: reward: 163.00, mean_100: 404.78, episodes: 2651, reward function loss: -0.0111\n",
      "1018309: reward: 500.00, mean_100: 404.78, episodes: 2652, reward function loss: -0.0288\n",
      "1018455: reward: 146.00, mean_100: 401.24, episodes: 2653, reward function loss: -0.0288\n",
      "1018620: reward: 165.00, mean_100: 397.89, episodes: 2654, reward function loss: -0.0288\n",
      "1018768: reward: 148.00, mean_100: 394.37, episodes: 2655, reward function loss: -0.0288\n",
      "1019268: reward: 500.00, mean_100: 394.37, episodes: 2656, reward function loss: -0.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019768: reward: 500.00, mean_100: 394.37, episodes: 2657, reward function loss: -0.0193\n",
      "1019923: reward: 155.00, mean_100: 390.92, episodes: 2658, reward function loss: -0.0193\n",
      "1020423: reward: 500.00, mean_100: 390.92, episodes: 2659, reward function loss: -0.0193\n",
      "1020579: reward: 156.00, mean_100: 387.48, episodes: 2660, reward function loss: -0.0288\n",
      "1021079: reward: 500.00, mean_100: 387.48, episodes: 2661, reward function loss: -0.0288\n",
      "1021579: reward: 500.00, mean_100: 387.48, episodes: 2662, reward function loss: -0.0288\n",
      "1021729: reward: 150.00, mean_100: 383.98, episodes: 2663, reward function loss: -0.0288\n",
      "1021883: reward: 154.00, mean_100: 380.52, episodes: 2664, reward function loss: -0.0288\n",
      "1022041: reward: 158.00, mean_100: 377.10, episodes: 2665, reward function loss: -0.0288\n",
      "1022541: reward: 500.00, mean_100: 377.10, episodes: 2666, reward function loss: -0.0288\n",
      "1023041: reward: 500.00, mean_100: 377.10, episodes: 2667, reward function loss: -0.0288\n",
      "1023541: reward: 500.00, mean_100: 377.10, episodes: 2668, reward function loss: -0.0365\n",
      "1023708: reward: 167.00, mean_100: 373.77, episodes: 2669, reward function loss: -0.0365\n",
      "1023855: reward: 147.00, mean_100: 370.24, episodes: 2670, reward function loss: -0.0365\n",
      "1023999: reward: 144.00, mean_100: 366.68, episodes: 2671, reward function loss: -0.0365\n",
      "1024149: reward: 150.00, mean_100: 363.18, episodes: 2672, reward function loss: -0.0115\n",
      "1024649: reward: 500.00, mean_100: 363.18, episodes: 2673, reward function loss: -0.0115\n",
      "1024802: reward: 153.00, mean_100: 359.71, episodes: 2674, reward function loss: -0.0115\n",
      "1024935: reward: 133.00, mean_100: 356.04, episodes: 2675, reward function loss: -0.0115\n",
      "1025070: reward: 135.00, mean_100: 352.39, episodes: 2676, reward function loss: -0.0197\n",
      "1025222: reward: 152.00, mean_100: 348.91, episodes: 2677, reward function loss: -0.0197\n",
      "1025362: reward: 140.00, mean_100: 345.31, episodes: 2678, reward function loss: -0.0197\n",
      "1025532: reward: 170.00, mean_100: 342.01, episodes: 2679, reward function loss: -0.0197\n",
      "1025677: reward: 145.00, mean_100: 338.46, episodes: 2680, reward function loss: -0.0122\n",
      "1025839: reward: 162.00, mean_100: 335.08, episodes: 2681, reward function loss: -0.0122\n",
      "1025969: reward: 130.00, mean_100: 331.38, episodes: 2682, reward function loss: -0.0122\n",
      "1026469: reward: 500.00, mean_100: 331.38, episodes: 2683, reward function loss: -0.0122\n",
      "1026597: reward: 128.00, mean_100: 327.66, episodes: 2684, reward function loss: -0.0203\n",
      "1027097: reward: 500.00, mean_100: 327.66, episodes: 2685, reward function loss: -0.0203\n",
      "1027236: reward: 139.00, mean_100: 324.05, episodes: 2686, reward function loss: -0.0203\n",
      "1027736: reward: 500.00, mean_100: 324.05, episodes: 2687, reward function loss: -0.0203\n",
      "1027886: reward: 150.00, mean_100: 320.55, episodes: 2688, reward function loss: -0.0287\n",
      "1028386: reward: 500.00, mean_100: 320.55, episodes: 2689, reward function loss: -0.0287\n",
      "1028529: reward: 143.00, mean_100: 316.98, episodes: 2690, reward function loss: -0.0287\n",
      "1028693: reward: 164.00, mean_100: 317.19, episodes: 2691, reward function loss: -0.0287\n",
      "1028841: reward: 148.00, mean_100: 313.67, episodes: 2692, reward function loss: -0.0201\n",
      "1029341: reward: 500.00, mean_100: 313.67, episodes: 2693, reward function loss: -0.0201\n",
      "1029488: reward: 147.00, mean_100: 310.14, episodes: 2694, reward function loss: -0.0201\n",
      "1029670: reward: 182.00, mean_100: 306.96, episodes: 2695, reward function loss: -0.0201\n",
      "1030170: reward: 500.00, mean_100: 306.96, episodes: 2696, reward function loss: -0.0297\n",
      "1030328: reward: 158.00, mean_100: 303.54, episodes: 2697, reward function loss: -0.0297\n",
      "1030488: reward: 160.00, mean_100: 300.14, episodes: 2698, reward function loss: -0.0297\n",
      "1030647: reward: 159.00, mean_100: 300.17, episodes: 2699, reward function loss: -0.0297\n",
      "1031147: reward: 500.00, mean_100: 300.17, episodes: 2700, reward function loss: -0.0185\n",
      "1031310: reward: 163.00, mean_100: 296.80, episodes: 2701, reward function loss: -0.0185\n",
      "1031810: reward: 500.00, mean_100: 296.80, episodes: 2702, reward function loss: -0.0185\n",
      "1031962: reward: 152.00, mean_100: 293.32, episodes: 2703, reward function loss: -0.0185\n",
      "1032108: reward: 146.00, mean_100: 293.26, episodes: 2704, reward function loss: -0.0193\n",
      "1032608: reward: 500.00, mean_100: 293.26, episodes: 2705, reward function loss: -0.0193\n",
      "1032761: reward: 153.00, mean_100: 289.79, episodes: 2706, reward function loss: -0.0193\n",
      "1033261: reward: 500.00, mean_100: 289.79, episodes: 2707, reward function loss: -0.0193\n",
      "1033761: reward: 500.00, mean_100: 293.30, episodes: 2708, reward function loss: -0.0360\n",
      "1034261: reward: 500.00, mean_100: 296.73, episodes: 2709, reward function loss: -0.0360\n",
      "1034411: reward: 150.00, mean_100: 293.23, episodes: 2710, reward function loss: -0.0360\n",
      "1034591: reward: 180.00, mean_100: 290.03, episodes: 2711, reward function loss: -0.0360\n",
      "1034747: reward: 156.00, mean_100: 286.59, episodes: 2712, reward function loss: -0.0208\n",
      "1035247: reward: 500.00, mean_100: 286.59, episodes: 2713, reward function loss: -0.0208\n",
      "1035747: reward: 500.00, mean_100: 286.59, episodes: 2714, reward function loss: -0.0208\n",
      "1036247: reward: 500.00, mean_100: 286.59, episodes: 2715, reward function loss: -0.0208\n",
      "1036747: reward: 500.00, mean_100: 286.59, episodes: 2716, reward function loss: -0.0447\n",
      "1037247: reward: 500.00, mean_100: 286.59, episodes: 2717, reward function loss: -0.0447\n",
      "1037426: reward: 179.00, mean_100: 286.87, episodes: 2718, reward function loss: -0.0447\n",
      "1037926: reward: 500.00, mean_100: 286.87, episodes: 2719, reward function loss: -0.0447\n",
      "1038426: reward: 500.00, mean_100: 286.87, episodes: 2720, reward function loss: -0.0364\n",
      "1038926: reward: 500.00, mean_100: 286.87, episodes: 2721, reward function loss: -0.0364\n",
      "1039426: reward: 500.00, mean_100: 286.87, episodes: 2722, reward function loss: -0.0364\n",
      "1039926: reward: 500.00, mean_100: 290.56, episodes: 2723, reward function loss: -0.0364\n",
      "1040426: reward: 500.00, mean_100: 290.56, episodes: 2724, reward function loss: -0.0446\n",
      "1040926: reward: 500.00, mean_100: 290.56, episodes: 2725, reward function loss: -0.0446\n",
      "1041426: reward: 500.00, mean_100: 294.12, episodes: 2726, reward function loss: -0.0446\n",
      "1041926: reward: 500.00, mean_100: 297.58, episodes: 2727, reward function loss: -0.0446\n",
      "1042426: reward: 500.00, mean_100: 297.58, episodes: 2728, reward function loss: -0.0443\n",
      "1042926: reward: 500.00, mean_100: 297.58, episodes: 2729, reward function loss: -0.0443\n",
      "1043426: reward: 500.00, mean_100: 301.15, episodes: 2730, reward function loss: -0.0443\n",
      "1043926: reward: 500.00, mean_100: 301.15, episodes: 2731, reward function loss: -0.0443\n",
      "1044426: reward: 500.00, mean_100: 304.77, episodes: 2732, reward function loss: -0.0450\n",
      "1044926: reward: 500.00, mean_100: 308.31, episodes: 2733, reward function loss: -0.0450\n",
      "1045426: reward: 500.00, mean_100: 311.72, episodes: 2734, reward function loss: -0.0450\n",
      "1045926: reward: 500.00, mean_100: 315.22, episodes: 2735, reward function loss: -0.0450\n",
      "1046426: reward: 500.00, mean_100: 318.78, episodes: 2736, reward function loss: -0.0434\n",
      "1046926: reward: 500.00, mean_100: 322.26, episodes: 2737, reward function loss: -0.0434\n",
      "1047426: reward: 500.00, mean_100: 325.90, episodes: 2738, reward function loss: -0.0434\n",
      "1047926: reward: 500.00, mean_100: 325.90, episodes: 2739, reward function loss: -0.0434\n",
      "1048426: reward: 500.00, mean_100: 329.43, episodes: 2740, reward function loss: -0.0446\n",
      "1048926: reward: 500.00, mean_100: 333.09, episodes: 2741, reward function loss: -0.0446\n",
      "1049426: reward: 500.00, mean_100: 336.60, episodes: 2742, reward function loss: -0.0446\n",
      "1049926: reward: 500.00, mean_100: 336.60, episodes: 2743, reward function loss: -0.0446\n",
      "1050426: reward: 500.00, mean_100: 340.05, episodes: 2744, reward function loss: -0.0435\n",
      "1050926: reward: 500.00, mean_100: 343.67, episodes: 2745, reward function loss: -0.0435\n",
      "1051426: reward: 500.00, mean_100: 347.28, episodes: 2746, reward function loss: -0.0435\n",
      "1051926: reward: 500.00, mean_100: 350.83, episodes: 2747, reward function loss: -0.0435\n",
      "1052426: reward: 500.00, mean_100: 354.21, episodes: 2748, reward function loss: -0.0443\n",
      "1052926: reward: 500.00, mean_100: 357.80, episodes: 2749, reward function loss: -0.0443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1053426: reward: 500.00, mean_100: 357.80, episodes: 2750, reward function loss: -0.0443\n",
      "1053926: reward: 500.00, mean_100: 361.17, episodes: 2751, reward function loss: -0.0443\n",
      "1054426: reward: 500.00, mean_100: 361.17, episodes: 2752, reward function loss: -0.0435\n",
      "1054926: reward: 500.00, mean_100: 364.71, episodes: 2753, reward function loss: -0.0435\n",
      "1055426: reward: 500.00, mean_100: 368.06, episodes: 2754, reward function loss: -0.0435\n",
      "1055926: reward: 500.00, mean_100: 371.58, episodes: 2755, reward function loss: -0.0435\n",
      "1056426: reward: 500.00, mean_100: 371.58, episodes: 2756, reward function loss: -0.0432\n",
      "1056926: reward: 500.00, mean_100: 371.58, episodes: 2757, reward function loss: -0.0432\n",
      "1057426: reward: 500.00, mean_100: 375.03, episodes: 2758, reward function loss: -0.0432\n",
      "1057926: reward: 500.00, mean_100: 375.03, episodes: 2759, reward function loss: -0.0432\n",
      "1058426: reward: 500.00, mean_100: 378.47, episodes: 2760, reward function loss: -0.0439\n",
      "1058926: reward: 500.00, mean_100: 378.47, episodes: 2761, reward function loss: -0.0439\n",
      "1059426: reward: 500.00, mean_100: 378.47, episodes: 2762, reward function loss: -0.0439\n",
      "1059926: reward: 500.00, mean_100: 381.97, episodes: 2763, reward function loss: -0.0439\n",
      "1060426: reward: 500.00, mean_100: 385.43, episodes: 2764, reward function loss: -0.0441\n",
      "1060926: reward: 500.00, mean_100: 388.85, episodes: 2765, reward function loss: -0.0441\n",
      "1061426: reward: 500.00, mean_100: 388.85, episodes: 2766, reward function loss: -0.0441\n",
      "1061926: reward: 500.00, mean_100: 388.85, episodes: 2767, reward function loss: -0.0441\n",
      "1062426: reward: 500.00, mean_100: 388.85, episodes: 2768, reward function loss: -0.0441\n",
      "1062926: reward: 500.00, mean_100: 392.18, episodes: 2769, reward function loss: -0.0441\n",
      "1063426: reward: 500.00, mean_100: 395.71, episodes: 2770, reward function loss: -0.0441\n",
      "1063926: reward: 500.00, mean_100: 399.27, episodes: 2771, reward function loss: -0.0441\n",
      "1064426: reward: 500.00, mean_100: 402.77, episodes: 2772, reward function loss: -0.0443\n",
      "1064926: reward: 500.00, mean_100: 402.77, episodes: 2773, reward function loss: -0.0443\n",
      "1065426: reward: 500.00, mean_100: 406.24, episodes: 2774, reward function loss: -0.0443\n",
      "1065926: reward: 500.00, mean_100: 409.91, episodes: 2775, reward function loss: -0.0443\n",
      "1066426: reward: 500.00, mean_100: 413.56, episodes: 2776, reward function loss: -0.0435\n",
      "1066926: reward: 500.00, mean_100: 417.04, episodes: 2777, reward function loss: -0.0435\n",
      "1067426: reward: 500.00, mean_100: 420.64, episodes: 2778, reward function loss: -0.0435\n",
      "1067926: reward: 500.00, mean_100: 423.94, episodes: 2779, reward function loss: -0.0435\n",
      "1068426: reward: 500.00, mean_100: 427.49, episodes: 2780, reward function loss: -0.0439\n",
      "1068926: reward: 500.00, mean_100: 430.87, episodes: 2781, reward function loss: -0.0439\n",
      "1069426: reward: 500.00, mean_100: 434.57, episodes: 2782, reward function loss: -0.0439\n",
      "1069926: reward: 500.00, mean_100: 434.57, episodes: 2783, reward function loss: -0.0439\n",
      "1070426: reward: 500.00, mean_100: 438.29, episodes: 2784, reward function loss: -0.0433\n",
      "1070926: reward: 500.00, mean_100: 438.29, episodes: 2785, reward function loss: -0.0433\n",
      "1071426: reward: 500.00, mean_100: 441.90, episodes: 2786, reward function loss: -0.0433\n",
      "1071926: reward: 500.00, mean_100: 441.90, episodes: 2787, reward function loss: -0.0433\n",
      "1072426: reward: 500.00, mean_100: 445.40, episodes: 2788, reward function loss: -0.0435\n",
      "1072926: reward: 500.00, mean_100: 445.40, episodes: 2789, reward function loss: -0.0435\n",
      "1073426: reward: 500.00, mean_100: 448.97, episodes: 2790, reward function loss: -0.0435\n",
      "1073926: reward: 500.00, mean_100: 452.33, episodes: 2791, reward function loss: -0.0435\n",
      "1074426: reward: 500.00, mean_100: 455.85, episodes: 2792, reward function loss: -0.0438\n",
      "1074926: reward: 500.00, mean_100: 455.85, episodes: 2793, reward function loss: -0.0438\n",
      "1075426: reward: 500.00, mean_100: 459.38, episodes: 2794, reward function loss: -0.0438\n",
      "1075926: reward: 500.00, mean_100: 462.56, episodes: 2795, reward function loss: -0.0438\n",
      "1076426: reward: 500.00, mean_100: 462.56, episodes: 2796, reward function loss: -0.0436\n",
      "1076926: reward: 500.00, mean_100: 465.98, episodes: 2797, reward function loss: -0.0436\n",
      "1077426: reward: 500.00, mean_100: 469.38, episodes: 2798, reward function loss: -0.0436\n",
      "1077926: reward: 500.00, mean_100: 472.79, episodes: 2799, reward function loss: -0.0436\n",
      "1078426: reward: 500.00, mean_100: 472.79, episodes: 2800, reward function loss: -0.0436\n",
      "1078926: reward: 500.00, mean_100: 476.16, episodes: 2801, reward function loss: -0.0436\n",
      "1079426: reward: 500.00, mean_100: 476.16, episodes: 2802, reward function loss: -0.0436\n",
      "1079926: reward: 500.00, mean_100: 479.64, episodes: 2803, reward function loss: -0.0436\n",
      "1080426: reward: 500.00, mean_100: 483.18, episodes: 2804, reward function loss: -0.0429\n",
      "1080926: reward: 500.00, mean_100: 483.18, episodes: 2805, reward function loss: -0.0429\n",
      "1081426: reward: 500.00, mean_100: 486.65, episodes: 2806, reward function loss: -0.0429\n",
      "1081926: reward: 500.00, mean_100: 486.65, episodes: 2807, reward function loss: -0.0429\n",
      "1082426: reward: 500.00, mean_100: 486.65, episodes: 2808, reward function loss: -0.0428\n",
      "1082926: reward: 500.00, mean_100: 486.65, episodes: 2809, reward function loss: -0.0428\n",
      "1083426: reward: 500.00, mean_100: 490.15, episodes: 2810, reward function loss: -0.0428\n",
      "1083926: reward: 500.00, mean_100: 493.35, episodes: 2811, reward function loss: -0.0428\n",
      "1084426: reward: 500.00, mean_100: 496.79, episodes: 2812, reward function loss: -0.0415\n",
      "1084926: reward: 500.00, mean_100: 496.79, episodes: 2813, reward function loss: -0.0415\n",
      "1085426: reward: 500.00, mean_100: 496.79, episodes: 2814, reward function loss: -0.0415\n",
      "1085926: reward: 500.00, mean_100: 496.79, episodes: 2815, reward function loss: -0.0415\n",
      "1086426: reward: 500.00, mean_100: 496.79, episodes: 2816, reward function loss: -0.0362\n",
      "1086926: reward: 500.00, mean_100: 496.79, episodes: 2817, reward function loss: -0.0362\n",
      "1087426: reward: 500.00, mean_100: 500.00, episodes: 2818, reward function loss: -0.0362\n",
      "1087926: reward: 500.00, mean_100: 500.00, episodes: 2819, reward function loss: -0.0362\n",
      "1088426: reward: 500.00, mean_100: 500.00, episodes: 2820, reward function loss: -0.0103\n",
      "1088926: reward: 500.00, mean_100: 500.00, episodes: 2821, reward function loss: -0.0103\n",
      "1089426: reward: 500.00, mean_100: 500.00, episodes: 2822, reward function loss: -0.0103\n",
      "1089926: reward: 500.00, mean_100: 500.00, episodes: 2823, reward function loss: -0.0103\n",
      "1090426: reward: 500.00, mean_100: 500.00, episodes: 2824, reward function loss: -0.0172\n",
      "1090926: reward: 500.00, mean_100: 500.00, episodes: 2825, reward function loss: -0.0172\n",
      "1091426: reward: 500.00, mean_100: 500.00, episodes: 2826, reward function loss: -0.0172\n",
      "1091926: reward: 500.00, mean_100: 500.00, episodes: 2827, reward function loss: -0.0172\n",
      "1092426: reward: 500.00, mean_100: 500.00, episodes: 2828, reward function loss: -0.0157\n",
      "1092835: reward: 409.00, mean_100: 499.09, episodes: 2829, reward function loss: -0.0157\n",
      "1093335: reward: 500.00, mean_100: 499.09, episodes: 2830, reward function loss: -0.0157\n",
      "1093835: reward: 500.00, mean_100: 499.09, episodes: 2831, reward function loss: -0.0157\n",
      "1094335: reward: 500.00, mean_100: 499.09, episodes: 2832, reward function loss: -0.0234\n",
      "1094835: reward: 500.00, mean_100: 499.09, episodes: 2833, reward function loss: -0.0234\n",
      "1095256: reward: 421.00, mean_100: 498.30, episodes: 2834, reward function loss: -0.0234\n",
      "1095756: reward: 500.00, mean_100: 498.30, episodes: 2835, reward function loss: -0.0234\n",
      "1096256: reward: 500.00, mean_100: 498.30, episodes: 2836, reward function loss: -0.0173\n",
      "1096728: reward: 472.00, mean_100: 498.02, episodes: 2837, reward function loss: -0.0173\n",
      "1097228: reward: 500.00, mean_100: 498.02, episodes: 2838, reward function loss: -0.0173\n",
      "1097603: reward: 375.00, mean_100: 496.77, episodes: 2839, reward function loss: -0.0173\n",
      "1098084: reward: 481.00, mean_100: 496.58, episodes: 2840, reward function loss: -0.0191\n",
      "1098546: reward: 462.00, mean_100: 496.20, episodes: 2841, reward function loss: -0.0191\n",
      "1099046: reward: 500.00, mean_100: 496.20, episodes: 2842, reward function loss: -0.0191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099534: reward: 488.00, mean_100: 496.08, episodes: 2843, reward function loss: -0.0191\n",
      "1100006: reward: 472.00, mean_100: 495.80, episodes: 2844, reward function loss: -0.0144\n",
      "1100506: reward: 500.00, mean_100: 495.80, episodes: 2845, reward function loss: -0.0144\n",
      "1101006: reward: 500.00, mean_100: 495.80, episodes: 2846, reward function loss: -0.0144\n",
      "1101506: reward: 500.00, mean_100: 495.80, episodes: 2847, reward function loss: -0.0144\n",
      "1102006: reward: 500.00, mean_100: 495.80, episodes: 2848, reward function loss: -0.0088\n",
      "1102506: reward: 500.00, mean_100: 495.80, episodes: 2849, reward function loss: -0.0088\n",
      "1102952: reward: 446.00, mean_100: 495.26, episodes: 2850, reward function loss: -0.0088\n",
      "1103326: reward: 374.00, mean_100: 494.00, episodes: 2851, reward function loss: -0.0088\n",
      "1103696: reward: 370.00, mean_100: 492.70, episodes: 2852, reward function loss: -0.0093\n",
      "1104079: reward: 383.00, mean_100: 491.53, episodes: 2853, reward function loss: -0.0093\n",
      "1104579: reward: 500.00, mean_100: 491.53, episodes: 2854, reward function loss: -0.0093\n",
      "1104943: reward: 364.00, mean_100: 490.17, episodes: 2855, reward function loss: -0.0093\n",
      "1105371: reward: 428.00, mean_100: 489.45, episodes: 2856, reward function loss: -0.0002\n",
      "1105667: reward: 296.00, mean_100: 487.41, episodes: 2857, reward function loss: -0.0002\n",
      "1106129: reward: 462.00, mean_100: 487.03, episodes: 2858, reward function loss: -0.0002\n",
      "1106629: reward: 500.00, mean_100: 487.03, episodes: 2859, reward function loss: -0.0002\n",
      "1107129: reward: 500.00, mean_100: 487.03, episodes: 2860, reward function loss: -0.0014\n",
      "1107629: reward: 500.00, mean_100: 487.03, episodes: 2861, reward function loss: -0.0014\n",
      "1108129: reward: 500.00, mean_100: 487.03, episodes: 2862, reward function loss: -0.0014\n",
      "1108629: reward: 500.00, mean_100: 487.03, episodes: 2863, reward function loss: -0.0014\n",
      "1109129: reward: 500.00, mean_100: 487.03, episodes: 2864, reward function loss: -0.0016\n",
      "1109629: reward: 500.00, mean_100: 487.03, episodes: 2865, reward function loss: -0.0016\n",
      "1110129: reward: 500.00, mean_100: 487.03, episodes: 2866, reward function loss: -0.0016\n",
      "1110557: reward: 428.00, mean_100: 486.31, episodes: 2867, reward function loss: -0.0016\n",
      "1111057: reward: 500.00, mean_100: 486.31, episodes: 2868, reward function loss: -0.0017\n",
      "1111557: reward: 500.00, mean_100: 486.31, episodes: 2869, reward function loss: -0.0017\n",
      "1112057: reward: 500.00, mean_100: 486.31, episodes: 2870, reward function loss: -0.0017\n",
      "1112557: reward: 500.00, mean_100: 486.31, episodes: 2871, reward function loss: -0.0017\n",
      "1113057: reward: 500.00, mean_100: 486.31, episodes: 2872, reward function loss: -0.0000\n",
      "1113557: reward: 500.00, mean_100: 486.31, episodes: 2873, reward function loss: -0.0000\n",
      "1114057: reward: 500.00, mean_100: 486.31, episodes: 2874, reward function loss: -0.0000\n",
      "1114557: reward: 500.00, mean_100: 486.31, episodes: 2875, reward function loss: -0.0000\n",
      "1115032: reward: 475.00, mean_100: 486.06, episodes: 2876, reward function loss: -0.0004\n",
      "1115532: reward: 500.00, mean_100: 486.06, episodes: 2877, reward function loss: -0.0004\n",
      "1116032: reward: 500.00, mean_100: 486.06, episodes: 2878, reward function loss: -0.0004\n",
      "1116532: reward: 500.00, mean_100: 486.06, episodes: 2879, reward function loss: -0.0004\n",
      "1117032: reward: 500.00, mean_100: 486.06, episodes: 2880, reward function loss: -0.0001\n",
      "1117532: reward: 500.00, mean_100: 486.06, episodes: 2881, reward function loss: -0.0001\n",
      "1118032: reward: 500.00, mean_100: 486.06, episodes: 2882, reward function loss: -0.0001\n",
      "1118532: reward: 500.00, mean_100: 486.06, episodes: 2883, reward function loss: -0.0001\n",
      "1119032: reward: 500.00, mean_100: 486.06, episodes: 2884, reward function loss: -0.0001\n",
      "1119532: reward: 500.00, mean_100: 486.06, episodes: 2885, reward function loss: -0.0001\n",
      "1120032: reward: 500.00, mean_100: 486.06, episodes: 2886, reward function loss: -0.0001\n",
      "1120532: reward: 500.00, mean_100: 486.06, episodes: 2887, reward function loss: -0.0001\n",
      "1121032: reward: 500.00, mean_100: 486.06, episodes: 2888, reward function loss: -0.0001\n",
      "1121532: reward: 500.00, mean_100: 486.06, episodes: 2889, reward function loss: -0.0001\n",
      "1122032: reward: 500.00, mean_100: 486.06, episodes: 2890, reward function loss: -0.0001\n",
      "1122532: reward: 500.00, mean_100: 486.06, episodes: 2891, reward function loss: -0.0001\n",
      "1123032: reward: 500.00, mean_100: 486.06, episodes: 2892, reward function loss: -0.0001\n",
      "1123532: reward: 500.00, mean_100: 486.06, episodes: 2893, reward function loss: -0.0001\n",
      "1124032: reward: 500.00, mean_100: 486.06, episodes: 2894, reward function loss: -0.0001\n",
      "1124532: reward: 500.00, mean_100: 486.06, episodes: 2895, reward function loss: -0.0001\n",
      "1125032: reward: 500.00, mean_100: 486.06, episodes: 2896, reward function loss: -0.0003\n",
      "1125532: reward: 500.00, mean_100: 486.06, episodes: 2897, reward function loss: -0.0003\n",
      "1126032: reward: 500.00, mean_100: 486.06, episodes: 2898, reward function loss: -0.0003\n",
      "1126532: reward: 500.00, mean_100: 486.06, episodes: 2899, reward function loss: -0.0003\n",
      "1127032: reward: 500.00, mean_100: 486.06, episodes: 2900, reward function loss: -0.0012\n",
      "1127532: reward: 500.00, mean_100: 486.06, episodes: 2901, reward function loss: -0.0012\n",
      "1128032: reward: 500.00, mean_100: 486.06, episodes: 2902, reward function loss: -0.0012\n",
      "1128532: reward: 500.00, mean_100: 486.06, episodes: 2903, reward function loss: -0.0012\n",
      "1129032: reward: 500.00, mean_100: 486.06, episodes: 2904, reward function loss: -0.0171\n",
      "1129532: reward: 500.00, mean_100: 486.06, episodes: 2905, reward function loss: -0.0171\n",
      "1130032: reward: 500.00, mean_100: 486.06, episodes: 2906, reward function loss: -0.0171\n",
      "1130532: reward: 500.00, mean_100: 486.06, episodes: 2907, reward function loss: -0.0171\n",
      "1131032: reward: 500.00, mean_100: 486.06, episodes: 2908, reward function loss: -0.0400\n",
      "1131532: reward: 500.00, mean_100: 486.06, episodes: 2909, reward function loss: -0.0400\n",
      "1132032: reward: 500.00, mean_100: 486.06, episodes: 2910, reward function loss: -0.0400\n",
      "1132532: reward: 500.00, mean_100: 486.06, episodes: 2911, reward function loss: -0.0400\n",
      "1133032: reward: 500.00, mean_100: 486.06, episodes: 2912, reward function loss: -0.0475\n",
      "1133532: reward: 500.00, mean_100: 486.06, episodes: 2913, reward function loss: -0.0475\n",
      "1134032: reward: 500.00, mean_100: 486.06, episodes: 2914, reward function loss: -0.0475\n",
      "1134532: reward: 500.00, mean_100: 486.06, episodes: 2915, reward function loss: -0.0475\n",
      "1135032: reward: 500.00, mean_100: 486.06, episodes: 2916, reward function loss: -0.0452\n",
      "1135532: reward: 500.00, mean_100: 486.06, episodes: 2917, reward function loss: -0.0452\n",
      "1136032: reward: 500.00, mean_100: 486.06, episodes: 2918, reward function loss: -0.0452\n",
      "1136532: reward: 500.00, mean_100: 486.06, episodes: 2919, reward function loss: -0.0452\n",
      "1137032: reward: 500.00, mean_100: 486.06, episodes: 2920, reward function loss: -0.0462\n",
      "1137532: reward: 500.00, mean_100: 486.06, episodes: 2921, reward function loss: -0.0462\n",
      "1138032: reward: 500.00, mean_100: 486.06, episodes: 2922, reward function loss: -0.0462\n",
      "1138532: reward: 500.00, mean_100: 486.06, episodes: 2923, reward function loss: -0.0462\n",
      "1139032: reward: 500.00, mean_100: 486.06, episodes: 2924, reward function loss: -0.0458\n",
      "1139532: reward: 500.00, mean_100: 486.06, episodes: 2925, reward function loss: -0.0458\n",
      "1140032: reward: 500.00, mean_100: 486.06, episodes: 2926, reward function loss: -0.0458\n",
      "1140532: reward: 500.00, mean_100: 486.06, episodes: 2927, reward function loss: -0.0458\n",
      "1141032: reward: 500.00, mean_100: 486.06, episodes: 2928, reward function loss: -0.0477\n",
      "1141532: reward: 500.00, mean_100: 486.97, episodes: 2929, reward function loss: -0.0477\n",
      "1142032: reward: 500.00, mean_100: 486.97, episodes: 2930, reward function loss: -0.0477\n",
      "1142532: reward: 500.00, mean_100: 486.97, episodes: 2931, reward function loss: -0.0477\n",
      "1143032: reward: 500.00, mean_100: 486.97, episodes: 2932, reward function loss: -0.0456\n",
      "1143532: reward: 500.00, mean_100: 486.97, episodes: 2933, reward function loss: -0.0456\n",
      "1144032: reward: 500.00, mean_100: 487.76, episodes: 2934, reward function loss: -0.0456\n",
      "1144532: reward: 500.00, mean_100: 487.76, episodes: 2935, reward function loss: -0.0456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145032: reward: 500.00, mean_100: 487.76, episodes: 2936, reward function loss: -0.0475\n",
      "1145532: reward: 500.00, mean_100: 488.04, episodes: 2937, reward function loss: -0.0475\n",
      "1146032: reward: 500.00, mean_100: 488.04, episodes: 2938, reward function loss: -0.0475\n",
      "1146532: reward: 500.00, mean_100: 489.29, episodes: 2939, reward function loss: -0.0475\n",
      "1147032: reward: 500.00, mean_100: 489.48, episodes: 2940, reward function loss: -0.0475\n",
      "1147532: reward: 500.00, mean_100: 489.86, episodes: 2941, reward function loss: -0.0475\n",
      "1148032: reward: 500.00, mean_100: 489.86, episodes: 2942, reward function loss: -0.0475\n",
      "1148532: reward: 500.00, mean_100: 489.98, episodes: 2943, reward function loss: -0.0475\n",
      "1149032: reward: 500.00, mean_100: 490.26, episodes: 2944, reward function loss: -0.0473\n",
      "1149532: reward: 500.00, mean_100: 490.26, episodes: 2945, reward function loss: -0.0473\n",
      "1150032: reward: 500.00, mean_100: 490.26, episodes: 2946, reward function loss: -0.0473\n",
      "1150532: reward: 500.00, mean_100: 490.26, episodes: 2947, reward function loss: -0.0473\n",
      "1151032: reward: 500.00, mean_100: 490.26, episodes: 2948, reward function loss: -0.0473\n",
      "1151532: reward: 500.00, mean_100: 490.26, episodes: 2949, reward function loss: -0.0473\n",
      "1152032: reward: 500.00, mean_100: 490.80, episodes: 2950, reward function loss: -0.0473\n",
      "1152532: reward: 500.00, mean_100: 492.06, episodes: 2951, reward function loss: -0.0473\n",
      "1153032: reward: 500.00, mean_100: 493.36, episodes: 2952, reward function loss: -0.0479\n",
      "1153532: reward: 500.00, mean_100: 494.53, episodes: 2953, reward function loss: -0.0479\n",
      "1154032: reward: 500.00, mean_100: 494.53, episodes: 2954, reward function loss: -0.0479\n",
      "1154532: reward: 500.00, mean_100: 495.89, episodes: 2955, reward function loss: -0.0479\n",
      "1155032: reward: 500.00, mean_100: 496.61, episodes: 2956, reward function loss: -0.0479\n",
      "1155532: reward: 500.00, mean_100: 498.65, episodes: 2957, reward function loss: -0.0479\n",
      "1156032: reward: 500.00, mean_100: 499.03, episodes: 2958, reward function loss: -0.0479\n",
      "1156532: reward: 500.00, mean_100: 499.03, episodes: 2959, reward function loss: -0.0479\n",
      "1157032: reward: 500.00, mean_100: 499.03, episodes: 2960, reward function loss: -0.0471\n",
      "1157532: reward: 500.00, mean_100: 499.03, episodes: 2961, reward function loss: -0.0471\n",
      "1158032: reward: 500.00, mean_100: 499.03, episodes: 2962, reward function loss: -0.0471\n",
      "1158532: reward: 500.00, mean_100: 499.03, episodes: 2963, reward function loss: -0.0471\n",
      "1159032: reward: 500.00, mean_100: 499.03, episodes: 2964, reward function loss: -0.0469\n",
      "1159532: reward: 500.00, mean_100: 499.03, episodes: 2965, reward function loss: -0.0469\n",
      "1160032: reward: 500.00, mean_100: 499.03, episodes: 2966, reward function loss: -0.0469\n",
      "1160532: reward: 500.00, mean_100: 499.75, episodes: 2967, reward function loss: -0.0469\n",
      "1161032: reward: 500.00, mean_100: 499.75, episodes: 2968, reward function loss: -0.0477\n",
      "1161532: reward: 500.00, mean_100: 499.75, episodes: 2969, reward function loss: -0.0477\n",
      "1162032: reward: 500.00, mean_100: 499.75, episodes: 2970, reward function loss: -0.0477\n",
      "1162532: reward: 500.00, mean_100: 499.75, episodes: 2971, reward function loss: -0.0477\n",
      "1163032: reward: 500.00, mean_100: 499.75, episodes: 2972, reward function loss: -0.0471\n",
      "1163532: reward: 500.00, mean_100: 499.75, episodes: 2973, reward function loss: -0.0471\n",
      "1164032: reward: 500.00, mean_100: 499.75, episodes: 2974, reward function loss: -0.0471\n",
      "1164532: reward: 500.00, mean_100: 499.75, episodes: 2975, reward function loss: -0.0471\n",
      "1165032: reward: 500.00, mean_100: 500.00, episodes: 2976, reward function loss: -0.0475\n",
      "1165532: reward: 500.00, mean_100: 500.00, episodes: 2977, reward function loss: -0.0475\n",
      "1166032: reward: 500.00, mean_100: 500.00, episodes: 2978, reward function loss: -0.0475\n",
      "1166532: reward: 500.00, mean_100: 500.00, episodes: 2979, reward function loss: -0.0475\n",
      "1167032: reward: 500.00, mean_100: 500.00, episodes: 2980, reward function loss: -0.0472\n",
      "1167532: reward: 500.00, mean_100: 500.00, episodes: 2981, reward function loss: -0.0472\n",
      "1168032: reward: 500.00, mean_100: 500.00, episodes: 2982, reward function loss: -0.0472\n",
      "1168532: reward: 500.00, mean_100: 500.00, episodes: 2983, reward function loss: -0.0472\n",
      "1169032: reward: 500.00, mean_100: 500.00, episodes: 2984, reward function loss: -0.0478\n",
      "1169532: reward: 500.00, mean_100: 500.00, episodes: 2985, reward function loss: -0.0478\n",
      "1170032: reward: 500.00, mean_100: 500.00, episodes: 2986, reward function loss: -0.0478\n",
      "1170532: reward: 500.00, mean_100: 500.00, episodes: 2987, reward function loss: -0.0478\n",
      "1171032: reward: 500.00, mean_100: 500.00, episodes: 2988, reward function loss: -0.0473\n",
      "1171532: reward: 500.00, mean_100: 500.00, episodes: 2989, reward function loss: -0.0473\n",
      "1172032: reward: 500.00, mean_100: 500.00, episodes: 2990, reward function loss: -0.0473\n",
      "1172532: reward: 500.00, mean_100: 500.00, episodes: 2991, reward function loss: -0.0473\n",
      "1173032: reward: 500.00, mean_100: 500.00, episodes: 2992, reward function loss: -0.0478\n",
      "1173532: reward: 500.00, mean_100: 500.00, episodes: 2993, reward function loss: -0.0478\n",
      "1174032: reward: 500.00, mean_100: 500.00, episodes: 2994, reward function loss: -0.0478\n",
      "1174532: reward: 500.00, mean_100: 500.00, episodes: 2995, reward function loss: -0.0478\n",
      "1175032: reward: 500.00, mean_100: 500.00, episodes: 2996, reward function loss: -0.0475\n",
      "1175532: reward: 500.00, mean_100: 500.00, episodes: 2997, reward function loss: -0.0475\n",
      "1176032: reward: 500.00, mean_100: 500.00, episodes: 2998, reward function loss: -0.0475\n",
      "1176532: reward: 500.00, mean_100: 500.00, episodes: 2999, reward function loss: -0.0475\n",
      "1177032: reward: 500.00, mean_100: 500.00, episodes: 3000, reward function loss: -0.0473\n",
      "1177532: reward: 500.00, mean_100: 500.00, episodes: 3001, reward function loss: -0.0473\n",
      "1178032: reward: 500.00, mean_100: 500.00, episodes: 3002, reward function loss: -0.0473\n",
      "1178532: reward: 500.00, mean_100: 500.00, episodes: 3003, reward function loss: -0.0473\n",
      "1179032: reward: 500.00, mean_100: 500.00, episodes: 3004, reward function loss: -0.0479\n",
      "1179532: reward: 500.00, mean_100: 500.00, episodes: 3005, reward function loss: -0.0479\n",
      "1180032: reward: 500.00, mean_100: 500.00, episodes: 3006, reward function loss: -0.0479\n",
      "1180532: reward: 500.00, mean_100: 500.00, episodes: 3007, reward function loss: -0.0479\n",
      "1181032: reward: 500.00, mean_100: 500.00, episodes: 3008, reward function loss: -0.0477\n",
      "1181532: reward: 500.00, mean_100: 500.00, episodes: 3009, reward function loss: -0.0477\n",
      "1182032: reward: 500.00, mean_100: 500.00, episodes: 3010, reward function loss: -0.0477\n",
      "1182532: reward: 500.00, mean_100: 500.00, episodes: 3011, reward function loss: -0.0477\n",
      "1183032: reward: 500.00, mean_100: 500.00, episodes: 3012, reward function loss: -0.0472\n",
      "1183532: reward: 500.00, mean_100: 500.00, episodes: 3013, reward function loss: -0.0472\n",
      "1184032: reward: 500.00, mean_100: 500.00, episodes: 3014, reward function loss: -0.0472\n",
      "1184532: reward: 500.00, mean_100: 500.00, episodes: 3015, reward function loss: -0.0472\n",
      "1185032: reward: 500.00, mean_100: 500.00, episodes: 3016, reward function loss: -0.0473\n",
      "1185532: reward: 500.00, mean_100: 500.00, episodes: 3017, reward function loss: -0.0473\n",
      "1186032: reward: 500.00, mean_100: 500.00, episodes: 3018, reward function loss: -0.0473\n",
      "1186532: reward: 500.00, mean_100: 500.00, episodes: 3019, reward function loss: -0.0473\n",
      "1187032: reward: 500.00, mean_100: 500.00, episodes: 3020, reward function loss: -0.0474\n",
      "1187532: reward: 500.00, mean_100: 500.00, episodes: 3021, reward function loss: -0.0474\n",
      "1188032: reward: 500.00, mean_100: 500.00, episodes: 3022, reward function loss: -0.0474\n",
      "1188532: reward: 500.00, mean_100: 500.00, episodes: 3023, reward function loss: -0.0474\n",
      "1189032: reward: 500.00, mean_100: 500.00, episodes: 3024, reward function loss: -0.0474\n",
      "1189532: reward: 500.00, mean_100: 500.00, episodes: 3025, reward function loss: -0.0474\n",
      "1190032: reward: 500.00, mean_100: 500.00, episodes: 3026, reward function loss: -0.0474\n",
      "1190532: reward: 500.00, mean_100: 500.00, episodes: 3027, reward function loss: -0.0474\n",
      "1191032: reward: 500.00, mean_100: 500.00, episodes: 3028, reward function loss: -0.0475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1191532: reward: 500.00, mean_100: 500.00, episodes: 3029, reward function loss: -0.0475\n",
      "1192032: reward: 500.00, mean_100: 500.00, episodes: 3030, reward function loss: -0.0475\n",
      "1192532: reward: 500.00, mean_100: 500.00, episodes: 3031, reward function loss: -0.0475\n",
      "1193032: reward: 500.00, mean_100: 500.00, episodes: 3032, reward function loss: -0.0475\n",
      "1193532: reward: 500.00, mean_100: 500.00, episodes: 3033, reward function loss: -0.0475\n",
      "1194032: reward: 500.00, mean_100: 500.00, episodes: 3034, reward function loss: -0.0475\n",
      "1194532: reward: 500.00, mean_100: 500.00, episodes: 3035, reward function loss: -0.0475\n",
      "1195032: reward: 500.00, mean_100: 500.00, episodes: 3036, reward function loss: -0.0475\n",
      "1195532: reward: 500.00, mean_100: 500.00, episodes: 3037, reward function loss: -0.0475\n",
      "1196032: reward: 500.00, mean_100: 500.00, episodes: 3038, reward function loss: -0.0475\n",
      "1196532: reward: 500.00, mean_100: 500.00, episodes: 3039, reward function loss: -0.0475\n",
      "1197032: reward: 500.00, mean_100: 500.00, episodes: 3040, reward function loss: -0.0473\n",
      "1197532: reward: 500.00, mean_100: 500.00, episodes: 3041, reward function loss: -0.0473\n",
      "1198032: reward: 500.00, mean_100: 500.00, episodes: 3042, reward function loss: -0.0473\n",
      "1198532: reward: 500.00, mean_100: 500.00, episodes: 3043, reward function loss: -0.0473\n",
      "1199032: reward: 500.00, mean_100: 500.00, episodes: 3044, reward function loss: -0.0479\n",
      "1199532: reward: 500.00, mean_100: 500.00, episodes: 3045, reward function loss: -0.0479\n",
      "1200032: reward: 500.00, mean_100: 500.00, episodes: 3046, reward function loss: -0.0479\n",
      "1200532: reward: 500.00, mean_100: 500.00, episodes: 3047, reward function loss: -0.0479\n",
      "1201032: reward: 500.00, mean_100: 500.00, episodes: 3048, reward function loss: -0.0473\n",
      "1201532: reward: 500.00, mean_100: 500.00, episodes: 3049, reward function loss: -0.0473\n",
      "1202032: reward: 500.00, mean_100: 500.00, episodes: 3050, reward function loss: -0.0473\n",
      "1202532: reward: 500.00, mean_100: 500.00, episodes: 3051, reward function loss: -0.0473\n",
      "1203032: reward: 500.00, mean_100: 500.00, episodes: 3052, reward function loss: -0.0466\n",
      "1203532: reward: 500.00, mean_100: 500.00, episodes: 3053, reward function loss: -0.0466\n",
      "1204032: reward: 500.00, mean_100: 500.00, episodes: 3054, reward function loss: -0.0466\n",
      "1204532: reward: 500.00, mean_100: 500.00, episodes: 3055, reward function loss: -0.0466\n",
      "1205032: reward: 500.00, mean_100: 500.00, episodes: 3056, reward function loss: -0.0473\n",
      "1205532: reward: 500.00, mean_100: 500.00, episodes: 3057, reward function loss: -0.0473\n",
      "1206032: reward: 500.00, mean_100: 500.00, episodes: 3058, reward function loss: -0.0473\n",
      "1206532: reward: 500.00, mean_100: 500.00, episodes: 3059, reward function loss: -0.0473\n",
      "1207032: reward: 500.00, mean_100: 500.00, episodes: 3060, reward function loss: -0.0478\n",
      "1207532: reward: 500.00, mean_100: 500.00, episodes: 3061, reward function loss: -0.0478\n",
      "1208032: reward: 500.00, mean_100: 500.00, episodes: 3062, reward function loss: -0.0478\n",
      "1208532: reward: 500.00, mean_100: 500.00, episodes: 3063, reward function loss: -0.0478\n",
      "1209032: reward: 500.00, mean_100: 500.00, episodes: 3064, reward function loss: -0.0477\n",
      "1209532: reward: 500.00, mean_100: 500.00, episodes: 3065, reward function loss: -0.0477\n",
      "1210032: reward: 500.00, mean_100: 500.00, episodes: 3066, reward function loss: -0.0477\n",
      "1210532: reward: 500.00, mean_100: 500.00, episodes: 3067, reward function loss: -0.0477\n",
      "1211032: reward: 500.00, mean_100: 500.00, episodes: 3068, reward function loss: -0.0471\n",
      "1211532: reward: 500.00, mean_100: 500.00, episodes: 3069, reward function loss: -0.0471\n",
      "1212032: reward: 500.00, mean_100: 500.00, episodes: 3070, reward function loss: -0.0471\n",
      "1212532: reward: 500.00, mean_100: 500.00, episodes: 3071, reward function loss: -0.0471\n",
      "1213032: reward: 500.00, mean_100: 500.00, episodes: 3072, reward function loss: -0.0471\n",
      "1213532: reward: 500.00, mean_100: 500.00, episodes: 3073, reward function loss: -0.0471\n",
      "1214032: reward: 500.00, mean_100: 500.00, episodes: 3074, reward function loss: -0.0471\n",
      "1214532: reward: 500.00, mean_100: 500.00, episodes: 3075, reward function loss: -0.0471\n",
      "1215032: reward: 500.00, mean_100: 500.00, episodes: 3076, reward function loss: -0.0479\n",
      "1215532: reward: 500.00, mean_100: 500.00, episodes: 3077, reward function loss: -0.0479\n",
      "1216032: reward: 500.00, mean_100: 500.00, episodes: 3078, reward function loss: -0.0479\n",
      "1216532: reward: 500.00, mean_100: 500.00, episodes: 3079, reward function loss: -0.0479\n",
      "1217032: reward: 500.00, mean_100: 500.00, episodes: 3080, reward function loss: -0.0467\n",
      "1217532: reward: 500.00, mean_100: 500.00, episodes: 3081, reward function loss: -0.0467\n",
      "1218032: reward: 500.00, mean_100: 500.00, episodes: 3082, reward function loss: -0.0467\n",
      "1218532: reward: 500.00, mean_100: 500.00, episodes: 3083, reward function loss: -0.0467\n",
      "1219032: reward: 500.00, mean_100: 500.00, episodes: 3084, reward function loss: -0.0473\n",
      "1219532: reward: 500.00, mean_100: 500.00, episodes: 3085, reward function loss: -0.0473\n",
      "1220032: reward: 500.00, mean_100: 500.00, episodes: 3086, reward function loss: -0.0473\n",
      "1220532: reward: 500.00, mean_100: 500.00, episodes: 3087, reward function loss: -0.0473\n",
      "1221032: reward: 500.00, mean_100: 500.00, episodes: 3088, reward function loss: -0.0470\n",
      "1221532: reward: 500.00, mean_100: 500.00, episodes: 3089, reward function loss: -0.0470\n",
      "1222032: reward: 500.00, mean_100: 500.00, episodes: 3090, reward function loss: -0.0470\n",
      "1222532: reward: 500.00, mean_100: 500.00, episodes: 3091, reward function loss: -0.0470\n",
      "1223032: reward: 500.00, mean_100: 500.00, episodes: 3092, reward function loss: -0.0478\n",
      "1223532: reward: 500.00, mean_100: 500.00, episodes: 3093, reward function loss: -0.0478\n",
      "1224032: reward: 500.00, mean_100: 500.00, episodes: 3094, reward function loss: -0.0478\n",
      "1224532: reward: 500.00, mean_100: 500.00, episodes: 3095, reward function loss: -0.0478\n",
      "1225032: reward: 500.00, mean_100: 500.00, episodes: 3096, reward function loss: -0.0476\n",
      "1225532: reward: 500.00, mean_100: 500.00, episodes: 3097, reward function loss: -0.0476\n",
      "1226032: reward: 500.00, mean_100: 500.00, episodes: 3098, reward function loss: -0.0476\n",
      "1226532: reward: 500.00, mean_100: 500.00, episodes: 3099, reward function loss: -0.0476\n",
      "1227032: reward: 500.00, mean_100: 500.00, episodes: 3100, reward function loss: -0.0476\n",
      "1227532: reward: 500.00, mean_100: 500.00, episodes: 3101, reward function loss: -0.0476\n",
      "1228032: reward: 500.00, mean_100: 500.00, episodes: 3102, reward function loss: -0.0476\n",
      "1228532: reward: 500.00, mean_100: 500.00, episodes: 3103, reward function loss: -0.0476\n",
      "1229032: reward: 500.00, mean_100: 500.00, episodes: 3104, reward function loss: -0.0475\n",
      "1229532: reward: 500.00, mean_100: 500.00, episodes: 3105, reward function loss: -0.0475\n",
      "1230032: reward: 500.00, mean_100: 500.00, episodes: 3106, reward function loss: -0.0475\n",
      "1230532: reward: 500.00, mean_100: 500.00, episodes: 3107, reward function loss: -0.0475\n",
      "1231032: reward: 500.00, mean_100: 500.00, episodes: 3108, reward function loss: -0.0474\n",
      "1231532: reward: 500.00, mean_100: 500.00, episodes: 3109, reward function loss: -0.0474\n",
      "1232032: reward: 500.00, mean_100: 500.00, episodes: 3110, reward function loss: -0.0474\n",
      "1232532: reward: 500.00, mean_100: 500.00, episodes: 3111, reward function loss: -0.0474\n",
      "1233032: reward: 500.00, mean_100: 500.00, episodes: 3112, reward function loss: -0.0475\n",
      "1233532: reward: 500.00, mean_100: 500.00, episodes: 3113, reward function loss: -0.0475\n",
      "1234032: reward: 500.00, mean_100: 500.00, episodes: 3114, reward function loss: -0.0475\n",
      "1234532: reward: 500.00, mean_100: 500.00, episodes: 3115, reward function loss: -0.0475\n",
      "1235032: reward: 500.00, mean_100: 500.00, episodes: 3116, reward function loss: -0.0477\n",
      "1235532: reward: 500.00, mean_100: 500.00, episodes: 3117, reward function loss: -0.0477\n",
      "1236032: reward: 500.00, mean_100: 500.00, episodes: 3118, reward function loss: -0.0477\n",
      "1236532: reward: 500.00, mean_100: 500.00, episodes: 3119, reward function loss: -0.0477\n",
      "1237032: reward: 500.00, mean_100: 500.00, episodes: 3120, reward function loss: -0.0478\n",
      "1237532: reward: 500.00, mean_100: 500.00, episodes: 3121, reward function loss: -0.0478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1238032: reward: 500.00, mean_100: 500.00, episodes: 3122, reward function loss: -0.0478\n",
      "1238532: reward: 500.00, mean_100: 500.00, episodes: 3123, reward function loss: -0.0478\n",
      "1239032: reward: 500.00, mean_100: 500.00, episodes: 3124, reward function loss: -0.0475\n",
      "1239532: reward: 500.00, mean_100: 500.00, episodes: 3125, reward function loss: -0.0475\n",
      "1240032: reward: 500.00, mean_100: 500.00, episodes: 3126, reward function loss: -0.0475\n",
      "1240532: reward: 500.00, mean_100: 500.00, episodes: 3127, reward function loss: -0.0475\n",
      "1241032: reward: 500.00, mean_100: 500.00, episodes: 3128, reward function loss: -0.0475\n",
      "1241532: reward: 500.00, mean_100: 500.00, episodes: 3129, reward function loss: -0.0475\n",
      "1242032: reward: 500.00, mean_100: 500.00, episodes: 3130, reward function loss: -0.0475\n",
      "1242532: reward: 500.00, mean_100: 500.00, episodes: 3131, reward function loss: -0.0475\n",
      "1243032: reward: 500.00, mean_100: 500.00, episodes: 3132, reward function loss: -0.0474\n",
      "1243532: reward: 500.00, mean_100: 500.00, episodes: 3133, reward function loss: -0.0474\n",
      "1244032: reward: 500.00, mean_100: 500.00, episodes: 3134, reward function loss: -0.0474\n",
      "1244532: reward: 500.00, mean_100: 500.00, episodes: 3135, reward function loss: -0.0474\n",
      "1245032: reward: 500.00, mean_100: 500.00, episodes: 3136, reward function loss: -0.0475\n",
      "1245532: reward: 500.00, mean_100: 500.00, episodes: 3137, reward function loss: -0.0475\n",
      "1246032: reward: 500.00, mean_100: 500.00, episodes: 3138, reward function loss: -0.0475\n",
      "1246532: reward: 500.00, mean_100: 500.00, episodes: 3139, reward function loss: -0.0475\n",
      "1247032: reward: 500.00, mean_100: 500.00, episodes: 3140, reward function loss: -0.0478\n",
      "1247532: reward: 500.00, mean_100: 500.00, episodes: 3141, reward function loss: -0.0478\n",
      "1248032: reward: 500.00, mean_100: 500.00, episodes: 3142, reward function loss: -0.0478\n",
      "1248532: reward: 500.00, mean_100: 500.00, episodes: 3143, reward function loss: -0.0478\n",
      "1249032: reward: 500.00, mean_100: 500.00, episodes: 3144, reward function loss: -0.0468\n",
      "1249532: reward: 500.00, mean_100: 500.00, episodes: 3145, reward function loss: -0.0468\n",
      "1250032: reward: 500.00, mean_100: 500.00, episodes: 3146, reward function loss: -0.0468\n",
      "1250532: reward: 500.00, mean_100: 500.00, episodes: 3147, reward function loss: -0.0468\n",
      "1251032: reward: 500.00, mean_100: 500.00, episodes: 3148, reward function loss: -0.0478\n",
      "1251532: reward: 500.00, mean_100: 500.00, episodes: 3149, reward function loss: -0.0478\n",
      "1252032: reward: 500.00, mean_100: 500.00, episodes: 3150, reward function loss: -0.0478\n",
      "1252532: reward: 500.00, mean_100: 500.00, episodes: 3151, reward function loss: -0.0478\n",
      "1253032: reward: 500.00, mean_100: 500.00, episodes: 3152, reward function loss: -0.0474\n",
      "1253532: reward: 500.00, mean_100: 500.00, episodes: 3153, reward function loss: -0.0474\n",
      "1254032: reward: 500.00, mean_100: 500.00, episodes: 3154, reward function loss: -0.0474\n",
      "1254532: reward: 500.00, mean_100: 500.00, episodes: 3155, reward function loss: -0.0474\n",
      "1255032: reward: 500.00, mean_100: 500.00, episodes: 3156, reward function loss: -0.0473\n",
      "1255532: reward: 500.00, mean_100: 500.00, episodes: 3157, reward function loss: -0.0473\n",
      "1256032: reward: 500.00, mean_100: 500.00, episodes: 3158, reward function loss: -0.0473\n",
      "1256532: reward: 500.00, mean_100: 500.00, episodes: 3159, reward function loss: -0.0473\n",
      "1257032: reward: 500.00, mean_100: 500.00, episodes: 3160, reward function loss: -0.0473\n",
      "1257532: reward: 500.00, mean_100: 500.00, episodes: 3161, reward function loss: -0.0473\n",
      "1258032: reward: 500.00, mean_100: 500.00, episodes: 3162, reward function loss: -0.0473\n",
      "1258532: reward: 500.00, mean_100: 500.00, episodes: 3163, reward function loss: -0.0473\n",
      "1259032: reward: 500.00, mean_100: 500.00, episodes: 3164, reward function loss: -0.0471\n",
      "1259532: reward: 500.00, mean_100: 500.00, episodes: 3165, reward function loss: -0.0471\n",
      "1260032: reward: 500.00, mean_100: 500.00, episodes: 3166, reward function loss: -0.0471\n",
      "1260532: reward: 500.00, mean_100: 500.00, episodes: 3167, reward function loss: -0.0471\n",
      "1261032: reward: 500.00, mean_100: 500.00, episodes: 3168, reward function loss: -0.0479\n",
      "1261532: reward: 500.00, mean_100: 500.00, episodes: 3169, reward function loss: -0.0479\n",
      "1262032: reward: 500.00, mean_100: 500.00, episodes: 3170, reward function loss: -0.0479\n",
      "1262532: reward: 500.00, mean_100: 500.00, episodes: 3171, reward function loss: -0.0479\n",
      "1263032: reward: 500.00, mean_100: 500.00, episodes: 3172, reward function loss: -0.0479\n",
      "1263532: reward: 500.00, mean_100: 500.00, episodes: 3173, reward function loss: -0.0479\n",
      "1264032: reward: 500.00, mean_100: 500.00, episodes: 3174, reward function loss: -0.0479\n",
      "1264532: reward: 500.00, mean_100: 500.00, episodes: 3175, reward function loss: -0.0479\n",
      "1265032: reward: 500.00, mean_100: 500.00, episodes: 3176, reward function loss: -0.0475\n",
      "1265532: reward: 500.00, mean_100: 500.00, episodes: 3177, reward function loss: -0.0475\n",
      "1266032: reward: 500.00, mean_100: 500.00, episodes: 3178, reward function loss: -0.0475\n",
      "1266532: reward: 500.00, mean_100: 500.00, episodes: 3179, reward function loss: -0.0475\n",
      "1267032: reward: 500.00, mean_100: 500.00, episodes: 3180, reward function loss: -0.0468\n",
      "1267532: reward: 500.00, mean_100: 500.00, episodes: 3181, reward function loss: -0.0468\n",
      "1268032: reward: 500.00, mean_100: 500.00, episodes: 3182, reward function loss: -0.0468\n",
      "1268532: reward: 500.00, mean_100: 500.00, episodes: 3183, reward function loss: -0.0468\n",
      "1269032: reward: 500.00, mean_100: 500.00, episodes: 3184, reward function loss: -0.0479\n",
      "1269532: reward: 500.00, mean_100: 500.00, episodes: 3185, reward function loss: -0.0479\n",
      "1270032: reward: 500.00, mean_100: 500.00, episodes: 3186, reward function loss: -0.0479\n",
      "1270532: reward: 500.00, mean_100: 500.00, episodes: 3187, reward function loss: -0.0479\n",
      "1271032: reward: 500.00, mean_100: 500.00, episodes: 3188, reward function loss: -0.0465\n",
      "1271532: reward: 500.00, mean_100: 500.00, episodes: 3189, reward function loss: -0.0465\n",
      "1272032: reward: 500.00, mean_100: 500.00, episodes: 3190, reward function loss: -0.0465\n",
      "1272532: reward: 500.00, mean_100: 500.00, episodes: 3191, reward function loss: -0.0465\n",
      "1273032: reward: 500.00, mean_100: 500.00, episodes: 3192, reward function loss: -0.0474\n",
      "1273532: reward: 500.00, mean_100: 500.00, episodes: 3193, reward function loss: -0.0474\n",
      "1274032: reward: 500.00, mean_100: 500.00, episodes: 3194, reward function loss: -0.0474\n",
      "1274532: reward: 500.00, mean_100: 500.00, episodes: 3195, reward function loss: -0.0474\n",
      "1275032: reward: 500.00, mean_100: 500.00, episodes: 3196, reward function loss: -0.0471\n",
      "1275532: reward: 500.00, mean_100: 500.00, episodes: 3197, reward function loss: -0.0471\n",
      "1276032: reward: 500.00, mean_100: 500.00, episodes: 3198, reward function loss: -0.0471\n",
      "1276532: reward: 500.00, mean_100: 500.00, episodes: 3199, reward function loss: -0.0471\n",
      "1277032: reward: 500.00, mean_100: 500.00, episodes: 3200, reward function loss: -0.0461\n",
      "1277532: reward: 500.00, mean_100: 500.00, episodes: 3201, reward function loss: -0.0461\n",
      "1278032: reward: 500.00, mean_100: 500.00, episodes: 3202, reward function loss: -0.0461\n",
      "1278532: reward: 500.00, mean_100: 500.00, episodes: 3203, reward function loss: -0.0461\n",
      "1279032: reward: 500.00, mean_100: 500.00, episodes: 3204, reward function loss: -0.0474\n",
      "1279532: reward: 500.00, mean_100: 500.00, episodes: 3205, reward function loss: -0.0474\n",
      "1280032: reward: 500.00, mean_100: 500.00, episodes: 3206, reward function loss: -0.0474\n",
      "1280532: reward: 500.00, mean_100: 500.00, episodes: 3207, reward function loss: -0.0474\n",
      "1281032: reward: 500.00, mean_100: 500.00, episodes: 3208, reward function loss: -0.0468\n",
      "1281532: reward: 500.00, mean_100: 500.00, episodes: 3209, reward function loss: -0.0468\n",
      "1282032: reward: 500.00, mean_100: 500.00, episodes: 3210, reward function loss: -0.0468\n",
      "1282532: reward: 500.00, mean_100: 500.00, episodes: 3211, reward function loss: -0.0468\n",
      "1283032: reward: 500.00, mean_100: 500.00, episodes: 3212, reward function loss: -0.0473\n",
      "1283532: reward: 500.00, mean_100: 500.00, episodes: 3213, reward function loss: -0.0473\n",
      "1284032: reward: 500.00, mean_100: 500.00, episodes: 3214, reward function loss: -0.0473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1284532: reward: 500.00, mean_100: 500.00, episodes: 3215, reward function loss: -0.0473\n",
      "1285032: reward: 500.00, mean_100: 500.00, episodes: 3216, reward function loss: -0.0476\n",
      "1285532: reward: 500.00, mean_100: 500.00, episodes: 3217, reward function loss: -0.0476\n",
      "1286032: reward: 500.00, mean_100: 500.00, episodes: 3218, reward function loss: -0.0476\n",
      "1286532: reward: 500.00, mean_100: 500.00, episodes: 3219, reward function loss: -0.0476\n",
      "1287032: reward: 500.00, mean_100: 500.00, episodes: 3220, reward function loss: -0.0474\n",
      "1287532: reward: 500.00, mean_100: 500.00, episodes: 3221, reward function loss: -0.0474\n",
      "1288032: reward: 500.00, mean_100: 500.00, episodes: 3222, reward function loss: -0.0474\n",
      "1288532: reward: 500.00, mean_100: 500.00, episodes: 3223, reward function loss: -0.0474\n",
      "1289032: reward: 500.00, mean_100: 500.00, episodes: 3224, reward function loss: -0.0479\n",
      "1289532: reward: 500.00, mean_100: 500.00, episodes: 3225, reward function loss: -0.0479\n",
      "1290032: reward: 500.00, mean_100: 500.00, episodes: 3226, reward function loss: -0.0479\n",
      "1290532: reward: 500.00, mean_100: 500.00, episodes: 3227, reward function loss: -0.0479\n",
      "1291032: reward: 500.00, mean_100: 500.00, episodes: 3228, reward function loss: -0.0475\n",
      "1291532: reward: 500.00, mean_100: 500.00, episodes: 3229, reward function loss: -0.0475\n",
      "1292032: reward: 500.00, mean_100: 500.00, episodes: 3230, reward function loss: -0.0475\n",
      "1292532: reward: 500.00, mean_100: 500.00, episodes: 3231, reward function loss: -0.0475\n",
      "1293032: reward: 500.00, mean_100: 500.00, episodes: 3232, reward function loss: -0.0464\n",
      "1293532: reward: 500.00, mean_100: 500.00, episodes: 3233, reward function loss: -0.0464\n",
      "1294032: reward: 500.00, mean_100: 500.00, episodes: 3234, reward function loss: -0.0464\n",
      "1294532: reward: 500.00, mean_100: 500.00, episodes: 3235, reward function loss: -0.0464\n",
      "1295032: reward: 500.00, mean_100: 500.00, episodes: 3236, reward function loss: -0.0471\n",
      "1295532: reward: 500.00, mean_100: 500.00, episodes: 3237, reward function loss: -0.0471\n",
      "1296032: reward: 500.00, mean_100: 500.00, episodes: 3238, reward function loss: -0.0471\n",
      "1296532: reward: 500.00, mean_100: 500.00, episodes: 3239, reward function loss: -0.0471\n",
      "1297032: reward: 500.00, mean_100: 500.00, episodes: 3240, reward function loss: -0.0473\n",
      "1297532: reward: 500.00, mean_100: 500.00, episodes: 3241, reward function loss: -0.0473\n",
      "1298032: reward: 500.00, mean_100: 500.00, episodes: 3242, reward function loss: -0.0473\n",
      "1298532: reward: 500.00, mean_100: 500.00, episodes: 3243, reward function loss: -0.0473\n",
      "1299032: reward: 500.00, mean_100: 500.00, episodes: 3244, reward function loss: -0.0472\n",
      "1299532: reward: 500.00, mean_100: 500.00, episodes: 3245, reward function loss: -0.0472\n",
      "1300032: reward: 500.00, mean_100: 500.00, episodes: 3246, reward function loss: -0.0472\n",
      "1300532: reward: 500.00, mean_100: 500.00, episodes: 3247, reward function loss: -0.0472\n",
      "1301032: reward: 500.00, mean_100: 500.00, episodes: 3248, reward function loss: -0.0468\n",
      "1301532: reward: 500.00, mean_100: 500.00, episodes: 3249, reward function loss: -0.0468\n",
      "1302032: reward: 500.00, mean_100: 500.00, episodes: 3250, reward function loss: -0.0468\n",
      "1302532: reward: 500.00, mean_100: 500.00, episodes: 3251, reward function loss: -0.0468\n",
      "1303032: reward: 500.00, mean_100: 500.00, episodes: 3252, reward function loss: -0.0475\n",
      "1303532: reward: 500.00, mean_100: 500.00, episodes: 3253, reward function loss: -0.0475\n",
      "1304032: reward: 500.00, mean_100: 500.00, episodes: 3254, reward function loss: -0.0475\n",
      "1304532: reward: 500.00, mean_100: 500.00, episodes: 3255, reward function loss: -0.0475\n",
      "1305032: reward: 500.00, mean_100: 500.00, episodes: 3256, reward function loss: -0.0432\n",
      "1305532: reward: 500.00, mean_100: 500.00, episodes: 3257, reward function loss: -0.0432\n",
      "1306032: reward: 500.00, mean_100: 500.00, episodes: 3258, reward function loss: -0.0432\n",
      "1306532: reward: 500.00, mean_100: 500.00, episodes: 3259, reward function loss: -0.0432\n",
      "1307032: reward: 500.00, mean_100: 500.00, episodes: 3260, reward function loss: -0.0460\n",
      "1307532: reward: 500.00, mean_100: 500.00, episodes: 3261, reward function loss: -0.0460\n",
      "1308032: reward: 500.00, mean_100: 500.00, episodes: 3262, reward function loss: -0.0460\n",
      "1308532: reward: 500.00, mean_100: 500.00, episodes: 3263, reward function loss: -0.0460\n",
      "1309032: reward: 500.00, mean_100: 500.00, episodes: 3264, reward function loss: -0.0477\n",
      "1309532: reward: 500.00, mean_100: 500.00, episodes: 3265, reward function loss: -0.0477\n",
      "1310032: reward: 500.00, mean_100: 500.00, episodes: 3266, reward function loss: -0.0477\n",
      "1310532: reward: 500.00, mean_100: 500.00, episodes: 3267, reward function loss: -0.0477\n",
      "1311032: reward: 500.00, mean_100: 500.00, episodes: 3268, reward function loss: -0.0474\n",
      "1311532: reward: 500.00, mean_100: 500.00, episodes: 3269, reward function loss: -0.0474\n",
      "1312032: reward: 500.00, mean_100: 500.00, episodes: 3270, reward function loss: -0.0474\n",
      "1312532: reward: 500.00, mean_100: 500.00, episodes: 3271, reward function loss: -0.0474\n",
      "1313032: reward: 500.00, mean_100: 500.00, episodes: 3272, reward function loss: -0.0459\n",
      "1313532: reward: 500.00, mean_100: 500.00, episodes: 3273, reward function loss: -0.0459\n",
      "1314032: reward: 500.00, mean_100: 500.00, episodes: 3274, reward function loss: -0.0459\n",
      "1314532: reward: 500.00, mean_100: 500.00, episodes: 3275, reward function loss: -0.0459\n",
      "1315032: reward: 500.00, mean_100: 500.00, episodes: 3276, reward function loss: -0.0479\n",
      "1315532: reward: 500.00, mean_100: 500.00, episodes: 3277, reward function loss: -0.0479\n",
      "1316032: reward: 500.00, mean_100: 500.00, episodes: 3278, reward function loss: -0.0479\n",
      "1316532: reward: 500.00, mean_100: 500.00, episodes: 3279, reward function loss: -0.0479\n",
      "1317032: reward: 500.00, mean_100: 500.00, episodes: 3280, reward function loss: -0.0479\n",
      "1317532: reward: 500.00, mean_100: 500.00, episodes: 3281, reward function loss: -0.0479\n",
      "1318032: reward: 500.00, mean_100: 500.00, episodes: 3282, reward function loss: -0.0479\n",
      "1318532: reward: 500.00, mean_100: 500.00, episodes: 3283, reward function loss: -0.0479\n",
      "1319032: reward: 500.00, mean_100: 500.00, episodes: 3284, reward function loss: -0.0446\n",
      "1319532: reward: 500.00, mean_100: 500.00, episodes: 3285, reward function loss: -0.0446\n",
      "1320032: reward: 500.00, mean_100: 500.00, episodes: 3286, reward function loss: -0.0446\n",
      "1320532: reward: 500.00, mean_100: 500.00, episodes: 3287, reward function loss: -0.0446\n",
      "1321032: reward: 500.00, mean_100: 500.00, episodes: 3288, reward function loss: -0.0479\n",
      "1321532: reward: 500.00, mean_100: 500.00, episodes: 3289, reward function loss: -0.0479\n",
      "1322032: reward: 500.00, mean_100: 500.00, episodes: 3290, reward function loss: -0.0479\n",
      "1322532: reward: 500.00, mean_100: 500.00, episodes: 3291, reward function loss: -0.0479\n",
      "1323032: reward: 500.00, mean_100: 500.00, episodes: 3292, reward function loss: -0.0443\n",
      "1323532: reward: 500.00, mean_100: 500.00, episodes: 3293, reward function loss: -0.0443\n",
      "1324032: reward: 500.00, mean_100: 500.00, episodes: 3294, reward function loss: -0.0443\n",
      "1324532: reward: 500.00, mean_100: 500.00, episodes: 3295, reward function loss: -0.0443\n",
      "1325032: reward: 500.00, mean_100: 500.00, episodes: 3296, reward function loss: -0.0476\n",
      "1325532: reward: 500.00, mean_100: 500.00, episodes: 3297, reward function loss: -0.0476\n",
      "1326032: reward: 500.00, mean_100: 500.00, episodes: 3298, reward function loss: -0.0476\n",
      "1326532: reward: 500.00, mean_100: 500.00, episodes: 3299, reward function loss: -0.0476\n",
      "1327032: reward: 500.00, mean_100: 500.00, episodes: 3300, reward function loss: -0.0450\n",
      "1327532: reward: 500.00, mean_100: 500.00, episodes: 3301, reward function loss: -0.0450\n",
      "1328032: reward: 500.00, mean_100: 500.00, episodes: 3302, reward function loss: -0.0450\n",
      "1328532: reward: 500.00, mean_100: 500.00, episodes: 3303, reward function loss: -0.0450\n",
      "1329032: reward: 500.00, mean_100: 500.00, episodes: 3304, reward function loss: -0.0449\n",
      "1329532: reward: 500.00, mean_100: 500.00, episodes: 3305, reward function loss: -0.0449\n",
      "1330032: reward: 500.00, mean_100: 500.00, episodes: 3306, reward function loss: -0.0449\n",
      "1330532: reward: 500.00, mean_100: 500.00, episodes: 3307, reward function loss: -0.0449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1331032: reward: 500.00, mean_100: 500.00, episodes: 3308, reward function loss: -0.0471\n",
      "1331532: reward: 500.00, mean_100: 500.00, episodes: 3309, reward function loss: -0.0471\n",
      "1332032: reward: 500.00, mean_100: 500.00, episodes: 3310, reward function loss: -0.0471\n",
      "1332532: reward: 500.00, mean_100: 500.00, episodes: 3311, reward function loss: -0.0471\n",
      "1333032: reward: 500.00, mean_100: 500.00, episodes: 3312, reward function loss: -0.0427\n",
      "1333532: reward: 500.00, mean_100: 500.00, episodes: 3313, reward function loss: -0.0427\n",
      "1334032: reward: 500.00, mean_100: 500.00, episodes: 3314, reward function loss: -0.0427\n",
      "1334532: reward: 500.00, mean_100: 500.00, episodes: 3315, reward function loss: -0.0427\n",
      "1335032: reward: 500.00, mean_100: 500.00, episodes: 3316, reward function loss: -0.0415\n",
      "1335532: reward: 500.00, mean_100: 500.00, episodes: 3317, reward function loss: -0.0415\n",
      "1336032: reward: 500.00, mean_100: 500.00, episodes: 3318, reward function loss: -0.0415\n",
      "1336532: reward: 500.00, mean_100: 500.00, episodes: 3319, reward function loss: -0.0415\n",
      "1337032: reward: 500.00, mean_100: 500.00, episodes: 3320, reward function loss: -0.0458\n",
      "1337532: reward: 500.00, mean_100: 500.00, episodes: 3321, reward function loss: -0.0458\n",
      "1338032: reward: 500.00, mean_100: 500.00, episodes: 3322, reward function loss: -0.0458\n",
      "1338532: reward: 500.00, mean_100: 500.00, episodes: 3323, reward function loss: -0.0458\n",
      "1339032: reward: 500.00, mean_100: 500.00, episodes: 3324, reward function loss: -0.0396\n",
      "1339532: reward: 500.00, mean_100: 500.00, episodes: 3325, reward function loss: -0.0396\n",
      "1340032: reward: 500.00, mean_100: 500.00, episodes: 3326, reward function loss: -0.0396\n",
      "1340532: reward: 500.00, mean_100: 500.00, episodes: 3327, reward function loss: -0.0396\n",
      "1341032: reward: 500.00, mean_100: 500.00, episodes: 3328, reward function loss: -0.0395\n",
      "1341532: reward: 500.00, mean_100: 500.00, episodes: 3329, reward function loss: -0.0395\n",
      "1342032: reward: 500.00, mean_100: 500.00, episodes: 3330, reward function loss: -0.0395\n",
      "1342532: reward: 500.00, mean_100: 500.00, episodes: 3331, reward function loss: -0.0395\n",
      "1343032: reward: 500.00, mean_100: 500.00, episodes: 3332, reward function loss: -0.0447\n",
      "1343532: reward: 500.00, mean_100: 500.00, episodes: 3333, reward function loss: -0.0447\n",
      "1344032: reward: 500.00, mean_100: 500.00, episodes: 3334, reward function loss: -0.0447\n",
      "1344532: reward: 500.00, mean_100: 500.00, episodes: 3335, reward function loss: -0.0447\n",
      "1345032: reward: 500.00, mean_100: 500.00, episodes: 3336, reward function loss: -0.0470\n",
      "1345532: reward: 500.00, mean_100: 500.00, episodes: 3337, reward function loss: -0.0470\n",
      "1346032: reward: 500.00, mean_100: 500.00, episodes: 3338, reward function loss: -0.0470\n",
      "1346532: reward: 500.00, mean_100: 500.00, episodes: 3339, reward function loss: -0.0470\n",
      "1347032: reward: 500.00, mean_100: 500.00, episodes: 3340, reward function loss: -0.0348\n",
      "1347532: reward: 500.00, mean_100: 500.00, episodes: 3341, reward function loss: -0.0348\n",
      "1348032: reward: 500.00, mean_100: 500.00, episodes: 3342, reward function loss: -0.0348\n",
      "1348532: reward: 500.00, mean_100: 500.00, episodes: 3343, reward function loss: -0.0348\n",
      "1349032: reward: 500.00, mean_100: 500.00, episodes: 3344, reward function loss: -0.0404\n",
      "1349532: reward: 500.00, mean_100: 500.00, episodes: 3345, reward function loss: -0.0404\n",
      "1350032: reward: 500.00, mean_100: 500.00, episodes: 3346, reward function loss: -0.0404\n",
      "1350532: reward: 500.00, mean_100: 500.00, episodes: 3347, reward function loss: -0.0404\n",
      "1351032: reward: 500.00, mean_100: 500.00, episodes: 3348, reward function loss: -0.0314\n",
      "1351532: reward: 500.00, mean_100: 500.00, episodes: 3349, reward function loss: -0.0314\n",
      "1352032: reward: 500.00, mean_100: 500.00, episodes: 3350, reward function loss: -0.0314\n",
      "1352532: reward: 500.00, mean_100: 500.00, episodes: 3351, reward function loss: -0.0314\n",
      "1353032: reward: 500.00, mean_100: 500.00, episodes: 3352, reward function loss: -0.0334\n",
      "1353532: reward: 500.00, mean_100: 500.00, episodes: 3353, reward function loss: -0.0334\n",
      "1354032: reward: 500.00, mean_100: 500.00, episodes: 3354, reward function loss: -0.0334\n",
      "1354532: reward: 500.00, mean_100: 500.00, episodes: 3355, reward function loss: -0.0334\n",
      "1355032: reward: 500.00, mean_100: 500.00, episodes: 3356, reward function loss: -0.0355\n",
      "1355532: reward: 500.00, mean_100: 500.00, episodes: 3357, reward function loss: -0.0355\n",
      "1356032: reward: 500.00, mean_100: 500.00, episodes: 3358, reward function loss: -0.0355\n",
      "1356532: reward: 500.00, mean_100: 500.00, episodes: 3359, reward function loss: -0.0355\n",
      "1357032: reward: 500.00, mean_100: 500.00, episodes: 3360, reward function loss: -0.0439\n",
      "1357532: reward: 500.00, mean_100: 500.00, episodes: 3361, reward function loss: -0.0439\n",
      "1358032: reward: 500.00, mean_100: 500.00, episodes: 3362, reward function loss: -0.0439\n",
      "1358532: reward: 500.00, mean_100: 500.00, episodes: 3363, reward function loss: -0.0439\n",
      "1359032: reward: 500.00, mean_100: 500.00, episodes: 3364, reward function loss: -0.0276\n",
      "1359532: reward: 500.00, mean_100: 500.00, episodes: 3365, reward function loss: -0.0276\n",
      "1360032: reward: 500.00, mean_100: 500.00, episodes: 3366, reward function loss: -0.0276\n",
      "1360532: reward: 500.00, mean_100: 500.00, episodes: 3367, reward function loss: -0.0276\n",
      "1361032: reward: 500.00, mean_100: 500.00, episodes: 3368, reward function loss: -0.0419\n",
      "1361532: reward: 500.00, mean_100: 500.00, episodes: 3369, reward function loss: -0.0419\n",
      "1362032: reward: 500.00, mean_100: 500.00, episodes: 3370, reward function loss: -0.0419\n",
      "1362532: reward: 500.00, mean_100: 500.00, episodes: 3371, reward function loss: -0.0419\n",
      "1363032: reward: 500.00, mean_100: 500.00, episodes: 3372, reward function loss: -0.0250\n",
      "1363532: reward: 500.00, mean_100: 500.00, episodes: 3373, reward function loss: -0.0250\n",
      "1364032: reward: 500.00, mean_100: 500.00, episodes: 3374, reward function loss: -0.0250\n",
      "1364532: reward: 500.00, mean_100: 500.00, episodes: 3375, reward function loss: -0.0250\n",
      "1365032: reward: 500.00, mean_100: 500.00, episodes: 3376, reward function loss: -0.0384\n",
      "1365532: reward: 500.00, mean_100: 500.00, episodes: 3377, reward function loss: -0.0384\n",
      "1366032: reward: 500.00, mean_100: 500.00, episodes: 3378, reward function loss: -0.0384\n",
      "1366532: reward: 500.00, mean_100: 500.00, episodes: 3379, reward function loss: -0.0384\n",
      "1367032: reward: 500.00, mean_100: 500.00, episodes: 3380, reward function loss: -0.0380\n",
      "1367532: reward: 500.00, mean_100: 500.00, episodes: 3381, reward function loss: -0.0380\n",
      "1368032: reward: 500.00, mean_100: 500.00, episodes: 3382, reward function loss: -0.0380\n",
      "1368532: reward: 500.00, mean_100: 500.00, episodes: 3383, reward function loss: -0.0380\n",
      "1369032: reward: 500.00, mean_100: 500.00, episodes: 3384, reward function loss: -0.0388\n",
      "1369532: reward: 500.00, mean_100: 500.00, episodes: 3385, reward function loss: -0.0388\n",
      "1370032: reward: 500.00, mean_100: 500.00, episodes: 3386, reward function loss: -0.0388\n",
      "1370532: reward: 500.00, mean_100: 500.00, episodes: 3387, reward function loss: -0.0388\n",
      "1371032: reward: 500.00, mean_100: 500.00, episodes: 3388, reward function loss: -0.0367\n",
      "1371532: reward: 500.00, mean_100: 500.00, episodes: 3389, reward function loss: -0.0367\n",
      "1372032: reward: 500.00, mean_100: 500.00, episodes: 3390, reward function loss: -0.0367\n",
      "1372532: reward: 500.00, mean_100: 500.00, episodes: 3391, reward function loss: -0.0367\n",
      "1373032: reward: 500.00, mean_100: 500.00, episodes: 3392, reward function loss: -0.0201\n",
      "1373532: reward: 500.00, mean_100: 500.00, episodes: 3393, reward function loss: -0.0201\n",
      "1374032: reward: 500.00, mean_100: 500.00, episodes: 3394, reward function loss: -0.0201\n",
      "1374532: reward: 500.00, mean_100: 500.00, episodes: 3395, reward function loss: -0.0201\n",
      "1375032: reward: 500.00, mean_100: 500.00, episodes: 3396, reward function loss: -0.0327\n",
      "1375532: reward: 500.00, mean_100: 500.00, episodes: 3397, reward function loss: -0.0327\n",
      "1376032: reward: 500.00, mean_100: 500.00, episodes: 3398, reward function loss: -0.0327\n",
      "1376532: reward: 500.00, mean_100: 500.00, episodes: 3399, reward function loss: -0.0327\n",
      "1377032: reward: 500.00, mean_100: 500.00, episodes: 3400, reward function loss: -0.0317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1377532: reward: 500.00, mean_100: 500.00, episodes: 3401, reward function loss: -0.0317\n",
      "1378032: reward: 500.00, mean_100: 500.00, episodes: 3402, reward function loss: -0.0317\n",
      "1378532: reward: 500.00, mean_100: 500.00, episodes: 3403, reward function loss: -0.0317\n",
      "1378577: reward:  45.00, mean_100: 495.45, episodes: 3404, reward function loss: -0.0211\n",
      "1379077: reward: 500.00, mean_100: 495.45, episodes: 3405, reward function loss: -0.0211\n",
      "1379577: reward: 500.00, mean_100: 495.45, episodes: 3406, reward function loss: -0.0211\n",
      "1380077: reward: 500.00, mean_100: 495.45, episodes: 3407, reward function loss: -0.0211\n",
      "1380577: reward: 500.00, mean_100: 495.45, episodes: 3408, reward function loss: -0.0065\n",
      "1380855: reward: 278.00, mean_100: 493.23, episodes: 3409, reward function loss: -0.0065\n",
      "1381355: reward: 500.00, mean_100: 493.23, episodes: 3410, reward function loss: -0.0065\n",
      "1381855: reward: 500.00, mean_100: 493.23, episodes: 3411, reward function loss: -0.0065\n",
      "1382355: reward: 500.00, mean_100: 493.23, episodes: 3412, reward function loss: -0.0113\n",
      "1382367: reward:  12.00, mean_100: 488.35, episodes: 3413, reward function loss: -0.0113\n",
      "1382867: reward: 500.00, mean_100: 488.35, episodes: 3414, reward function loss: -0.0113\n",
      "1383367: reward: 500.00, mean_100: 488.35, episodes: 3415, reward function loss: -0.0113\n",
      "1383867: reward: 500.00, mean_100: 488.35, episodes: 3416, reward function loss: -0.0137\n",
      "1384367: reward: 500.00, mean_100: 488.35, episodes: 3417, reward function loss: -0.0137\n",
      "1384409: reward:  42.00, mean_100: 483.77, episodes: 3418, reward function loss: -0.0137\n",
      "1384909: reward: 500.00, mean_100: 483.77, episodes: 3419, reward function loss: -0.0137\n",
      "1385409: reward: 500.00, mean_100: 483.77, episodes: 3420, reward function loss: -0.0151\n",
      "1385909: reward: 500.00, mean_100: 483.77, episodes: 3421, reward function loss: -0.0151\n",
      "1385919: reward:  10.00, mean_100: 478.87, episodes: 3422, reward function loss: -0.0151\n",
      "1385933: reward:  14.00, mean_100: 474.01, episodes: 3423, reward function loss: -0.0151\n",
      "1386433: reward: 500.00, mean_100: 474.01, episodes: 3424, reward function loss: 0.0009\n",
      "1386551: reward: 118.00, mean_100: 470.19, episodes: 3425, reward function loss: 0.0009\n",
      "1386562: reward:  11.00, mean_100: 465.30, episodes: 3426, reward function loss: 0.0009\n",
      "1387062: reward: 500.00, mean_100: 465.30, episodes: 3427, reward function loss: 0.0009\n",
      "1387562: reward: 500.00, mean_100: 465.30, episodes: 3428, reward function loss: -0.0033\n",
      "1387606: reward:  44.00, mean_100: 460.74, episodes: 3429, reward function loss: -0.0033\n",
      "1388034: reward: 428.00, mean_100: 460.02, episodes: 3430, reward function loss: -0.0033\n",
      "1388044: reward:  10.00, mean_100: 455.12, episodes: 3431, reward function loss: -0.0033\n",
      "1388057: reward:  13.00, mean_100: 450.25, episodes: 3432, reward function loss: 0.0002\n",
      "1388068: reward:  11.00, mean_100: 445.36, episodes: 3433, reward function loss: 0.0002\n",
      "1388078: reward:  10.00, mean_100: 440.46, episodes: 3434, reward function loss: 0.0002\n",
      "1388088: reward:  10.00, mean_100: 435.56, episodes: 3435, reward function loss: 0.0002\n",
      "1388131: reward:  43.00, mean_100: 430.99, episodes: 3436, reward function loss: -0.0000\n",
      "1388145: reward:  14.00, mean_100: 426.13, episodes: 3437, reward function loss: -0.0000\n",
      "1388155: reward:  10.00, mean_100: 421.23, episodes: 3438, reward function loss: -0.0000\n",
      "1388613: reward: 458.00, mean_100: 420.81, episodes: 3439, reward function loss: -0.0000\n",
      "1388626: reward:  13.00, mean_100: 415.94, episodes: 3440, reward function loss: -0.0000\n",
      "1388637: reward:  11.00, mean_100: 411.05, episodes: 3441, reward function loss: -0.0000\n",
      "1388647: reward:  10.00, mean_100: 406.15, episodes: 3442, reward function loss: -0.0000\n",
      "1388656: reward:   9.00, mean_100: 401.24, episodes: 3443, reward function loss: -0.0000\n",
      "1388665: reward:   9.00, mean_100: 396.33, episodes: 3444, reward function loss: 0.0000\n",
      "1388675: reward:  10.00, mean_100: 391.43, episodes: 3445, reward function loss: 0.0000\n",
      "1388684: reward:   9.00, mean_100: 386.52, episodes: 3446, reward function loss: 0.0000\n",
      "1388694: reward:  10.00, mean_100: 381.62, episodes: 3447, reward function loss: 0.0000\n",
      "1388704: reward:  10.00, mean_100: 376.72, episodes: 3448, reward function loss: 0.0000\n",
      "1388713: reward:   9.00, mean_100: 371.81, episodes: 3449, reward function loss: 0.0000\n",
      "1388724: reward:  11.00, mean_100: 366.92, episodes: 3450, reward function loss: 0.0000\n",
      "1389084: reward: 360.00, mean_100: 365.52, episodes: 3451, reward function loss: 0.0000\n",
      "1389094: reward:  10.00, mean_100: 360.62, episodes: 3452, reward function loss: 0.0000\n",
      "1389104: reward:  10.00, mean_100: 355.72, episodes: 3453, reward function loss: 0.0000\n",
      "1389114: reward:  10.00, mean_100: 350.82, episodes: 3454, reward function loss: 0.0000\n",
      "1389124: reward:  10.00, mean_100: 345.92, episodes: 3455, reward function loss: 0.0000\n",
      "1389135: reward:  11.00, mean_100: 341.03, episodes: 3456, reward function loss: -0.0000\n",
      "1389144: reward:   9.00, mean_100: 336.12, episodes: 3457, reward function loss: -0.0000\n",
      "1389154: reward:  10.00, mean_100: 331.22, episodes: 3458, reward function loss: -0.0000\n",
      "1389165: reward:  11.00, mean_100: 326.33, episodes: 3459, reward function loss: -0.0000\n",
      "1389177: reward:  12.00, mean_100: 321.45, episodes: 3460, reward function loss: 0.0000\n",
      "1389187: reward:  10.00, mean_100: 316.55, episodes: 3461, reward function loss: 0.0000\n",
      "1389197: reward:  10.00, mean_100: 311.65, episodes: 3462, reward function loss: 0.0000\n",
      "1389206: reward:   9.00, mean_100: 306.74, episodes: 3463, reward function loss: 0.0000\n",
      "1389215: reward:   9.00, mean_100: 301.83, episodes: 3464, reward function loss: -0.0000\n",
      "1389224: reward:   9.00, mean_100: 296.92, episodes: 3465, reward function loss: -0.0000\n",
      "1389234: reward:  10.00, mean_100: 292.02, episodes: 3466, reward function loss: -0.0000\n",
      "1389243: reward:   9.00, mean_100: 287.11, episodes: 3467, reward function loss: -0.0000\n",
      "1389253: reward:  10.00, mean_100: 282.21, episodes: 3468, reward function loss: 0.0000\n",
      "1389263: reward:  10.00, mean_100: 277.31, episodes: 3469, reward function loss: 0.0000\n",
      "1389272: reward:   9.00, mean_100: 272.40, episodes: 3470, reward function loss: 0.0000\n",
      "1389281: reward:   9.00, mean_100: 267.49, episodes: 3471, reward function loss: 0.0000\n",
      "1389291: reward:  10.00, mean_100: 262.59, episodes: 3472, reward function loss: 0.0000\n",
      "1389301: reward:  10.00, mean_100: 257.69, episodes: 3473, reward function loss: 0.0000\n",
      "1389310: reward:   9.00, mean_100: 252.78, episodes: 3474, reward function loss: 0.0000\n",
      "1389320: reward:  10.00, mean_100: 247.88, episodes: 3475, reward function loss: 0.0000\n",
      "1389331: reward:  11.00, mean_100: 242.99, episodes: 3476, reward function loss: 0.0000\n",
      "1389341: reward:  10.00, mean_100: 238.09, episodes: 3477, reward function loss: 0.0000\n",
      "1389351: reward:  10.00, mean_100: 233.19, episodes: 3478, reward function loss: 0.0000\n",
      "1389361: reward:  10.00, mean_100: 228.29, episodes: 3479, reward function loss: 0.0000\n",
      "1389371: reward:  10.00, mean_100: 223.39, episodes: 3480, reward function loss: 0.0000\n",
      "1389380: reward:   9.00, mean_100: 218.48, episodes: 3481, reward function loss: 0.0000\n",
      "1389389: reward:   9.00, mean_100: 213.57, episodes: 3482, reward function loss: 0.0000\n",
      "1389399: reward:  10.00, mean_100: 208.67, episodes: 3483, reward function loss: 0.0000\n",
      "1389409: reward:  10.00, mean_100: 203.77, episodes: 3484, reward function loss: -0.0000\n",
      "1389418: reward:   9.00, mean_100: 198.86, episodes: 3485, reward function loss: -0.0000\n",
      "1389427: reward:   9.00, mean_100: 193.95, episodes: 3486, reward function loss: -0.0000\n",
      "1389436: reward:   9.00, mean_100: 189.04, episodes: 3487, reward function loss: -0.0000\n",
      "1389446: reward:  10.00, mean_100: 184.14, episodes: 3488, reward function loss: -0.0000\n",
      "1389455: reward:   9.00, mean_100: 179.23, episodes: 3489, reward function loss: -0.0000\n",
      "1389465: reward:  10.00, mean_100: 174.33, episodes: 3490, reward function loss: -0.0000\n",
      "1389475: reward:  10.00, mean_100: 169.43, episodes: 3491, reward function loss: -0.0000\n",
      "1389485: reward:  10.00, mean_100: 164.53, episodes: 3492, reward function loss: 0.0000\n",
      "1389495: reward:  10.00, mean_100: 159.63, episodes: 3493, reward function loss: 0.0000\n",
      "1389504: reward:   9.00, mean_100: 154.72, episodes: 3494, reward function loss: 0.0000\n",
      "1389513: reward:   9.00, mean_100: 149.81, episodes: 3495, reward function loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1389523: reward:  10.00, mean_100: 144.91, episodes: 3496, reward function loss: -0.0000\n",
      "1389533: reward:  10.00, mean_100: 140.01, episodes: 3497, reward function loss: -0.0000\n",
      "1389543: reward:  10.00, mean_100: 135.11, episodes: 3498, reward function loss: -0.0000\n",
      "1389552: reward:   9.00, mean_100: 130.20, episodes: 3499, reward function loss: -0.0000\n",
      "1389563: reward:  11.00, mean_100: 125.31, episodes: 3500, reward function loss: -0.0000\n",
      "1389572: reward:   9.00, mean_100: 120.40, episodes: 3501, reward function loss: -0.0000\n",
      "1389581: reward:   9.00, mean_100: 115.49, episodes: 3502, reward function loss: -0.0000\n",
      "1389591: reward:  10.00, mean_100: 110.59, episodes: 3503, reward function loss: -0.0000\n",
      "1389697: reward: 106.00, mean_100: 111.20, episodes: 3504, reward function loss: -0.0000\n",
      "1389706: reward:   9.00, mean_100: 106.29, episodes: 3505, reward function loss: -0.0000\n",
      "1389715: reward:   9.00, mean_100: 101.38, episodes: 3506, reward function loss: -0.0000\n",
      "1389725: reward:  10.00, mean_100:  96.48, episodes: 3507, reward function loss: -0.0000\n",
      "1389735: reward:  10.00, mean_100:  91.58, episodes: 3508, reward function loss: 0.0000\n",
      "1389745: reward:  10.00, mean_100:  88.90, episodes: 3509, reward function loss: 0.0000\n",
      "1389754: reward:   9.00, mean_100:  83.99, episodes: 3510, reward function loss: 0.0000\n",
      "1389764: reward:  10.00, mean_100:  79.09, episodes: 3511, reward function loss: 0.0000\n",
      "1389773: reward:   9.00, mean_100:  74.18, episodes: 3512, reward function loss: -0.0000\n",
      "1389782: reward:   9.00, mean_100:  74.15, episodes: 3513, reward function loss: -0.0000\n",
      "1389792: reward:  10.00, mean_100:  69.25, episodes: 3514, reward function loss: -0.0000\n",
      "1389801: reward:   9.00, mean_100:  64.34, episodes: 3515, reward function loss: -0.0000\n",
      "1389809: reward:   8.00, mean_100:  59.42, episodes: 3516, reward function loss: -0.0000\n",
      "1389819: reward:  10.00, mean_100:  54.52, episodes: 3517, reward function loss: -0.0000\n",
      "1389828: reward:   9.00, mean_100:  54.19, episodes: 3518, reward function loss: -0.0000\n",
      "1389838: reward:  10.00, mean_100:  49.29, episodes: 3519, reward function loss: -0.0000\n",
      "1389848: reward:  10.00, mean_100:  44.39, episodes: 3520, reward function loss: 0.0000\n",
      "1389857: reward:   9.00, mean_100:  39.48, episodes: 3521, reward function loss: 0.0000\n",
      "1389866: reward:   9.00, mean_100:  39.47, episodes: 3522, reward function loss: 0.0000\n",
      "1389876: reward:  10.00, mean_100:  39.43, episodes: 3523, reward function loss: 0.0000\n",
      "1389886: reward:  10.00, mean_100:  34.53, episodes: 3524, reward function loss: -0.0000\n",
      "1389894: reward:   8.00, mean_100:  33.43, episodes: 3525, reward function loss: -0.0000\n",
      "1389904: reward:  10.00, mean_100:  33.42, episodes: 3526, reward function loss: -0.0000\n",
      "1389913: reward:   9.00, mean_100:  28.51, episodes: 3527, reward function loss: -0.0000\n",
      "1389923: reward:  10.00, mean_100:  23.61, episodes: 3528, reward function loss: -0.0000\n",
      "1389931: reward:   8.00, mean_100:  23.25, episodes: 3529, reward function loss: -0.0000\n",
      "1389942: reward:  11.00, mean_100:  19.08, episodes: 3530, reward function loss: -0.0000\n",
      "1389952: reward:  10.00, mean_100:  19.08, episodes: 3531, reward function loss: -0.0000\n",
      "1389960: reward:   8.00, mean_100:  19.03, episodes: 3532, reward function loss: 0.0000\n",
      "1389969: reward:   9.00, mean_100:  19.01, episodes: 3533, reward function loss: 0.0000\n",
      "1389978: reward:   9.00, mean_100:  19.00, episodes: 3534, reward function loss: 0.0000\n",
      "1389987: reward:   9.00, mean_100:  18.99, episodes: 3535, reward function loss: 0.0000\n",
      "1389997: reward:  10.00, mean_100:  18.66, episodes: 3536, reward function loss: 0.0000\n",
      "1390007: reward:  10.00, mean_100:  18.62, episodes: 3537, reward function loss: 0.0000\n",
      "1390017: reward:  10.00, mean_100:  18.62, episodes: 3538, reward function loss: 0.0000\n",
      "1390026: reward:   9.00, mean_100:  14.13, episodes: 3539, reward function loss: 0.0000\n",
      "1390036: reward:  10.00, mean_100:  14.10, episodes: 3540, reward function loss: -0.0000\n",
      "1390044: reward:   8.00, mean_100:  14.07, episodes: 3541, reward function loss: -0.0000\n",
      "1390053: reward:   9.00, mean_100:  14.06, episodes: 3542, reward function loss: -0.0000\n",
      "1390063: reward:  10.00, mean_100:  14.07, episodes: 3543, reward function loss: -0.0000\n",
      "1390072: reward:   9.00, mean_100:  14.07, episodes: 3544, reward function loss: 0.0000\n",
      "1390082: reward:  10.00, mean_100:  14.07, episodes: 3545, reward function loss: 0.0000\n",
      "1390092: reward:  10.00, mean_100:  14.08, episodes: 3546, reward function loss: 0.0000\n",
      "1390101: reward:   9.00, mean_100:  14.07, episodes: 3547, reward function loss: 0.0000\n",
      "1390110: reward:   9.00, mean_100:  14.06, episodes: 3548, reward function loss: -0.0000\n",
      "1390121: reward:  11.00, mean_100:  14.08, episodes: 3549, reward function loss: -0.0000\n",
      "1390130: reward:   9.00, mean_100:  14.06, episodes: 3550, reward function loss: -0.0000\n",
      "1390140: reward:  10.00, mean_100:  10.56, episodes: 3551, reward function loss: -0.0000\n",
      "1390150: reward:  10.00, mean_100:  10.56, episodes: 3552, reward function loss: -0.0000\n",
      "1390159: reward:   9.00, mean_100:  10.55, episodes: 3553, reward function loss: -0.0000\n",
      "1390168: reward:   9.00, mean_100:  10.54, episodes: 3554, reward function loss: -0.0000\n",
      "1390177: reward:   9.00, mean_100:  10.53, episodes: 3555, reward function loss: -0.0000\n",
      "1390186: reward:   9.00, mean_100:  10.51, episodes: 3556, reward function loss: -0.0000\n",
      "1390194: reward:   8.00, mean_100:  10.50, episodes: 3557, reward function loss: -0.0000\n",
      "1390203: reward:   9.00, mean_100:  10.49, episodes: 3558, reward function loss: -0.0000\n",
      "1390213: reward:  10.00, mean_100:  10.48, episodes: 3559, reward function loss: -0.0000\n",
      "1390222: reward:   9.00, mean_100:  10.45, episodes: 3560, reward function loss: -0.0000\n",
      "1390232: reward:  10.00, mean_100:  10.45, episodes: 3561, reward function loss: -0.0000\n",
      "1390241: reward:   9.00, mean_100:  10.44, episodes: 3562, reward function loss: -0.0000\n",
      "1390250: reward:   9.00, mean_100:  10.44, episodes: 3563, reward function loss: -0.0000\n",
      "1390260: reward:  10.00, mean_100:  10.45, episodes: 3564, reward function loss: 0.0000\n",
      "1390268: reward:   8.00, mean_100:  10.44, episodes: 3565, reward function loss: 0.0000\n",
      "1390278: reward:  10.00, mean_100:  10.44, episodes: 3566, reward function loss: 0.0000\n",
      "1390288: reward:  10.00, mean_100:  10.45, episodes: 3567, reward function loss: 0.0000\n",
      "1390297: reward:   9.00, mean_100:  10.44, episodes: 3568, reward function loss: -0.0000\n",
      "1390306: reward:   9.00, mean_100:  10.43, episodes: 3569, reward function loss: -0.0000\n",
      "1390316: reward:  10.00, mean_100:  10.44, episodes: 3570, reward function loss: -0.0000\n",
      "1390325: reward:   9.00, mean_100:  10.44, episodes: 3571, reward function loss: -0.0000\n",
      "1390335: reward:  10.00, mean_100:  10.44, episodes: 3572, reward function loss: -0.0000\n",
      "1390344: reward:   9.00, mean_100:  10.43, episodes: 3573, reward function loss: -0.0000\n",
      "1390354: reward:  10.00, mean_100:  10.44, episodes: 3574, reward function loss: -0.0000\n",
      "1390363: reward:   9.00, mean_100:  10.43, episodes: 3575, reward function loss: -0.0000\n",
      "1390372: reward:   9.00, mean_100:  10.41, episodes: 3576, reward function loss: -0.0000\n",
      "1390382: reward:  10.00, mean_100:  10.41, episodes: 3577, reward function loss: -0.0000\n",
      "1390393: reward:  11.00, mean_100:  10.42, episodes: 3578, reward function loss: -0.0000\n",
      "1390403: reward:  10.00, mean_100:  10.42, episodes: 3579, reward function loss: -0.0000\n",
      "1390413: reward:  10.00, mean_100:  10.42, episodes: 3580, reward function loss: -0.0000\n",
      "1390422: reward:   9.00, mean_100:  10.42, episodes: 3581, reward function loss: -0.0000\n",
      "1390433: reward:  11.00, mean_100:  10.44, episodes: 3582, reward function loss: -0.0000\n",
      "1390443: reward:  10.00, mean_100:  10.44, episodes: 3583, reward function loss: -0.0000\n",
      "1390453: reward:  10.00, mean_100:  10.44, episodes: 3584, reward function loss: -0.0000\n",
      "1390463: reward:  10.00, mean_100:  10.45, episodes: 3585, reward function loss: -0.0000\n",
      "1390473: reward:  10.00, mean_100:  10.46, episodes: 3586, reward function loss: -0.0000\n",
      "1390482: reward:   9.00, mean_100:  10.46, episodes: 3587, reward function loss: -0.0000\n",
      "1390492: reward:  10.00, mean_100:  10.46, episodes: 3588, reward function loss: -0.0000\n",
      "1390501: reward:   9.00, mean_100:  10.46, episodes: 3589, reward function loss: -0.0000\n",
      "1390511: reward:  10.00, mean_100:  10.46, episodes: 3590, reward function loss: -0.0000\n",
      "1390521: reward:  10.00, mean_100:  10.46, episodes: 3591, reward function loss: -0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1390531: reward:  10.00, mean_100:  10.46, episodes: 3592, reward function loss: -0.0000\n",
      "1390540: reward:   9.00, mean_100:  10.45, episodes: 3593, reward function loss: -0.0000\n",
      "1390549: reward:   9.00, mean_100:  10.45, episodes: 3594, reward function loss: -0.0000\n",
      "1390557: reward:   8.00, mean_100:  10.44, episodes: 3595, reward function loss: -0.0000\n",
      "1390567: reward:  10.00, mean_100:  10.44, episodes: 3596, reward function loss: -0.0000\n",
      "1390576: reward:   9.00, mean_100:  10.43, episodes: 3597, reward function loss: -0.0000\n",
      "1390586: reward:  10.00, mean_100:  10.43, episodes: 3598, reward function loss: -0.0000\n",
      "1390596: reward:  10.00, mean_100:  10.44, episodes: 3599, reward function loss: -0.0000\n",
      "1390605: reward:   9.00, mean_100:  10.42, episodes: 3600, reward function loss: -0.0000\n",
      "1390614: reward:   9.00, mean_100:  10.42, episodes: 3601, reward function loss: -0.0000\n",
      "1390624: reward:  10.00, mean_100:  10.43, episodes: 3602, reward function loss: -0.0000\n",
      "1390633: reward:   9.00, mean_100:  10.42, episodes: 3603, reward function loss: -0.0000\n",
      "1390643: reward:  10.00, mean_100:   9.46, episodes: 3604, reward function loss: -0.0000\n",
      "1390652: reward:   9.00, mean_100:   9.46, episodes: 3605, reward function loss: -0.0000\n",
      "1390662: reward:  10.00, mean_100:   9.47, episodes: 3606, reward function loss: -0.0000\n",
      "1390671: reward:   9.00, mean_100:   9.46, episodes: 3607, reward function loss: -0.0000\n",
      "1390680: reward:   9.00, mean_100:   9.45, episodes: 3608, reward function loss: -0.0000\n",
      "1390689: reward:   9.00, mean_100:   9.44, episodes: 3609, reward function loss: -0.0000\n",
      "1390699: reward:  10.00, mean_100:   9.45, episodes: 3610, reward function loss: -0.0000\n",
      "1390708: reward:   9.00, mean_100:   9.44, episodes: 3611, reward function loss: -0.0000\n",
      "1390718: reward:  10.00, mean_100:   9.45, episodes: 3612, reward function loss: -0.0000\n",
      "1390728: reward:  10.00, mean_100:   9.46, episodes: 3613, reward function loss: -0.0000\n",
      "1390738: reward:  10.00, mean_100:   9.46, episodes: 3614, reward function loss: -0.0000\n",
      "1390748: reward:  10.00, mean_100:   9.47, episodes: 3615, reward function loss: -0.0000\n",
      "1390757: reward:   9.00, mean_100:   9.48, episodes: 3616, reward function loss: -0.0000\n",
      "1390765: reward:   8.00, mean_100:   9.46, episodes: 3617, reward function loss: -0.0000\n",
      "1390774: reward:   9.00, mean_100:   9.46, episodes: 3618, reward function loss: -0.0000\n",
      "1390784: reward:  10.00, mean_100:   9.46, episodes: 3619, reward function loss: -0.0000\n",
      "1390793: reward:   9.00, mean_100:   9.45, episodes: 3620, reward function loss: -0.0000\n",
      "1390803: reward:  10.00, mean_100:   9.46, episodes: 3621, reward function loss: -0.0000\n",
      "1390864: reward:  61.00, mean_100:   9.98, episodes: 3622, reward function loss: -0.0000\n",
      "1390873: reward:   9.00, mean_100:   9.97, episodes: 3623, reward function loss: -0.0000\n",
      "1390884: reward:  11.00, mean_100:   9.98, episodes: 3624, reward function loss: -0.0000\n",
      "1390893: reward:   9.00, mean_100:   9.99, episodes: 3625, reward function loss: -0.0000\n",
      "1390902: reward:   9.00, mean_100:   9.98, episodes: 3626, reward function loss: -0.0000\n",
      "1390912: reward:  10.00, mean_100:   9.99, episodes: 3627, reward function loss: -0.0000\n",
      "1390921: reward:   9.00, mean_100:   9.98, episodes: 3628, reward function loss: -0.0000\n",
      "1390931: reward:  10.00, mean_100:  10.00, episodes: 3629, reward function loss: -0.0000\n",
      "1390941: reward:  10.00, mean_100:   9.99, episodes: 3630, reward function loss: -0.0000\n",
      "1390950: reward:   9.00, mean_100:   9.98, episodes: 3631, reward function loss: -0.0000\n",
      "1390959: reward:   9.00, mean_100:   9.99, episodes: 3632, reward function loss: -0.0000\n",
      "1390969: reward:  10.00, mean_100:  10.00, episodes: 3633, reward function loss: -0.0000\n",
      "1390977: reward:   8.00, mean_100:   9.99, episodes: 3634, reward function loss: -0.0000\n",
      "1390986: reward:   9.00, mean_100:   9.99, episodes: 3635, reward function loss: -0.0000\n",
      "1390995: reward:   9.00, mean_100:   9.98, episodes: 3636, reward function loss: -0.0000\n",
      "1391005: reward:  10.00, mean_100:   9.98, episodes: 3637, reward function loss: -0.0000\n",
      "1391016: reward:  11.00, mean_100:   9.99, episodes: 3638, reward function loss: -0.0000\n",
      "1391026: reward:  10.00, mean_100:  10.00, episodes: 3639, reward function loss: -0.0000\n",
      "1391036: reward:  10.00, mean_100:  10.00, episodes: 3640, reward function loss: -0.0000\n",
      "1391044: reward:   8.00, mean_100:  10.00, episodes: 3641, reward function loss: -0.0000\n",
      "1391053: reward:   9.00, mean_100:  10.00, episodes: 3642, reward function loss: -0.0000\n",
      "1391062: reward:   9.00, mean_100:   9.99, episodes: 3643, reward function loss: -0.0000\n",
      "1391072: reward:  10.00, mean_100:  10.00, episodes: 3644, reward function loss: -0.0000\n",
      "1391082: reward:  10.00, mean_100:  10.00, episodes: 3645, reward function loss: -0.0000\n",
      "1391092: reward:  10.00, mean_100:  10.00, episodes: 3646, reward function loss: -0.0000\n",
      "1391101: reward:   9.00, mean_100:  10.00, episodes: 3647, reward function loss: -0.0000\n",
      "1391109: reward:   8.00, mean_100:   9.99, episodes: 3648, reward function loss: -0.0000\n",
      "1391119: reward:  10.00, mean_100:   9.98, episodes: 3649, reward function loss: -0.0000\n",
      "1391129: reward:  10.00, mean_100:   9.99, episodes: 3650, reward function loss: -0.0000\n",
      "1391139: reward:  10.00, mean_100:   9.99, episodes: 3651, reward function loss: -0.0000\n",
      "1391148: reward:   9.00, mean_100:   9.98, episodes: 3652, reward function loss: -0.0000\n",
      "1391158: reward:  10.00, mean_100:   9.99, episodes: 3653, reward function loss: -0.0000\n",
      "1391166: reward:   8.00, mean_100:   9.98, episodes: 3654, reward function loss: -0.0000\n",
      "1391176: reward:  10.00, mean_100:   9.99, episodes: 3655, reward function loss: -0.0000\n",
      "1391185: reward:   9.00, mean_100:   9.99, episodes: 3656, reward function loss: -0.0000\n",
      "1391193: reward:   8.00, mean_100:   9.99, episodes: 3657, reward function loss: -0.0000\n",
      "1391201: reward:   8.00, mean_100:   9.98, episodes: 3658, reward function loss: -0.0000\n",
      "1391211: reward:  10.00, mean_100:   9.98, episodes: 3659, reward function loss: -0.0000\n",
      "1391221: reward:  10.00, mean_100:   9.99, episodes: 3660, reward function loss: -0.0001\n",
      "1391230: reward:   9.00, mean_100:   9.98, episodes: 3661, reward function loss: -0.0001\n",
      "1391239: reward:   9.00, mean_100:   9.98, episodes: 3662, reward function loss: -0.0001\n",
      "1391249: reward:  10.00, mean_100:   9.99, episodes: 3663, reward function loss: -0.0001\n",
      "1391257: reward:   8.00, mean_100:   9.97, episodes: 3664, reward function loss: -0.0000\n",
      "1391268: reward:  11.00, mean_100:  10.00, episodes: 3665, reward function loss: -0.0000\n",
      "1391278: reward:  10.00, mean_100:  10.00, episodes: 3666, reward function loss: -0.0000\n",
      "1391287: reward:   9.00, mean_100:   9.99, episodes: 3667, reward function loss: -0.0000\n",
      "1391295: reward:   8.00, mean_100:   9.98, episodes: 3668, reward function loss: -0.0001\n",
      "1391304: reward:   9.00, mean_100:   9.98, episodes: 3669, reward function loss: -0.0001\n",
      "1391314: reward:  10.00, mean_100:   9.98, episodes: 3670, reward function loss: -0.0001\n",
      "1391323: reward:   9.00, mean_100:   9.98, episodes: 3671, reward function loss: -0.0001\n",
      "1391331: reward:   8.00, mean_100:   9.96, episodes: 3672, reward function loss: -0.0000\n",
      "1391340: reward:   9.00, mean_100:   9.96, episodes: 3673, reward function loss: -0.0000\n",
      "1391348: reward:   8.00, mean_100:   9.94, episodes: 3674, reward function loss: -0.0000\n",
      "1391358: reward:  10.00, mean_100:   9.95, episodes: 3675, reward function loss: -0.0000\n",
      "1391368: reward:  10.00, mean_100:   9.96, episodes: 3676, reward function loss: -0.0000\n",
      "1391377: reward:   9.00, mean_100:   9.95, episodes: 3677, reward function loss: -0.0000\n",
      "1391387: reward:  10.00, mean_100:   9.94, episodes: 3678, reward function loss: -0.0000\n",
      "1391396: reward:   9.00, mean_100:   9.93, episodes: 3679, reward function loss: -0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-98560be57da1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0moptimizer_reward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mloss_rwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0moptimizer_reward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_rewards = []\n",
    "step_idx = 0\n",
    "done_episodes = 0\n",
    "\n",
    "batch_episodes = 0\n",
    "batch_states, batch_actions, batch_qvals = [], [], []\n",
    "cur_rewards = []\n",
    "loss_rwd = 0.\n",
    "\n",
    "for step_idx, exp in enumerate(exp_source):\n",
    "    batch_states.append(exp.state)\n",
    "    batch_actions.append(int(exp.action))\n",
    "    x = torch.cat([float32_preprocessor(exp.state), float32_preprocessor([int(exp.action)])]).view(1, -1)\n",
    "    reward = reward_net(x)\n",
    "    cur_rewards.append(reward.item())\n",
    "\n",
    "    if exp.last_state is None:\n",
    "        batch_qvals.extend(calc_qvals(cur_rewards))\n",
    "        cur_rewards.clear()\n",
    "        batch_episodes += 1\n",
    "\n",
    "    new_rewards = exp_source.pop_total_rewards()\n",
    "    if new_rewards:\n",
    "        done_episodes += 1\n",
    "        reward = new_rewards[0]\n",
    "        total_rewards.append(reward)\n",
    "        mean_rewards = float(np.mean(total_rewards[-100:]))\n",
    "        writer.add_scalar('reward', reward, done_episodes)\n",
    "        writer.add_scalar('mean_reward', mean_rewards, done_episodes)\n",
    "        writer.add_scalar('loss_rwd', loss_rwd, done_episodes) \n",
    "        print(f'{step_idx}: reward: {reward:6.2f}, mean_100: {mean_rewards:6.2f}, '\n",
    "              f'episodes: {done_episodes}, reward function loss: {loss_rwd:6.4f}')\n",
    "        \n",
    "        if done_episodes%100 == 0 or mean_rewards>=500:\n",
    "            N_samp = 20\n",
    "            S1 = np.linspace(-5, 5, N_samp)\n",
    "            S2 = np.linspace(-3.1457, 3.1457, N_samp)\n",
    "            S3 = 0*S1\n",
    "            S4 = 0*S1\n",
    "            \n",
    "            S5 = np.ones(N_samp)\n",
    "            \n",
    "            for action in [0,1]:\n",
    "                Reward = np.zeros((N_samp,N_samp))\n",
    "                for i in range(N_samp):\n",
    "                    for j in range(N_samp):\n",
    "                        state = [S1[i], S2[j], 0, 0]\n",
    "#                         action = 1\n",
    "                        x = torch.cat([float32_preprocessor(state), float32_preprocessor([int(action)])]).view(1, -1)\n",
    "                        r = reward_net(x)\n",
    "                        Reward[i,j] = r\n",
    "\n",
    "                X, Y = np.meshgrid(S1, S2)\n",
    "                Z = Reward\n",
    "                fig = plt.figure()\n",
    "                ax = plt.axes(projection='3d')\n",
    "                ax.plot_surface(X, Y, Z, rstride=1, cstride=1,\n",
    "                                cmap='viridis', edgecolor='none')\n",
    "                ax.set_title('surface');\n",
    "                ax.set_xlabel('x')\n",
    "                ax.set_ylabel('y')\n",
    "                ax.set_zlabel('z');\n",
    "                ax.view_init(azim=90, elev=90)\n",
    "                if action ==0:\n",
    "                    writer.add_figure('x1 vs x2 with a = 0', fig, global_step=done_episodes/100)\n",
    "                if action ==1:\n",
    "                    writer.add_figure('x1 vs x2 with a = 1', fig, global_step=done_episodes/100)    \n",
    "            \n",
    "        if mean_rewards >= 600:\n",
    "            print(f'Solved in {step_idx} steps and {done_episodes} episodes!')\n",
    "            torch.save(agent_net.state_dict(), 'cartpole_learner.mod')\n",
    "            torch.save(reward_net.state_dict(), 'cartpole-v1_reward_func.mod')\n",
    "            break\n",
    "        \n",
    "\n",
    "    if batch_episodes < EPISODES_TO_TRAIN:\n",
    "        continue\n",
    "\n",
    "    states_v = torch.FloatTensor(batch_states)\n",
    "    batch_actions_t = torch.LongTensor(batch_actions)\n",
    "    batch_qvals_v = torch.FloatTensor(batch_qvals)\n",
    "\n",
    "    # reward function learning\n",
    "    demo_states = demonstrations['states']\n",
    "    demo_actions = demonstrations['actions']\n",
    "    demo_probs = demonstrations['traj_probs']\n",
    "    for rf_i in range(10):\n",
    "        # Check is preprocessing is required \n",
    "        selected = np.random.choice(len(demonstrations), DEMO_BATCH)\n",
    "#         print(selected)\n",
    "        demo_states = demo_states[selected]\n",
    "        demo_actions = demo_actions[selected]\n",
    "#         demo_probs = demo_probs[selected]\n",
    "        demo_batch_states, demo_batch_actions = [], []\n",
    "        for idx in range(len(demo_states)):\n",
    "            demo_batch_states.extend(demo_states[idx])\n",
    "            demo_batch_actions.extend(demo_actions[idx])\n",
    "        demo_batch_states = torch.FloatTensor(demo_batch_states)\n",
    "        demo_batch_actions = torch.FloatTensor(demo_batch_actions)\n",
    "        D_demo = torch.cat([demo_batch_states, demo_batch_actions.view(-1, 1)], dim=-1)\n",
    "        D_samp = torch.cat([states_v, batch_actions_t.float().view(-1, 1)], dim=-1)\n",
    "        D_samp = torch.cat([D_demo, D_samp])\n",
    "        # dummy importance weights - fix later\n",
    "        z = torch.ones((D_samp.shape[0], 1))\n",
    "\n",
    "        # objective\n",
    "        D_demo_out = reward_net(D_demo)\n",
    "        D_samp_out = reward_net(D_samp)\n",
    "        D_samp_out = z * torch.exp(D_samp_out)\n",
    "        loss_rwd = torch.mean(D_demo_out) - torch.log(torch.mean(D_samp_out))\n",
    "        loss_rwd = -loss_rwd  # for maximization\n",
    "\n",
    "        # update parameters\n",
    "        optimizer_reward.zero_grad()\n",
    "        loss_rwd.backward()\n",
    "        optimizer_reward.step()\n",
    "\n",
    "    # agent\n",
    "    optimizer_agent.zero_grad()\n",
    "    logits_v = agent_net(states_v)\n",
    "    log_prob_v = torch.log_softmax(logits_v, dim=1)\n",
    "    # REINFORCE\n",
    "    log_prob_actions_v = batch_qvals_v * log_prob_v[range(len(batch_states)), batch_actions_t]\n",
    "    loss_v = -log_prob_actions_v.mean()\n",
    "    \n",
    "    writer.add_scalar('loss_agent_net', loss_v, done_episodes) \n",
    "    \n",
    "    loss_v.backward()\n",
    "    optimizer_agent.step()\n",
    "\n",
    "    batch_episodes = 0\n",
    "    batch_states.clear()\n",
    "    batch_actions.clear()\n",
    "    batch_qvals.clear()\n",
    "env.close()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Testing \n",
    "from util import Agent\n",
    "agent_net.eval()\n",
    "agent_ = Agent(agent_net, apply_softmax=True, preprocessor=ptan.agent.float32_preprocessor)\n",
    "\n",
    "for i in range(10):\n",
    "    state = env.reset()\n",
    "    Reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = agent_(state)\n",
    "        new_state, reward, done, _ = env.step(int(action))\n",
    "        Reward += reward\n",
    "    print(\"Trial :\", i, \" Reward: \", Reward)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected, len(demonstrations), DEMO_BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "S1 = np.linspace(-5, 5, 100)\n",
    "S2 = np.linspace(-3.1457, 3.1457, 100)\n",
    "S3 = 0*S1\n",
    "S4 = 0*S1\n",
    "S5 = np.ones(100)\n",
    "Reward = np.zeros((100,100))\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        state = [S1[i], S2[j], 0, 0]\n",
    "        action = 1\n",
    "        x = torch.cat([float32_preprocessor(state), float32_preprocessor([int(action)])]).view(1, -1)\n",
    "        r = reward_net(x)\n",
    "        Reward[i,j] = r\n",
    "        \n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(X, Y, Z, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.set_title('surface');\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z');\n",
    "ax.view_init(azim=90, elev=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstrations['states'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
